{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42c9e70",
   "metadata": {},
   "source": [
    "Predecir el futuro es algo que haces todo el tiempo, ya sea que estés terminando la frase de un amigo o anticipando el olor del café en el desayuno. En este capítulo discutiremos las redes neuronales recurrentes (RNN), una clase de redes que pueden predecir el futuro (bueno, hasta un punto). Los RNN pueden analizar datos de series temporales, como el número de usuarios activos diarios en su sitio web, la temperatura por hora en su ciudad, el consumo diario de energía de su hogar, las trayectorias de los coches cercanos y más. Una vez que un RNN aprende patrones pasados en los datos, puede usar su conocimiento para pronosticar el futuro, asumiendo, por supuesto, que los patrones pasados aún se mantienen en el futuro.\n",
    "\n",
    "De manera más general, los RNN pueden trabajar en secuencias de longitudes arbitrarias, en lugar de en entradas de tamaño fijo. Por ejemplo, pueden tomar oraciones, documentos o muestras de audio como entrada, lo que los hace extremadamente útiles para aplicaciones de procesamiento de lenguaje natural como la traducción automática o la conversión de voz a texto.\n",
    "\n",
    "En este capítulo, primero repasaremos los conceptos fundamentales que subyacen a los RNN y cómo entrenarlos utilizando la repropagación a través del tiempo. Luego, los usaremos para pronosticar una serie temporal. En el camino, veremos la popular familia de modelos ARMA, que a menudo se utilizan para pronosticar series temporales, y los utilizaremos como líneas de base para comparar con nuestros RNN. Después de eso, exploraremos las dos principales dificultades a las que se enfrentan los RNN:\n",
    "\n",
    "- Gradientes inestables (discutidos en el Capítulo 11), que se pueden aliviar utilizando varias técnicas, incluida la abandono recurrente y la normalización recurrente de la capa.\n",
    "\n",
    "* Una memoria a corto plazo (muy) limitada, que se puede ampliar utilizando células LSTM y GRU.\n",
    "\n",
    "Los RNN no son los únicos tipos de redes neuronales capaces de manejar datos secuenciales. Para secuencias pequeñas, una red densa regular puede hacer el truco, y para secuencias muy largas, como muestras de audio o texto, las redes neuronales convolucionales también pueden funcionar bastante bien. Discutiremos ambas posibilidades, y terminaremos este capítulo implementando una WaveNet, una arquitectura de CNN capaz de manejar secuencias de decenas de miles de pasos de tiempo. ¡Empecemos!\n",
    "\n",
    "\n",
    "# Neuronas y capas recurrentes\n",
    "\n",
    "\n",
    "Hasta ahora nos hemos centrado en las redes neuronales de avance, donde las activaciones fluyen solo en una dirección, desde la capa de entrada hasta la capa de salida. Una red neuronal recurrente se parece mucho a una red neuronal de avance, excepto que también tiene conexiones que apuntan hacia atrás.\n",
    "\n",
    "Echemos un vistazo a la RNN más simple posible, compuesta por una neurona que recibe entradas, produce una salida y envía esa salida de vuelta a sí misma, como se muestra en la Figura 15-1 (izquierda). En cada paso de tiempo t (también llamado marco), esta neurona recurrente recibe las entradas x(t), así como su propia salida del paso de tiempo anterior, ŷ(t–1). Dado que no hay una salida anterior en el primer paso de tiempo, generalmente se establece en 0. Podemos representar esta pequeña red contra el eje del tiempo, como se muestra en la Figura 15-1 (derecha). Esto se llama desenrollar la red a través del tiempo (es la misma neurona recurrente representada una vez por paso de tiempo).\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1501.png)\n",
    "\n",
    "(_Figura 15-1. Una neurona recurrente (izquierda) desenrollada a través del tiempo (derecha)_)\n",
    "\n",
    "Puedes crear fácilmente una capa de neuronas recurrentes. En cada paso de tiempo t, cada neurona recibe tanto el vector de entrada x(t) como el vector de salida del paso de tiempo anterior ŷ(t–1), como se muestra en la Figura 15-2. Tenga en cuenta que tanto las entradas como las salidas son ahora vectores (cuando solo había una neurona, la salida era escalar).\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1502.png)\n",
    "\n",
    "(_Figura 15-2. Una capa de neuronas recurrentes (izquierda) desenrollada a través del tiempo (derecha)_)\n",
    "\n",
    "Cada neurona recurrente tiene dos conjuntos de pesos: uno para las entradas x(t) y el otro para las salidas del paso de tiempo anterior, ŷ(t–1). Llamemos a estos vectores de peso wx y wŷ. Si consideramos toda la capa recurrente en lugar de una sola neurona recurrente, podemos colocar todos los vectores de peso en dos matrices de peso: Wx y Wŷ.\n",
    "\n",
    "El vector de salida de toda la capa recurrente se puede calcular más o menos como es de esperar, como se muestra en la ecuación 15-1, donde b es el vector de sesgo y φ(·) es la función de activación (por ejemplo, ReLU⁠1).\n",
    "\n",
    "\n",
    "### Ecuación 15-1. Salida de una capa recurrente para una sola instancia\n",
    "\n",
    "\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/PmyQ4RP/Captura-de-pantalla-2024-03-24-a-las-3-22-12.png\" alt=\"Captura-de-pantalla-2024-03-24-a-las-3-22-12\" border=\"0\"></a><br /><a target='_blank' href='https://imgbb.com/'>training images free</a><br />\n",
    "\n",
    "Al igual que con las redes neuronales de alimentación, podemos calcular la salida de una capa recurrente en una sola toma para un mini lote completo colocando todas las entradas en el momento del paso t en una matriz de entrada X(t) (ver Ecuación 15-2).\n",
    "\n",
    "### Ecuación 15-2. Salidas de una capa de neuronas recurrentes para todos los casos en un pase: [mini-lote\n",
    "\n",
    "<a href=\"https://ibb.co/fpFQ9Vt\"><img src=\"https://i.ibb.co/MVS9fyp/Captura-de-pantalla-2024-03-24-a-las-3-24-22.png\" alt=\"Captura-de-pantalla-2024-03-24-a-las-3-24-22\" border=\"0\"></a>\n",
    "\n",
    "En esta ecuación:\n",
    "\n",
    "* **Ŷ(t)** es una matriz de m × nneuronas que contiene las salidas de la capa en el paso t de tiempo para cada instancia en el minilote (m es el número de instancias en el minilote y las nneuronas es el número de neuronas).\n",
    "\n",
    "- **X(t)** es una matriz de m × ninputs que contiene las entradas para todas las instancias (ninputs es el número de características de entrada).\n",
    "\n",
    "* **Wx** es una matriz de ninputs × nneurons que contiene los pesos de conexión para las entradas del paso de tiempo actual.\n",
    "\n",
    "- **Wŷ** es una matriz de nneurones × nneurones que contiene los pesos de conexión para las salidas del paso de tiempo anterior.\n",
    "\n",
    "* **b** es un vector de nneuronas de tamaño que contiene el término de sesgo de cada neurona.\n",
    "\n",
    "- Las matrices de peso Wx y Wŷ a menudo se concatenan verticalmente en una sola matriz de peso W de forma (ninputs + nneurones) × nneurones (ver la segunda línea de la ecuación 15-2).\n",
    "\n",
    "* La notación [X(t) Ŷ(t–1)] representa la concatenación horizontal de las matrices X(t) y Ŷ(t–1).\n",
    "\n",
    "Tenga en cuenta que Ŷ(t) es una función de X(t) y Ŷ(t–1), que es una función de X(t–1) y Ŷ(t–2), que es una función de X(t–2) y Ŷ(t–3), y así suces. Esto hace queŶ(t) sea una función de todas las entradas desde el momento t = 0 (es decir, X(0), X(1), ... , X(t)). En el primer paso, t = 0, no hay salidas anteriores, por lo que normalmente se supone que son todos ceros.\n",
    "\n",
    "\n",
    "## Células de memoria\n",
    "\n",
    "\n",
    "Dado que la salida de una neurona recurrente en el paso de tiempo t es una función de todas las entradas de los pasos de tiempo anteriores, se podría decir que tiene una forma de memoria. Una parte de una red neuronal que conserva algún estado a través de los pasos de tiempo se llama celda de memoria (o simplemente una celda). Una sola neurona recurrente, o una capa de neuronas recurrentes, es una célula muy básica, capaz de aprender solo patrones cortos (normalmente de unos 10 pasos de largo, pero esto varía dependiendo de la tarea). Más adelante en este capítulo, analizaremos algunos tipos de células más complejos y poderosos capaces de aprender patrones más largos (aproximadamente 10 veces más largos, pero de nuevo, esto depende de la tarea).\n",
    "\n",
    "El estado de una celda en el paso de tiempo t, denotado h(t) (la \"h\" significa \"oculto\"), es una función de algunas entradas en ese paso de tiempo y su estado en el paso de tiempo anterior: h(t) = f(x(t), h(t–1). Su salida en el paso de tiempo t, denotada ŷ(t), también es una función del estado anterior y de las entradas actuales. En el caso de las células básicas que hemos discutido hasta ahora, la salida es igual al estado, pero en las celdas más complejas este no siempre es el caso, como se muestra en la Figura 15-3.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1503.png)\n",
    "\n",
    "(_Figura 15-3. El estado oculto de una celda y su salida pueden ser diferentes_)\n",
    "\n",
    "\n",
    "## Secuencias de entrada y salida\n",
    "\n",
    "\n",
    "Un RNN puede tomar simultáneamente una secuencia de entradas y producir una secuencia de salidas (ver la red superior izquierda en la Figura 15-4). Este tipo de red de secuencia a secuencia es útil para pronosticar series temporales, como el consumo diario de energía de su hogar: le alimenta los datos durante los últimos días y lo entrena para producir el consumo de energía cambiado un día hacia el futuro (es decir, de N - hace 1 día a mañana).\n",
    "\n",
    "Alternativamente, podría alimentar a la red con una secuencia de entradas e ignorar todas las salidas excepto la última (consulte la red de la parte superior derecha en la Figura 15-4). Esta es una red de secuencia a vector. Por ejemplo, podrías alimentar a la red con una secuencia de palabras correspondientes a una reseña de película, y la red produciría una puntuación de sentimiento (por ejemplo, de 0 [odio] a 1 [amor]).\n",
    "\n",
    "Por el contrario, podría alimentar a la red con el mismo vector de entrada una y otra vez en cada paso de tiempo y dejar que produzca una secuencia (ver la red inferior izquierda de la Figura 15-4). Esta es una red de vector a secuencia. Por ejemplo, la entrada podría ser una imagen (o la salida de una CNN), y la salida podría ser un pie de foto para esa imagen.\n",
    "\n",
    "Por último, podría tener una red de secuencia a vector, llamada codificador, seguida de una red de vector a secuencia, llamada decodificador (ver la red inferior derecha de la Figura 15-4). Por ejemplo, esto podría usarse para traducir una oración de un idioma a otro. Le darías a la red una oración en un idioma, el codificador convertiría esta oración en una sola representación vectorial, y luego el decodificador decodificaría este vector en una oración en otro idioma. Este modelo de dos pasos, llamado codificador-decodificador, ⁠2 funciona mucho mejor que tratar de traducir sobre la marcha con un solo RNN de secuencia a secuencia (como el representado en la parte superior izquierda): las últimas palabras de una oración pueden afectar a las primeras palabras de la traducción, por lo que debe esperar hasta que haya visto toda la oración antes de traducirla. Pasaremos por la implementación de un codificador-decodificador en el Capítulo 16 (como verá, es un poco más complejo de lo que sugiere la Figura 15-4).\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1504.png)\n",
    "\n",
    "(_Figura 15-4. Redes de secuencia a secuencia (arriba a la izquierda), de secuencia a vector (arriba a la derecha), de vector a secuencia (abajo a la izquierda) y codificador-decodificador (abajo a la derecha)_)\n",
    "\n",
    "Esta versatilidad suena prometedora, pero ¿cómo se entrena una red neuronal recurrente?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b39321",
   "metadata": {},
   "source": [
    "# Entrenamiento de RNN\n",
    "\n",
    "Para entrenar un RNN, el truco es desenrollarlo a través del tiempo (como acabamos de hacer) y luego usar la contrapropagación regular (ver Figura 15-5). Esta estrategia se llama repropagación a través del tiempo (BPTT).\n",
    "\n",
    "Al igual que en la contrapropagación regular, hay un primer paso hacia adelante a través de la red desenrollada (representada por las flechas diseadas). Luego, la secuencia de salida se evalúa utilizando una función de pérdida ℒ(Y(0), Y(1), ... , Y(T); Ŷ(0),Ŷ(1), ... , Ŷ(T)) (donde Y(i) es el ith objetivo, Ŷ(i) es la ith predicción y T es el paso de tiempo máximo). Tenga en cuenta que esta función de pérdida puede ignorar algunas salidas. Por ejemplo, en un RNN de secuencia a vector, todas las salidas se ignoran, excepto la última. En la Figura 15-5, la función de pérdida se calcula basándose solo en las tres últimas salidas. Los gradientes de esa función de pérdida se propagan hacia atrás a través de la red desenrollada (representada por las flechas sólidas). En este ejemplo, dado que las salidas Ŷ(0) y Ŷ(1) no se utilizan para calcular la pérdida, los gradientes no fluyen hacia atrás a través de ellas; solo fluyen a través de Ŷ(2), Ŷ(3) y Ŷ(4). Además, dado que se utilizan los mismos parámetros W y b en cada paso de tiempo, sus gradientes se ajustarán varias veces durante el backprop. Una vez que se ha completado la fase de retroceso y se han calculado todos los gradientes, BPTT puede realizar un paso de descenso de gradiente para actualizar los parámetros (esto no es diferente del backprop normal).\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1505.png)\n",
    "\n",
    "(_Figura 15-5. Retropropagación a través del tiempo_)\n",
    "\n",
    "Afortunadamente, Keras se encarga de toda esta complejidad por ti, como verás. Pero antes de llegar allí, carguemos una serie temporal y comencemos a analizarla utilizando herramientas clásicas para entender mejor con lo que estamos tratando y para obtener algunas métricas de referencia.\n",
    "\n",
    "\n",
    "# Pronostico de una serie de tiempo\n",
    "\n",
    "\n",
    "¡Muy bien! Finjamos que acabas de ser contratado como científico de datos por la Autoridad de Tránsito de Chicago. Su primera tarea es construir un modelo capaz de pronosticar el número de pasajeros que viajarán en autobús y tren al día siguiente. Tienes acceso a los datos de pasajeros diarios desde 2001. Vamos a ver juntos cómo manejarías esto. Comenzaremos cargando y limpiando los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"datasets/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv\")\n",
    "df = pd.read_csv(path, parse_dates=[\"service_date\"])\n",
    "df.columns = [\"date\", \"day_type\", \"bus\", \"rail\", \"total\"]  # shorter names\n",
    "df = df.sort_values(\"date\").set_index(\"date\")\n",
    "df = df.drop(\"total\", axis=1)  # no need for total, it's just bus + rail\n",
    "df = df.drop_duplicates()  # remove duplicated months (2011-10 and 2014-07)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b1e79a",
   "metadata": {},
   "source": [
    "Cargamos el archivo CSV, establecemos nombres de columna cortos, ordenamos las filas por fecha, eliminamos la columna `total` redundante y eliminamos las filas duplicadas. Ahora veamos cómo se ven las primeras filas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "'''\n",
    "           day_type     bus    rail\n",
    "date\n",
    "2001-01-01        U  297192  126455\n",
    "2001-01-02        W  780827  501952\n",
    "2001-01-03        W  824923  536432\n",
    "2001-01-04        W  870021  550011\n",
    "2001-01-05        W  890426  557917\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989737d",
   "metadata": {},
   "source": [
    "El 1 de enero de 2001, 297.192 personas subieron a un autobús en Chicago y 126.455 subieron a un tren. La columna `day_type` contiene `W` para días laborables, `A` para sábados y `U` para domingos o festivos.\n",
    "\n",
    "Ahora tracemos las cifras de pasajeros de autobuses y trenes a lo largo de unos pocos meses en 2019, para ver cómo se ve (ver Figura 15-6):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981187fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"2019-03\":\"2019-05\"].plot(grid=True, marker=\".\", figsize=(8, 3.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f3bc04",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1506.png)\n",
    "\n",
    "(_Figura 15-6. Aconiteración diaria en Chicago_)\n",
    "\n",
    "Tenga en cuenta que Pandas incluye tanto el mes de inicio como el final en el rango, por lo que esto traza los datos desde el 1 de marzo hasta el 31 de mayo. Esta es una serie temporal: datos con valores en diferentes pasos de tiempo, generalmente a intervalos regulares. Más específicamente, dado que hay múltiples valores por paso de tiempo, esto se llama serie de tiempo multivariable. Si solo miráramos la columna del `bus`, sería una serie temporal univariable, con un solo valor por paso de tiempo. La predicción de valores futuros (es decir, la previsión) es la tarea más típica cuando se trata de series temporales, y esto es en lo que nos centraremos en este capítulo. Otras tareas incluyen la imputación (relleno de los valores pasados que faltan), la clasificación, la detección de anomalías y más.\n",
    "\n",
    "Mirando la Figura 15-6, podemos ver que un patrón similar se repite claramente cada semana. Esto se llama estacionalidad semanal. De hecho, es tan fuerte en este caso que pronosticar el número de pasajeros de mañana con solo copiar los valores de una semana antes dará resultados razonablemente buenos. Esto se llama pronóstico ingenuo: simplemente copiar un valor pasado para hacer nuestro pronóstico. El pronóstico ingenuo es a menudo una gran línea de base, e incluso puede ser difícil de superar en algunos casos.\n",
    "\n",
    "#### NOTA\n",
    "\n",
    "En general, el pronóstico ingenuo significa copiar el último valor conocido (por ejemplo, pronosticar que mañana será el mismo que hoy). Sin embargo, en nuestro caso, copiar el valor de la semana anterior funciona mejor, debido a la fuerte estacionalidad semanal.\n",
    "\n",
    "#### ---------------------------------------------------------------------------------\n",
    "\n",
    "Para visualizar estos pronósticos ingenuos, superpongamos las dos series temporales (para autobús y ferrocarril), así como la misma serie temporal con un retraso de una semana (es decir, desplazada hacia la derecha) usando líneas de puntos. También trazaremos la diferencia entre los dos (es decir, el valor en el momento t menos el valor en el momento t - 7); esto se llama diferenciación (ver Figura 15-7):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_7 = df[[\"bus\", \"rail\"]].diff(7)[\"2019-03\":\"2019-05\"]\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(8, 5))\n",
    "df.plot(ax=axs[0], legend=False, marker=\".\")  # original time series\n",
    "df.shift(7).plot(ax=axs[0], grid=True, legend=False, linestyle=\":\")  # lagged\n",
    "diff_7.plot(ax=axs[1], grid=True, marker=\".\")  # 7-day difference time series\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47017c8f",
   "metadata": {},
   "source": [
    "¡No está tan mal! Observe qué tan de cerca la serie de tiempo retrasada rastrea la serie de tiempo real. Cuando una serie temporal se correlaciona con una versión con retaso de sí misma, decimos que la serie temporal está autocorrelacionada. Como puede ver, la mayoría de las diferencias son bastante pequeñas, excepto a finales de mayo. ¿Tal vez había un día festivo en ese momento? Revisemos la columna `day_type`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.loc[\"2019-05-25\":\"2019-05-27\"][\"day_type\"])\n",
    "\n",
    "'''\n",
    "['A', 'U', 'U']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad618d89",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1507.png)\n",
    "\n",
    "(_Figura 15-7. Serie temporal superperada con una serie temporal con un reso de 7 días (arriba) y la diferencia entre t y t - 7 (abajo)_)\n",
    "\n",
    "De hecho, hubo un fin de semana largo en ese entonces: el lunes era el día festivo del Día de los Caídos. Podríamos usar esta columna para mejorar nuestros pronósticos, pero por ahora solo medimos el error absoluto medio durante el período de tres meses en el que nos estamos centrando arbitrariamente (marzo, abril y mayo de 2019) para tener una idea aproximada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aad4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_7.abs().mean()\n",
    "\n",
    "'''\n",
    "bus     43915.608696\n",
    "rail    42143.271739\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3313811",
   "metadata": {},
   "source": [
    "Nuestros pronósticos ingenuos obtienen un MAE de alrededor de 43.916 pasaños de autobús y alrededor de 42.143 pasajueros de tren. Es difícil decir de un vistazo lo bueno o malo que es esto, así que pongamos los errores de pronóstico en perspectiva dividiéndolos por los valores objetivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc737f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df[[\"bus\", \"rail\"]][\"2019-03\":\"2019-05\"]\n",
    "(diff_7 / targets).abs().mean()\n",
    "\n",
    "'''\n",
    "bus     0.082938\n",
    "rail    0.089948\n",
    "dtype: float64\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf5e2da",
   "metadata": {},
   "source": [
    "Lo que acabamos de calcular se llama el error porcentual absoluto medio (MAPE): parece que nuestros pronósticos ingenuos nos dan un MAPE de aproximadamente el 8,3 % para el autobús y el 9,0 % para el ferrocarril. Es interesante tener en cuenta que el MAE para los pronósticos ferroviarios se ve ligeramente mejor que el MAE para los pronósticos de autobuses, mientras que lo contrario es cierto para el MAPE. Eso se debe a que el número de pasajeros de autobuses es mayor que el número de pasajeros de trenes, por lo que, naturalmente, los errores de pronóstico también son mayores, pero cuando ponemos los errores en perspectiva, resulta que los pronósticos de autobuses son en realidad un poco mejores que los pronósticos ferroviarios.\n",
    "\n",
    "\n",
    "#### TIP\n",
    "\n",
    "El MAE, el MAPE y el MSE se encuentran entre las métricas más comunes que puede utilizar para evaluar sus pronósticos. Como siempre, elegir la métrica correcta depende de la tarea. Por ejemplo, si su proyecto sufre cuadráticamente más de errores grandes que de pequeños, entonces el MSE puede ser preferible, ya que penaliza fuertemente los errores grandes.\n",
    "\n",
    "#### ----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Mirando la serie temporal, no parece haber ninguna estacionalidad mensual significativa, pero comprobemos si hay alguna estacionalidad anual. Analtaremos los datos de 2001 a 2019. Para reducir el riesgo de espionaje de datos, ignoraremos los datos más recientes por ahora. También tracemos un promedio móvil de 12 meses para cada serie para visualizar las tendencias a largo plazo (ver Figura 15-8):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8071eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = slice(\"2001\", \"2019\")\n",
    "df_monthly = df.resample('M').mean()  # compute the mean for each month\n",
    "rolling_average_12_months = df_monthly[period].rolling(window=12).mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "df_monthly[period].plot(ax=ax, marker=\".\")\n",
    "rolling_average_12_months.plot(ax=ax, grid=True, legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc87b903",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1508.png)\n",
    "\n",
    "(_Figura 15-8. Estacionalidad anual y tendencias a largo plazo_)\n",
    "\n",
    "¡Sí! Definitivamente también hay algo de estacionalidad anual, aunque es más ruidosa que la estacionalidad semanal, y más visible para la serie de trenes que para la serie de autobuses: vemos picos y baños en aproximadamente las mismas fechas cada año. Vamos a comprobar lo que obtenemos si trazamos la diferencia de 12 meses (ver Figura 15-9):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88318bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly.diff(12)[period].plot(grid=True, marker=\".\", figsize=(8, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a47ec",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1509.png)\n",
    "\n",
    "(_Figura 15-9. La diferencia de 12 meses_)\n",
    "\n",
    "Observe cómo la diferenciación no solo eliminó la estacionalidad anual, sino que también eliminó las tendencias a largo plazo. Por ejemplo, la tendencia lineal a la baja presente en las series temporales de 2016 a 2019 se convirtió en un valor negativo aproximadamente constante en las series temporales diferenciadas. De hecho, la diferenciación es una técnica común utilizada para eliminar la tendencia y la estacionalidad de una serie temporal: es más fácil estudiar una serie temporal estacionaria, es decir, una cuyas propiedades estadísticas permanecen constantes a lo largo del tiempo, sin ninguna estacionalidad o tendencias. Una vez que puedas hacer pronósticos precisos sobre las series temporales diferenciadas, es fácil convertirlos en pronósticos para la serie temporal real simplemente agregando los valores pasados que se restaron anteriormente.\n",
    "\n",
    "Puede que estés pensando que solo estamos tratando de predecir el número de pasajeros del mañana, por lo que los patrones a largo plazo importan mucho menos que los a corto plazo. Tienes razón, pero aún así, es posible que podamos mejorar ligeramente el rendimiento teniendo en cuenta los patrones a largo plazo. Por ejemplo, el número diario de pasajeros en autobuses se redujo en unos 2.500 en octubre de 2017, lo que representa alrededor de 570 pasajeros menos cada semana, por lo que si estuviéramos a finales de octubre de 2017, tendría sentido pronosticar el número de pasajeros de mañana copiando el valor de la semana pasada, menos 570. La contabilidad de la tendencia hará que sus pronósticos sean un poco más precisos en promedio.\n",
    "\n",
    "Ahora que está familiarizado con las series temporales de pasajeros, así como con algunos de los conceptos más importantes en el análisis de series temporales, incluyendo la estacionalidad, la tendencia, la diferenciación y los promedios móviles, echemos un vistazo rápido a una familia muy popular de modelos estadísticos que se utilizan comúnmente para analizar series temporales.\n",
    "\n",
    "\n",
    "## La familia de modelos ARMA\n",
    "\n",
    "Comenzaremos con el modelo de promedio móvil autorregresivo (ARMA), desarrollado por Herman Wold en la década de 1930: calcula sus pronósticos utilizando una simple suma ponderada de valores retrasados y corrige estos pronósticos agregando un promedio móvil, muy similar al que acabamos de discutir. Específicamente, el componente de la media móvil se calcula utilizando una suma ponderada de los últimos errores de pronóstico. La ecuación 15-3 muestra cómo el modelo hace sus pronósticos.\n",
    "\n",
    "### Ecuación 15-3. Pronóstico utilizando un modelo ARMA\n",
    "\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/yyzym2V/Captura-de-pantalla-2024-03-24-a-las-3-43-34.png\" alt=\"Captura-de-pantalla-2024-03-24-a-las-3-43-34\" border=\"0\"></a>\n",
    "\n",
    "\n",
    "En esta ecuación:\n",
    "\n",
    "- **ŷ(t)** es el pronóstico del modelo para el paso de tiempo t.\n",
    "\n",
    "* **y(t)** es el valor de la serie temporal en el paso de tiempo t.\n",
    "\n",
    "- La primera suma es la suma ponderada de los últimos valores de p de la serie temporal, utilizando los pesos aprendidos αi. El número p es un hiperparámetro, y determina hasta qué punto en el pasado debería verse el modelo. Esta suma es el componente autorregresivo del modelo: realiza una regresión basada en valores pasados.\n",
    "\n",
    "* La segunda suma es la suma ponderada sobre los últimos errores de pronóstico qε(t), utilizando los pesos aprendidos θi. El número q es un hiperparámetro. Esta suma es el componente de la media móvil del modelo.\n",
    "\n",
    "Es importante destacar que este modelo asume que la serie temporal es estacionaria. Si no lo es, entonces la diferenciación puede ayudar. El uso de la diferenciación en un solo paso de tiempo producirá una aproximación de la derivada de la serie de tiempo: de hecho, dará la pendiente de la serie en cada paso de tiempo. Esto significa que eliminará cualquier tendencia lineal, transformándola en un valor constante. Por ejemplo, si aplicas la diferenciación de un solo paso a la serie [3, 5, 7, 9, 11], obtienes la serie diferenciada [2, 2, 2, 2].\n",
    "\n",
    "Si la serie temporal original tiene una tendencia cuadrática en lugar de una tendencia lineal, entonces una sola ronda de diferenciación no será suficiente. Por ejemplo, la serie [1, 4, 9, 16, 25, 36] se convierte en [3, 5, 7, 9, 11] después de una ronda de diferenciación, pero si ejecutas la diferenciación para una segunda ronda, entonces obtienes [2, 2, 2, 2]. Por lo tanto, ejecutar dos rondas de diferenciación eliminará las tendencias cuadráticas. De manera más general, ejecutar d rondas consecutivas de diferenciación calcula una aproximación de la derivada de orden dth de la serie temporal, por lo que eliminará las tendencias polinómicas hasta el grado d. Este hiperparámetro d se llama orden de integración.\n",
    "\n",
    "La diferenciación es la contribución central del modelo de media móvil integrada autorregresiva (ARIMA), introducido en 1970 por George Box y Gwilym Jenkins en su libro Time Series Analysis (Wiley): este modelo ejecuta rondas de diferenciación para hacer que la serie temporal sea más estacionaria, luego aplica un modelo ARMA regular. Al hacer pronósticos, utiliza este modelo ARMA, luego agrega los términos que se restaron mediante la diferenciación.\n",
    "\n",
    "Un último miembro de la familia ARMA es el modelo estacional de ARIMA (SARIMA): modela la serie temporal de la misma manera que ARIMA, pero además modela un componente estacional para una frecuencia determinada (por ejemplo, semanal), utilizando exactamente el mismo enfoque de ARIMA. Tiene un total de siete hiperparámetros: los mismos hiperparámetros p, d y q que ARIMA, más hiperparámetros adicionales de P, D y Q para modelar el patrón estacional y, por último, el período del patrón estacional, señaló s. Los hiperparámetros P, D y Q son como p, d y q, pero se utilizan para modelar las series temporales en t - s, t - 2s, t - 3s, etc.\n",
    "\n",
    "Veamos cómo encajar un modelo de SARIMA en la serie de tiempo de ferrocarril, y usémoslo para hacer un pronóstico para el número de pasajeros de mañana. Fingiremos que hoy es el último día de mayo de 2019, y queremos pronosticar el número de pasajeros ferroviarios para \"mañana\", el 1 de junio de 2019. Para esto, podemos utilizar la biblioteca `statsmodels`, que contiene muchos modelos estadísticos diferentes, incluido el modelo ARMA y sus variantes, implementados por la clase `ARIMA`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "origin, today = \"2019-01-01\", \"2019-05-31\"\n",
    "rail_series = df.loc[origin:today][\"rail\"].asfreq(\"D\")\n",
    "model = ARIMA(rail_series,\n",
    "              order=(1, 0, 0),\n",
    "              seasonal_order=(0, 1, 1, 7))\n",
    "model = model.fit()\n",
    "y_pred = model.forecast()  # returns 427,758.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3817f34c",
   "metadata": {},
   "source": [
    "En este ejemplo de código:\n",
    "\n",
    "- Comenzamos importando la clase `ARIMA`, luego tomamos los datos de uso de trenes desde principios de 2019 hasta \"hoy\" y usamos `asfreq(\"D\")` para establecer la frecuencia de la serie temporal en diaria: esto no cambie los datos en este caso, ya que ya son diarios, pero sin esto la clase `ARIMA` tendría que adivinar la frecuencia y mostraría una advertencia.\n",
    "\n",
    "* A continuación, creamos una instancia `ARIMA`, pasándole todos los datos hasta “hoy”, y configuramos los hiperparámetros del modelo: `order=(1, 0, 0)` significa que p = 1, d = 0, q = 0, y `seasonal_order=(0, 1, 1, 7)` significa que P = 0, D = 1, Q = 1 y s = 7. Observe que la API de `statsmodels` difiere un poco de la API de Scikit-Learn, ya que pasamos los datos a el modelo en el momento de la construcción, en lugar de pasarlo al método `fit()`.\n",
    "\n",
    "- A continuación, ajustamos el modelo, y lo usamos para hacer un pronóstico para \"mañana\", el 1 de junio de 2019.\n",
    "\n",
    "El pronóstico es de 427.759 pasajeros, cuando en realidad había 379.044. Vaya, tenemos un 12,9 % de descuento, eso es bastante malo. En realidad, es un poco peor que el pronóstico ingenuo, que pronostica 426.932, con un descuento del 12,6 %. ¿Pero tal vez tuvimos mala suerte ese día? Para comprobar esto, podemos ejecutar el mismo código en un bucle para hacer pronósticos para todos los días de marzo, abril y mayo, y calcular el MAE durante ese período:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a969c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin, start_date, end_date = \"2019-01-01\", \"2019-03-01\", \"2019-05-31\"\n",
    "time_period = pd.date_range(start_date, end_date)\n",
    "rail_series = df.loc[origin:end_date][\"rail\"].asfreq(\"D\")\n",
    "y_preds = []\n",
    "for today in time_period.shift(-1):\n",
    "    model = ARIMA(rail_series[origin:today],  # train on data up to \"today\"\n",
    "                  order=(1, 0, 0),\n",
    "                  seasonal_order=(0, 1, 1, 7))\n",
    "    model = model.fit()  # note that we retrain the model every day!\n",
    "    y_pred = model.forecast()[0]\n",
    "    y_preds.append(y_pred)\n",
    "\n",
    "y_preds = pd.Series(y_preds, index=time_period)\n",
    "mae = (y_preds - rail_series[time_period]).abs().mean()  # returns 32,040.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a39d1f",
   "metadata": {},
   "source": [
    "¡Ah, eso es mucho mejor! El MAE es de aproximadamente 32,041, que es significativamente más bajo que el MAE que obtuvimos con el pronóstico ingenuo (42.143). Así que, aunque el modelo no es perfecto, todavía supera a la previsión ingenua por un gran margen, en promedio.\n",
    "\n",
    "En este punto, es posible que te preguntes cómo elegir buenos hiperparámetros para el modelo SARIMA. Hay varios métodos, pero el más fácil de entender y con el que empezar es el enfoque de fuerza bruta: simplemente ejecuta una búsqueda en cuadrícula. Para cada modelo que desee evaluar (es decir, cada combinación de hiperparámetros), puede ejecutar el ejemplo de código anterior, cambiando solo los valores de los hiperparámetros. Los valores buenos de p, q, P y Q suelen ser bastante pequeños (típicamente de 0 a 2, a veces hasta 5 o 6), y d y D suelen ser de 0 o 1, a veces 2. En cuanto a s, es solo el período del patrón estacional principal: en nuestro caso son 7 ya que hay una fuerte estacionalidad semanal. El modelo con el MAE más bajo gana. Por supuesto, puede reemplazar el MAE con otra métrica si se ajusta mejor a su objetivo comercial. ¡Y eso es todo!\n",
    "\n",
    "\n",
    "## Preparación de los datos para modelos de aprendizaje automático\n",
    "\n",
    "\n",
    "Ahora que tenemos dos líneas de base, la previsión ingenua y SARIMA, intentemos usar los modelos de aprendizaje automático que hemos cubierto hasta ahora para pronosticar esta serie temporal, comenzando con un modelo lineal básico. Nuestro objetivo será pronosticar el número de pasajeros de mañana en función del número de pasajeros de las últimas 8 semanas de datos (56 días). Por lo tanto, las entradas a nuestro modelo serán secuencias (generalmente una sola secuencia por día una vez que el modelo está en producción), cada una de las cuales contiene 56 valores de los pasos de tiempo t - 55 a t. Para cada secuencia de entrada, el modelo mostrará un solo valor: el pronóstico para el paso de tiempo t + 1.\n",
    "\n",
    "Pero, ¿qué usaremos como datos de entrenamiento? Bueno, ese es el truco: usaremos cada ventana de 56 días del pasado como datos de entrenamiento, y el objetivo de cada ventana será el valor inmediatamente después de ella.\n",
    "\n",
    "Keras en realidad tiene una función de utilidad interesante llamada `tf.keras.utils.timeseries_data⁠set_from_array()` para ayudarnos a preparar el conjunto de entrenamiento. Toma una serie de tiempo como entrada y crea un tf.data.Dataset (presentado en el Capítulo 13) que contiene todas las ventanas de la longitud deseada, así como sus objetivos correspondientes. A continuación se muestra un ejemplo que toma una serie de tiempo que contiene los números del 0 al 5 y crea un conjunto de datos que contiene todas las ventanas de longitud 3, con sus objetivos correspondientes, agrupados en lotes de tamaño 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "my_series = [0, 1, 2, 3, 4, 5]\n",
    "my_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    my_series,\n",
    "    targets=my_series[3:],  # the targets are 3 steps into the future\n",
    "    sequence_length=3,\n",
    "    batch_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b42ef",
   "metadata": {},
   "source": [
    "Inspeccionemos el contenido de este conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db73ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(my_dataset)\n",
    "\n",
    "'''\n",
    "[(<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
    "  array([[0, 1, 2],\n",
    "         [1, 2, 3]], dtype=int32)>,\n",
    "  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 4], dtype=int32)>),\n",
    " (<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[2, 3, 4]], dtype=int32)>,\n",
    "  <tf.Tensor: shape=(1,), dtype=int32, numpy=array([5], dtype=int32)>)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c42822",
   "metadata": {},
   "source": [
    "Cada muestra en el conjunto de datos es una ventana de longitud 3, junto con su objetivo correspondiente (es decir, el valor inmediatamente después de la ventana). Las ventanas son [0, 1, 2], [1, 2, 3] y [2, 3, 4], y sus respectivos objetivos son 3, 4 y 5. Dado que hay tres ventanas en total, que no es un múltiplo del tamaño del lote, el último lote solo contiene una ventana en lugar de dos.\n",
    "\n",
    "Otra forma de obtener el mismo resultado es utilizar el método `window()` de la clase `Dataset` de tf.data. Es más complejo, pero le brinda control total, lo que le resultará útil más adelante en este capítulo, así que veamos cómo funciona. El método `window()` devuelve un conjunto de datos de conjuntos de datos de ventana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52855262",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_dataset in tf.data.Dataset.range(6).window(4, shift=1):\n",
    "    for element in window_dataset:\n",
    "        print(f\"{element}\", end=\" \")\n",
    "    print()\n",
    "\n",
    "'''\n",
    "0 1 2 3\n",
    "1 2 3 4\n",
    "2 3 4 5\n",
    "3 4 5\n",
    "4 5\n",
    "5\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d44f1d",
   "metadata": {},
   "source": [
    "En este ejemplo, el conjunto de datos contiene seis ventanas, cada una desplazada un paso en comparación con la anterior, y las últimas tres ventanas son más pequeñas porque han llegado al final de la serie. En general, querrás deshacerte de estas ventanas más pequeñas pasando `drop_remainder=True` al método `window()`.\n",
    "\n",
    "El método `window()` devuelve un conjunto de datos anidado, análogo a una lista de listas. Esto es útil cuando desea transformar cada ventana llamando a sus métodos de conjunto de datos (por ejemplo, para mezclarlos o agruparlos). Sin embargo, no podemos usar un conjunto de datos anidado directamente para el entrenamiento, ya que nuestro modelo esperará tensores como entrada, no conjuntos de datos.\n",
    "\n",
    "Por lo tanto, debemos llamar al método `flat_map()`: convierte un conjunto de datos anidado en un conjunto de datos plano (uno que contiene tensores, no conjuntos de datos). Por ejemplo, supongamos que {1, 2, 3} representa un conjunto de datos que contiene la secuencia de tensores 1, 2 y 3. Si aplana el conjunto de datos anidado {{1, 2}, {3, 4, 5, 6}}, recuperará el conjunto de datos planos {1, 2, 3, 4, 5, 6}.\n",
    "\n",
    "Además, el método `flat_map()` toma una función como argumento, lo que le permite transformar cada conjunto de datos en el conjunto de datos anidado antes de aplanarlo. Por ejemplo, si pasa la función `lambda ds`: `ds.batch(2)` a `flat_map()`, transformará el conjunto de datos anidado {{1, 2}, {3, 4, 5, 6}} en el conjunto de datos plano {[1, 2], [3, 4], [5, 6]}: es un conjunto de datos que contiene 3 tensores, cada uno de tamaño 2.\n",
    "\n",
    "Con eso en mente, estamos listos para aplanar nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbdab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(6).window(4, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window_dataset: window_dataset.batch(4))\n",
    "for window_tensor in dataset:\n",
    "    print(f\"{window_tensor}\")\n",
    "\n",
    "'''\n",
    "[0 1 2 3]\n",
    "[1 2 3 4]\n",
    "[2 3 4 5]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b827ce",
   "metadata": {},
   "source": [
    "Dado que cada conjunto de datos de ventana contiene exactamente cuatro elementos, llamar al `batch(4)` en una ventana produce un único tensor de tamaño 4. ¡Genial! Ahora tenemos un conjunto de datos que contiene ventanas consecutivas representadas como tensores. Creemos una pequeña función auxiliar para que sea más fácil extraer ventanas de un conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cdea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_windows(dataset, length):\n",
    "    dataset = dataset.window(length, shift=1, drop_remainder=True)\n",
    "    return dataset.flat_map(lambda window_ds: window_ds.batch(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b6c60",
   "metadata": {},
   "source": [
    "El último paso es dividir cada ventana en entradas y objetivos, utilizando el método themap `map()`. También podemos agrupar las ventanas resultantes en lotes de tamaño 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1032793",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = to_windows(tf.data.Dataset.range(6), 4)  # 3 inputs + 1 target = 4\n",
    "dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "list(dataset.batch(2))\n",
    "\n",
    "'''\n",
    "[(<tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
    "  array([[0, 1, 2],\n",
    "         [1, 2, 3]])>,\n",
    "  <tf.Tensor: shape=(2,), dtype=int64, numpy=array([3, 4])>),\n",
    " (<tf.Tensor: shape=(1, 3), dtype=int64, numpy=array([[2, 3, 4]])>,\n",
    "  <tf.Tensor: shape=(1,), dtype=int64, numpy=array([5])>)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201f6050",
   "metadata": {},
   "source": [
    "Como puede ver, ahora tenemos el mismo resultado que obtuvimos antes con la función `timeseries_dataset_from_array()` (con un poco más de esfuerzo, pero pronto valdrá la pena).\n",
    "\n",
    "Ahora, antes de comenzar la capacitación, necesitamos dividir nuestros datos en un período de capacitación, un período de validación y un período de prueba. Por ahora, nos centraremos en el número de pasajeros ferroviarios. También lo reduciremos en un factor de un millón, para asegurarnos de que los valores estén cerca del rango 0-1; esto juega muy bien con la inicialización de peso por defecto y la tasa de aprendizaje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_train = df[\"rail\"][\"2016-01\":\"2018-12\"] / 1e6\n",
    "rail_valid = df[\"rail\"][\"2019-01\":\"2019-05\"] / 1e6\n",
    "rail_test = df[\"rail\"][\"2019-06\":] / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7dcb08",
   "metadata": {},
   "source": [
    "#### NOTA\n",
    "\n",
    "Cuando se trata de series temporales, generalmente quieres dividirte en el tiempo. Sin embargo, en algunos casos es posible que pueda dividirse a lo largo de otras dimensiones, lo que le dará un período de tiempo más largo para entrenar. Por ejemplo, si tiene datos sobre la salud financiera de 10.000 empresas de 2001 a 2019, es posible que pueda dividir estos datos entre las diferentes empresas. Sin embargo, es muy probable que muchas de estas empresas estén fuertemente correlacionadas (por ejemplo, sectores económicos enteros pueden subir o bajar conjuntamente), y si tiene empresas correlacionadas a través del conjunto de capacitación y el conjunto de pruebas, su conjunto de pruebas no será tan útil, ya que su medida del error de generalización estará sesgada de manera optimista.\n",
    "\n",
    "#### ----------------------------------------------------------------------------------\n",
    "\n",
    "A continuación, usemos `timeseries_dataset_from_array()` para crear conjuntos de datos para entrenamiento y validación. Dado que el descenso de gradiente espera que las instancias en el conjunto de entrenamiento sean independientes y estén distribuidas de manera idéntica (IID), como vimos en el Capítulo 4, debemos establecer el argumento `shuffle=True` para mezclar las ventanas de entrenamiento (pero no su contenido):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 56\n",
    "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    rail_train.to_numpy(),\n",
    "    targets=rail_train[seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    rail_valid.to_numpy(),\n",
    "    targets=rail_valid[seq_length:],\n",
    "    sequence_length=seq_length,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb26efe",
   "metadata": {},
   "source": [
    "¡Y ahora estamos listos para construir y entrenar cualquier modelo de regresión que queramos!\n",
    "\n",
    "## Pronóstico utilizando un modelo lineal\n",
    "\n",
    "Primero intentemos un modelo lineal básico. Utilizaremos la pérdida de Huber, que generalmente funciona mejor que minimizar el MAE directamente, como se discute en el capítulo 10. También usaremos la parada temprana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a73c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=[seq_length])\n",
    "])\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_mae\", patience=50, restore_best_weights=True)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(), optimizer=opt, metrics=[\"mae\"])\n",
    "history = model.fit(train_ds, validation_data=valid_ds, epochs=500,\n",
    "                    callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6431ce24",
   "metadata": {},
   "source": [
    "Este modelo alcanza un MAE de validación de aproximadamente 37 866 (su kilometraje puede variar). Eso es mejor que un pronóstico ingenuo, pero peor que el modelo SARIMA.\n",
    "\n",
    "¿Podemos hacerlo mejor con un RNN? ¡Vamos a ver!\n",
    "\n",
    "## Pronóstico usando un RNN simple\n",
    "\n",
    "Vamos a probar el RNN más básico, que contiene una sola capa recurrente con una sola neurona recurrente, como vimos en la Figura 15-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c419a5a",
   "metadata": {},
   "source": [
    "Todas las capas recurrentes en Keras esperan entradas 3D de forma [tamaño de lote, pasos de tiempo, dimensionalidad], donde la dimensionalidad es 1 para series temporales univariadas y más para series temporales multivariadas. Recuerde que el argumento input_shape ignora la primera dimensión (es decir, el tamaño del lote) y, dado que las capas recurrentes pueden aceptar secuencias de entrada de cualquier longitud, podemos establecer la segunda dimensión en `None`, que significa \"cualquier tamaño\". Por último, dado que estamos tratando con una serie de tiempo univariada, necesitamos que el tamaño de la última dimensión sea 1. Es por eso que especificamos la forma de entrada `[None, 1]`: significa \"secuencias univariadas de cualquier longitud\". Tenga en cuenta que los conjuntos de datos en realidad contienen entradas de forma [tamaño de lote, pasos de tiempo], por lo que nos falta la última dimensión, de tamaño 1, pero Keras tiene la amabilidad de agregarla en este caso.\n",
    "\n",
    "Este modelo funciona exactamente como vimos anteriormente: el estado inicial h(init) se establece en 0, y se pasa a una sola neurona recurrente, junto con el valor del primer paso de tiempo, x(0). La neurona calcula una suma ponderada de estos valores más el término de sesgo, y aplica la función de activación al resultado, utilizando la función tangente hiperbólica de forma predeterminada. El resultado es la primera salida, y0. En un RNN simple, esta salida también es el nuevo estado h0. Este nuevo estado se pasa a la misma neurona recurrente junto con el siguiente valor de entrada, x(1), y el proceso se repite hasta el último paso de tiempo. Al final, la capa solo muestra el último valor: en nuestro caso, las secuencias tienen 56 pasos de largo, por lo que el último valor es y55. Todo esto se realiza simultáneamente para cada secuencia del lote, de las cuales hay 32 en este caso.\n",
    "\n",
    "#### NOTA\n",
    "\n",
    "De forma predeterminada, las capas recurrentes en Keras solo devuelven la salida final. Para que devuelvan una salida por paso de tiempo, debe establecer `return_sequences=True`, como verá.\n",
    "\n",
    "#### ----------------------------------------------------------------------------------\n",
    "\n",
    "¡Así que ese es nuestro primer modelo recurrente! Es un modelo de secuencia a vector. Dado que hay una sola neurona de salida, el vector de salida tiene un tamaño de 1.\n",
    "\n",
    "Ahora, si compilas, entrenas y evalúas este modelo al igual que el modelo anterior, encontrarás que no es bueno en absoluto: ¡su validación MAE es superior a 100.000! Ay. Eso era de esperar, por dos razones:\n",
    "\n",
    "1. El modelo solo tiene una sola neurona recurrente, por lo que los únicos datos que puede usar para hacer una predicción en cada paso de tiempo son el valor de entrada en el paso de tiempo actual y el valor de salida del paso de tiempo anterior. ¡Eso no es mucho para hacer! En otras palabras, la memoria del RNN es extremadamente limitada: es solo un solo número, su salida anterior. Y contemos cuántos parámetros tiene este modelo: ya que solo hay una neurona recurrente con solo dos valores de entrada, todo el modelo solo tiene tres parámetros (dos pesos más un término de sesgo). Eso está lejos de ser suficiente para esta serie temporal. Por el contrario, nuestro modelo anterior podía ver los 56 valores anteriores a la vez, y tenía un total de 57 parámetros.\n",
    "\n",
    "2. La serie temporal contiene valores de 0 a aproximadamente 1,4, pero dado que la función de activación predeterminada es tanh, la capa recurrente solo puede generar valores entre -1 y +1. No hay forma de que pueda predecir valores entre 1.0 y 1.4.\n",
    "\n",
    "Vamos a solucionar ambos problemas: crearemos un modelo con una capa recurrente más grande, que contiene 32 neuronas recurrentes, y añadiremos una capa de salida densa encima con una sola neurona de salida y sin función de activación. La capa recurrente podrá transportar mucha más información de un paso a otro, y la capa de salida densa proyectará la salida final desde 32 dimensiones hasta 1, sin ninguna restricción de rango de valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61941a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "univar_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 1]),\n",
    "    tf.keras.layers.Dense(1)  # no activation function by default\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ef78f",
   "metadata": {},
   "source": [
    "Ahora, si compilas, ajustas y evalúas este modelo al igual que el anterior, encontrarás que su MAE de validación alcanza los 27.703. Ese es el mejor modelo que hemos entrenado hasta ahora, e incluso supera al modelo SARIMA: ¡lo estamos haciendo bastante bien!\n",
    "\n",
    "#### PROPINA\n",
    "\n",
    "Solo hemos normalizado las series temporales, sin eliminar la tendencia y la estacionalidad, y sin embargo, el modelo sigue teniendo un buen rendimiento. Esto es conveniente, ya que permite buscar rápidamente modelos prometedores sin preocuparse demasiado por el preprocesamiento. Sin embargo, para obtener el mejor rendimiento, es posible que desee intentar hacer que la serie temporal sea más estacionaria; por ejemplo, usando la diferenciación.\n",
    "\n",
    "#### ---------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "## Pronóstico usando un RNN profundo\n",
    "\n",
    "\n",
    "Es bastante común apilar múltiples capas de células, como se muestra en la Figura 15-10. Esto te da un RNN profundo.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1510.png)\n",
    "\n",
    "(_Figura 15-10. Un RNN profundo (izquierda) desenrollado a través del tiempo (derecha)_)\n",
    "\n",
    "Implementar un RNN profundo con Keras es sencillo: simplemente apile capas recurrentes. En el siguiente ejemplo, usamos tres capas `SimpleRNN` (pero podríamos usar cualquier otro tipo de capa recurrente, como una capa `LSTM` o una capa `GRU`, que discutiremos en breve). Las dos primeras son capas de secuencia a secuencia y la última es una capa de secuencia a vector. Finalmente, la capa `Dense` produce el pronóstico del modelo (puede considerarla como una capa de vector a vector). Entonces, este modelo es igual al modelo representado en la Figura 15-10, excepto que las salidas Ŷ(0) a Ŷ(t–1_) se ignoran y hay una capa densa encima de Ŷ(t), que genera el pronóstico real. :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c59e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 1]),\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(32),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f17a7",
   "metadata": {},
   "source": [
    "#### ADVERTENCIA\n",
    "\n",
    "Asegúrese de configurar `return_sequences=True` para todas las capas recurrentes (excepto la última, si solo le importa la última salida). Si olvida configurar este parámetro para una capa recurrente, generará una matriz 2D que contiene solo la salida del último paso de tiempo, en lugar de una matriz 3D que contiene salidas para todos los pasos de tiempo. La siguiente capa recurrente se quejará de que no le está suministrando secuencias en el formato 3D esperado.\n",
    "\n",
    "#### ---------------------------------------------------------------------------------\n",
    "\n",
    "Si entrenas y evalúas este modelo, encontrarás que alcanza un MAE de alrededor de 31.211. Eso es mejor que ambas líneas de base, pero no supera a nuestro RNN \"más bajo\". Parece que este RNN es un poco demasiado grande para nuestra tarea.\n",
    "\n",
    "## Pronóstico de series temporales multivariantes\n",
    "\n",
    "Una gran calidad de las redes neuronales es su flexibilidad: en particular, pueden lidiar con series temporales multivariadas sin casi ningún cambio en su arquitectura. Por ejemplo, intentemos pronosticar la serie de tiempo de los trenes utilizando tanto los datos del autobús como los del ferrocarril como entrada. De hecho, ¡vamos a incluir también el tipo de día! Dado que siempre podemos saber de antemano si mañana va a ser un día laborable, un fin de semana o un día festivo, podemos cambiar la serie de tipo de día un día hacia el futuro, para que el modelo se dé el tipo de día de mañana como entrada. Para simplificar, haremos este procesamiento usando Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mulvar = df[[\"bus\", \"rail\"]] / 1e6  # use both bus & rail series as input\n",
    "df_mulvar[\"next_day_type\"] = df[\"day_type\"].shift(-1)  # we know tomorrow's type\n",
    "df_mulvar = pd.get_dummies(df_mulvar)  # one-hot encode the day type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1716d3",
   "metadata": {},
   "source": [
    "Ahora `df_mulvar` es un DataFrame con cinco columnas: los datos de autobús y ferrocarril, más tres columnas que contienen la codificación one-hot del tipo del día siguiente (recuerde que hay tres tipos de días posibles, `W`, `A` y `U`). A continuación podemos proceder de forma muy parecida a como lo hicimos antes. Primero dividimos los datos en tres períodos, para entrenamiento, validación y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7397512",
   "metadata": {},
   "outputs": [],
   "source": [
    "mulvar_train = df_mulvar[\"2016-01\":\"2018-12\"]\n",
    "mulvar_valid = df_mulvar[\"2019-01\":\"2019-05\"]\n",
    "mulvar_test = df_mulvar[\"2019-06\":]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36cbeba",
   "metadata": {},
   "source": [
    "Luego creamos los conjuntos de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacc47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_train.to_numpy(),  # use all 5 columns as input\n",
    "    targets=mulvar_train[\"rail\"][seq_length:],  # forecast only the rail series\n",
    "    [...]  # the other 4 arguments are the same as earlier\n",
    ")\n",
    "valid_mulvar_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_valid.to_numpy(),\n",
    "    targets=mulvar_valid[\"rail\"][seq_length:],\n",
    "    [...]  # the other 2 arguments are the same as earlier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8479745c",
   "metadata": {},
   "source": [
    "Y finalmente creamos el RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mulvar_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc6baa",
   "metadata": {},
   "source": [
    "Tenga en cuenta que la única diferencia con el RNN `univar_model` que construimos anteriormente es la forma de la entrada: en cada paso de tiempo, el modelo ahora recibe cinco entradas en lugar de una. De hecho, este modelo alcanza una validación MAE de 22.062. ¡Ahora estamos logrando un gran progreso!\n",
    "\n",
    "De hecho, no es demasiado difícil hacer que RNN pronostique el número de pasajeros tanto en autobús como en tren. Solo necesita cambiar los objetivos al crear los conjuntos de datos, configurándolos en `mulvar_train[[\"bus\", \"rail\"]][seq_length:]` para el conjunto de entrenamiento y `mulvar_valid[[\"bus\", \"rail\"]][ seq_length:]` para el conjunto de validación. También debe agregar una neurona adicional en la capa `Dense` de salida, ya que ahora debe hacer dos pronósticos: uno para el número de viajes en autobús de mañana y el otro para el tren. ¡Eso es todo al respecto!\n",
    "\n",
    "Como discutimos en el capítulo 10, el uso de un solo modelo para múltiples tareas relacionadas a menudo resulta en un mejor rendimiento que el uso de un modelo separado para cada tarea, ya que las características aprendidas para una tarea pueden ser útiles para las otras tareas, y también porque tener que funcionar bien en múltiples tareas evita que el modelo se sobreajuste (es una forma de regularización). Sin embargo, depende de la tarea, y en este caso en particular, el RNN multitarea que pronostica tanto el autobús como el pasajero ferroviario no funciona tan bien como los modelos dedicados que pronostican uno u otro (usando las cinco columnas como entrada). Aún así, alcanza un MAE de validación de 25.330 para el ferrocarril y 26.369 para el autobús, lo cual es bastante bueno.\n",
    "\n",
    "\n",
    "## Pronóstico de varios pasos de tiempo por delante\n",
    "\n",
    "\n",
    "Hasta ahora solo hemos predicho el valor en el siguiente paso de tiempo, pero podríamos haber predicho fácilmente el valor varios pasos por delante cambiando los objetivos adecuadamente (por ejemplo, para predecir el número de pasajeros dentro de 2 semanas, podríamos cambiar los objetivos para que sean el valor con 14 días de anticipación en lugar de 1 día de anticipación). Pero, ¿y si queremos predecir los próximos 14 valores?\n",
    "\n",
    "La primera opción es tomar el RNN `univar_model` que entrenamos anteriormente para la serie temporal del ferrocarril, hacer que prediga el siguiente valor y agregar ese valor a las entradas, actuando como si el valor predicho realmente hubiera ocurrido; Luego usaríamos el modelo nuevamente para predecir el siguiente valor, y así sucesivamente, como en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce96333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = rail_valid.to_numpy()[np.newaxis, :seq_length, np.newaxis]\n",
    "for step_ahead in range(14):\n",
    "    y_pred_one = univar_model.predict(X)\n",
    "    X = np.concatenate([X, y_pred_one.reshape(1, 1, 1)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec650dfd",
   "metadata": {},
   "source": [
    "En este código, tomamos el número de pasajeros ferroviarios de los primeros 56 días del período de validación, y convertimos los datos en una matriz NumPy de forma [1, 56, 1] (recuerde que las capas recurrentes esperan entradas 3D). Luego usamos repetidamente el modelo para pronosticar el siguiente valor, y añadimos cada pronóstico a la serie de entrada, a lo largo del eje del tiempo (`axis=1`). Los pronósticos resultantes se trazan en la Figura 15-11.\n",
    "\n",
    "#### ADVERTENCIA\n",
    "\n",
    "Si el modelo comete un error en un paso de tiempo, entonces los pronósticos para los siguientes pasos de tiempo también se ven afectados: los errores tienden a acumularse. Por lo tanto, es preferible usar esta técnica solo para un pequeño número de pasos.\n",
    "\n",
    "#### ---------------------------------------------------------------------------------\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1511.png)\n",
    "\n",
    "(_Figura 15-11. Pronóstico de 14 pasos por delante, 1 paso a la vez_)\n",
    "\n",
    "La segunda opción es entrenar un RNN para que prediga los siguientes 14 valores de una sola vez. Todavía podemos usar un modelo de secuencia a vector, pero generará 14 valores en lugar de 1. Sin embargo, primero debemos cambiar los objetivos para que sean vectores que contengan los siguientes 14 valores. Para hacer esto, podemos usar `timeseries_dataset_from_array()` nuevamente, pero esta vez pidiéndole que cree conjuntos de datos sin objetivos `(targets=None)` y con secuencias más largas, de longitud `seq_length` + 14. Luego podemos usar el método `map()` de los conjuntos de datos para aplique una función personalizada a cada lote de secuencias, dividiéndolas en entradas y objetivos. En este ejemplo, utilizamos la serie temporal multivariada como entrada (usando las cinco columnas) y pronosticamos el número de pasajeros en tren para los próximos 14 días:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_inputs_and_targets(mulvar_series, ahead=14, target_col=1):\n",
    "    return mulvar_series[:, :-ahead], mulvar_series[:, -ahead:, target_col]\n",
    "\n",
    "ahead_train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_train.to_numpy(),\n",
    "    targets=None,\n",
    "    sequence_length=seq_length + 14,\n",
    "    [...]  # the other 3 arguments are the same as earlier\n",
    ").map(split_inputs_and_targets)\n",
    "ahead_valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    mulvar_valid.to_numpy(),\n",
    "    targets=None,\n",
    "    sequence_length=seq_length + 14,\n",
    "    batch_size=32\n",
    ").map(split_inputs_and_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e5adc4",
   "metadata": {},
   "source": [
    "Ahora solo necesitamos que la capa de salida tenga 14 unidades en lugar de 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355419ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahead_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1759f6c",
   "metadata": {},
   "source": [
    "Después de entrenar este modelo, puedes predecir los siguientes 14 valores a la vez de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mulvar_valid.to_numpy()[np.newaxis, :seq_length]  # shape [1, 56, 5]\n",
    "Y_pred = ahead_model.predict(X)  # shape [1, 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5393b3dd",
   "metadata": {},
   "source": [
    "Este enfoque funciona bastante bien. Sus pronósticos para el día siguiente son obviamente mejores que sus pronósticos para 14 días en el futuro, pero no acumula errores como lo hizo el enfoque anterior. Sin embargo, todavía podemos hacerlo mejor, utilizando un modelo de secuencia a secuencia (o seq2seq).\n",
    "\n",
    "\n",
    "## Pronóstico utilizando un modelo de secuencia a secuencia\n",
    "\n",
    "\n",
    "En lugar de entrenar al modelo para pronosticar los próximos 14 valores solo en el último paso de la vez, podemos entrenarlo para pronosticar los siguientes 14 valores en cada paso de la vez. En otras palabras, podemos convertir este RNN de secuencia a vector en un RNN de secuencia a secuencia. La ventaja de esta técnica es que la pérdida contendrá un término para la salida del RNN en todos y cada uno de los pasos de tiempo, no solo para la salida en el último paso de tiempo.\n",
    "\n",
    "Esto significa que habrá muchos más gradientes de error que fluirán a través del modelo, y no tendrán que fluir a través del tiempo tanto, ya que vendrán de la salida de cada paso de tiempo, no solo del último. Esto estabilizará y acelerará el entrenamiento.\n",
    "\n",
    "Para que quede claro, en el paso de tiempo 0, el modelo producirá un vector que contendrá las previsiones para los pasos de tiempo 1 a 14, luego en el paso de tiempo 1, el modelo pronosticará los pasos de tiempo del 2 al 15, y así sucesive. En otras palabras, los objetivos son secuencias de ventanas consecutivas, desplazadas por un paso de tiempo en cada paso de tiempo. El objetivo ya no es un vector, sino una secuencia de la misma longitud que las entradas, que contiene un vector de 14 dimensiones en cada paso.\n",
    "\n",
    "Preparar los conjuntos de datos no es trivial, ya que cada instancia tiene una ventana como entrada y una secuencia de ventanas como salida. Una forma de hacer esto es usar la función de utilidad `to_windows()` que creamos anteriormente, dos veces seguidas, para obtener ventanas de ventanas consecutivas. Por ejemplo, transformemos la serie de números del 0 al 6 en un conjunto de datos que contenga secuencias de 4 ventanas consecutivas, cada una de longitud 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81746a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = tf.data.Dataset.range(7)\n",
    "dataset = to_windows(to_windows(my_series, 3), 4)\n",
    "list(dataset)\n",
    "\n",
    "'''\n",
    "[<tf.Tensor: shape=(4, 3), dtype=int64, numpy=\n",
    " array([[0, 1, 2],\n",
    "        [1, 2, 3],\n",
    "        [2, 3, 4],\n",
    "        [3, 4, 5]])>,\n",
    " <tf.Tensor: shape=(4, 3), dtype=int64, numpy=\n",
    " array([[1, 2, 3],\n",
    "        [2, 3, 4],\n",
    "        [3, 4, 5],\n",
    "        [4, 5, 6]])>]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b163808",
   "metadata": {},
   "source": [
    "Ahora podemos usar el método `map()` para dividir estas ventanas de ventanas en entradas y destinos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8bd55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda S: (S[:, 0], S[:, 1:]))\n",
    "list(dataset)\n",
    "\n",
    "'''\n",
    "[(<tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 1, 2, 3])>,\n",
    "  <tf.Tensor: shape=(4, 2), dtype=int64, numpy=\n",
    "  array([[1, 2],\n",
    "         [2, 3],\n",
    "         [3, 4],\n",
    "         [4, 5]])>),\n",
    " (<tf.Tensor: shape=(4,), dtype=int64, numpy=array([1, 2, 3, 4])>,\n",
    "  <tf.Tensor: shape=(4, 2), dtype=int64, numpy=\n",
    "  array([[2, 3],\n",
    "         [3, 4],\n",
    "         [4, 5],\n",
    "         [5, 6]])>)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3b4214",
   "metadata": {},
   "source": [
    "Ahora el conjunto de datos contiene secuencias de longitud 4 como entradas, y los objetivos son secuencias que contienen los siguientes dos pasos, para cada paso de tiempo. Por ejemplo, la primera secuencia de entrada es [0, 1, 2, 3], y sus objetivos correspondientes son [[1, 2], [2, 3], [3, 4], [4, 5]], que son los siguientes dos valores para cada paso de tiempo. Si eres como yo, probablemente necesitarás unos minutos para entender esto. ¡Tómate tu tiempo!\n",
    "\n",
    "#### NOTA\n",
    "\n",
    "Puede ser sorprendente que los objetivos contengan valores que aparecen en las entradas. ¿No es hacer trampa? Afortunadamente, en absoluto: en cada paso de tiempo, un RNN solo conoce los pasos de tiempo pasados; no puede mirar hacia adelante. Se dice que es un modelo causal.\n",
    "\n",
    "#### ----------------------------------------------------------------------------------\n",
    "\n",
    "Vamos a crear otra pequeña función de utilidad para preparar los conjuntos de datos para nuestro modelo de secuencia a secuencia. También se encargará de barajar (opcional) y por lotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6056070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seq2seq_dataset(series, seq_length=56, ahead=14, target_col=1,\n",
    "                       batch_size=32, shuffle=False, seed=None):\n",
    "    ds = to_windows(tf.data.Dataset.from_tensor_slices(series), ahead + 1)\n",
    "    ds = to_windows(ds, seq_length).map(lambda S: (S[:, 0], S[:, 1:, 1]))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(8 * batch_size, seed=seed)\n",
    "    return ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b08cb",
   "metadata": {},
   "source": [
    "Ahora podemos usar esta función para crear los conjuntos de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e418876",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_train = to_seq2seq_dataset(mulvar_train, shuffle=True, seed=42)\n",
    "seq2seq_valid = to_seq2seq_dataset(mulvar_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc6de0",
   "metadata": {},
   "source": [
    "Y, por último, podemos construir el modelo de secuencia a secuencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79eb28",
   "metadata": {},
   "source": [
    "Es casi idéntico a nuestro modelo anterior: la única diferencia es que configuramos `return_sequences=True` en la capa `SimpleRNN`. De esta manera, generará una secuencia de vectores (cada uno de tamaño 32), en lugar de generar un solo vector en el último paso de tiempo. La capa `Dense` es lo suficientemente inteligente como para manejar secuencias como entrada: se aplicará en cada paso de tiempo, tomando un vector de 32 dimensiones como entrada y generando un vector de 14 dimensiones. De hecho, otra forma de obtener exactamente el mismo resultado es utilizar una capa `Conv1D` con un tamaño de kernel de 1: `Conv1D(14, kernel_size=1)`.\n",
    "\n",
    "\n",
    "#### TIP\n",
    "\n",
    "Keras ofrece una capa `TimeDistributed` que le permite aplicar cualquier capa de vector a vector a cada vector en las secuencias de entrada, en cada paso de tiempo. Lo hace de manera eficiente, remodelando las entradas para que cada paso de tiempo se trate como una instancia separada, luego remodela las salidas de la capa para recuperar la dimensión de tiempo. En nuestro caso, no lo necesitamos ya que la capa `Dense` ya admite secuencias como entradas.\n",
    "\n",
    "#### -------------------------------------------------------------------------------------\n",
    "\n",
    "El código de entrenamiento es el mismo de siempre. Durante el entrenamiento, se utilizan todos los resultados del modelo, pero después del entrenamiento solo importa el resultado del último paso, y el resto se puede ignorar. Por ejemplo, podemos pronosticar el número de pasajeros del tren para los próximos 14 días de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mulvar_valid.to_numpy()[np.newaxis, :seq_length]\n",
    "y_pred_14 = seq2seq_model.predict(X)[0, -1]  # only the last time step's output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e967346",
   "metadata": {},
   "source": [
    "Si evalúa los pronósticos de este modelo para t + 1, encontrará un MAE de validación de 25.519. Para t + 2 son 26.274, y el rendimiento continúa cayendo gradualmente a medida que el modelo intenta pronosticar más adelante en el futuro. En t + 14, el MAE es 34.322.\n",
    "\n",
    "#### TIP\n",
    "\n",
    "Puede combinar ambos enfoques para pronosticar varios pasos por delante: por ejemplo, puede entrenar un modelo que pronostica con 14 días de anticipación, luego tomar su salida y agregarla a las entradas, luego ejecutar el modelo de nuevo para obtener pronósticos para los siguientes 14 días y, posiblemente, repetir el proceso.\n",
    "\n",
    "#### --------------------------------------------------------------------------------------\n",
    "\n",
    "Los RNN simples pueden ser bastante buenos para predecir series temporales o manejar otros tipos de secuencias, pero no funcionan tan bien en series o secuencias temporales largas. Discutamos por qué y veamos qué podemos hacer al respecto.\n",
    "\n",
    "\n",
    "# Manejo De Secuencias Largas\n",
    "\n",
    "\n",
    "Para entrenar un RNN en secuencias largas, debemos ejecutarlo en muchos pasos de tiempo, haciendo del RNN desenrollado una red muy profunda. Al igual que cualquier red neuronal profunda, puede sufrir el problema de los gradientes inestables, que se discute en el capítulo 11: puede tardar una eternidad en entrenar, o el entrenamiento puede ser inestable. Además, cuando un RNN procesa una secuencia larga, olvidará gradualmente las primeras entradas de la secuencia. Echemos un vistazo a estos dos problemas, comenzando con el problema de los gradientes inestables.\n",
    "\n",
    "\n",
    "## Lucha contra el problema de los gradientes inestables\n",
    "\n",
    "\n",
    "Muchos de los trucos que usamos en redes profundas para aliviar el problema de los gradientes inestables también se pueden utilizar para los RNN: buena inicialización de parámetros, optimizadores más rápidos, abandono, etc. Sin embargo, las funciones de activación no saturadas (por ejemplo, ReLU) pueden no ayudar tanto aquí. De hecho, pueden hacer que el RNN sea aún más inestable durante el entrenamiento. ¿Por qué? Bueno, supongamos que el descenso del gradiente actualiza los pesos de una manera que aumente ligeramente las salidas en el primer paso. Debido a que se utilizan los mismos pesos en cada paso de tiempo, las salidas en el segundo paso de tiempo también se pueden aumentar ligeramente, y las del tercero, y así sucesivamente hasta que las salidas exploten, y una función de activación no saturada no lo impide.\n",
    "\n",
    "Puede reducir este riesgo utilizando una tasa de aprendizaje más pequeña, o puede usar una función de activación saturante como la tangente hiperbólica (esto explica por qué es el valor predeterminado).\n",
    "\n",
    "De la misma manera, los propios gradientes pueden explotar. Si nota que el entrenamiento es inestable, es posible que desee monitorear el tamaño de los gradientes (por ejemplo, usando TensorBoard) y tal vez usar recorte de gradiente.\n",
    "\n",
    "Además, la normalización de lotes no se puede utilizar de manera tan eficiente con los RNN como con las redes de alimentación profunda. De hecho, no se puede usar entre pasos de tiempo, solo entre capas recurrentes.\n",
    "\n",
    "Para ser más precisos, es técnicamente posible agregar una capa BN a una celda de memoria (como verá en breve) para que se aplique en cada paso de tiempo (tanto en las entradas para ese paso de tiempo como en el estado oculto de el paso anterior). Sin embargo, se utilizará la misma capa BN en cada paso de tiempo, con los mismos parámetros, independientemente de la escala real y el desplazamiento de las entradas y el estado oculto. En la práctica esto no produce buenos resultados, como lo demostraron César Laurent et al. en un artículo de 2015: los autores encontraron que BN era ligeramente beneficioso solo cuando se aplicaba a las entradas de la capa, no a los estados ocultos. En otras palabras, fue ligeramente mejor que nada cuando se aplicó entre capas recurrentes (es decir, verticalmente en la Figura 15-10), pero no dentro de capas recurrentes (es decir, horizontalmente). En Keras, puede aplicar BN entre capas simplemente agregando una capa `BatchNormalization` antes de cada capa recurrente, pero ralentizará el entrenamiento y puede que no ayude mucho.\n",
    "\n",
    "Otra forma de normalización a menudo funciona mejor con los RNN: la normalización de capas. Esta idea fue presentada por Jimmy Lei Ba et al. en un documento de 2016:⁠8 es muy similar a la normalización por lotes, pero en lugar de normalizarse en la dimensión del lote, la normalización de la capa se normaliza en la dimensión de las características. Una ventaja es que puede calcular las estadísticas requeridas sobre la marcha, en cada paso del tiempo, de forma independiente para cada instancia. Esto también significa que se comporta de la misma manera durante el entrenamiento y las pruebas (a diferencia de BN), y no necesita usar promedios móviles exponenciales para estimar las estadísticas de características en todas las instancias del conjunto de entrenamiento, como lo hace BN. Al igual que BN, la normalización de capas aprende una escala y un parámetro de desplazamiento para cada entrada. En un RNN, normalmente se usa justo después de la combinación lineal de las entradas y los estados ocultos.\n",
    "\n",
    "Usemos Keras para implementar la normalización de capas dentro de una celda de memoria simple. Para hacer esto, necesitamos definir una celda de memoria personalizada, que es como una capa normal, excepto que su método `call()` toma dos argumentos: las entradas `inputs` en el paso de tiempo actual y los estados `states` ocultos del paso de tiempo anterior.\n",
    "\n",
    "Tenga en cuenta que el argumento de estados `states` es una lista que contiene uno o más tensores. En el caso de una celda RNN simple, contiene un único tensor igual a las salidas del paso de tiempo anterior, pero otras celdas pueden tener múltiples tensores de estado (por ejemplo, una `LSTMCell` tiene un estado a largo plazo y un estado a corto plazo, como lo verás en breve). Una celda también debe tener un atributo `state_size` y un atributo `output_size`. En un RNN simple, ambos son simplemente iguales al número de unidades. El siguiente código implementa una celda de memoria personalizada que se comportará como `SimpleRNNCell`, excepto que también aplicará la normalización de capa en cada paso de tiempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb256f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNSimpleRNNCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = tf.keras.layers.SimpleRNNCell(units,\n",
    "                                                             activation=None)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2bf0f",
   "metadata": {},
   "source": [
    "Vamos a revisar este código:\n",
    "\n",
    "- Nuestra clase `LNSimpleRNNCell` hereda de la clase `tf.keras.layers.Layer`, como cualquier capa personalizada.\n",
    "\n",
    "* El constructor toma el número de unidades y la función de activación deseada y establece los atributos `state_size` y `output_size`, luego crea una `SimpleRNNCell` sin función de activación (porque queremos realizar la normalización de capas después de la operación lineal pero antes de la función de activación).⁠ Luego el constructor crea la capa `LayerNormalization` y finalmente obtiene la función de activación deseada.\n",
    "\n",
    "- El método `call()` comienza aplicando `simpleRNNCell`, que calcula una combinación lineal de las entradas actuales y los estados ocultos anteriores, y devuelve el resultado dos veces (de hecho, en `SimpleRNNCell`, las salidas son exactamente iguales a los estados ocultos: en En otras palabras, `new_states[0]` es igual a las salidas `outputs`, por lo que podemos ignorar con seguridad `new_states` en el resto del método `call()`). A continuación, el método `call()` aplica la normalización de capas, seguido de la función de activación. Finalmente, devuelve las salidas dos veces: una como salidas y otra como los nuevos estados ocultos. Para usar esta celda personalizada, todo lo que necesitamos hacer es crear una capa `tf.keras.layers.RNN` y pasarle una instancia de celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_ln_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.RNN(LNSimpleRNNCell(32), return_sequences=True,\n",
    "                        input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96933e04",
   "metadata": {},
   "source": [
    "De manera similar, puede crear una celda personalizada para aplicar la exclusión entre cada paso de tiempo. Pero hay una forma más sencilla: la mayoría de las capas y celdas recurrentes proporcionadas por Keras tienen hiperparámetros de `dropout` y `recurrent_dropout`: el primero define la tasa de abandono que se aplicará a las entradas y el segundo define la tasa de abandono para los estados ocultos, entre pasos de tiempo. Por lo tanto, no es necesario crear una celda personalizada para aplicar la exclusión en cada paso de tiempo en un RNN.\n",
    "\n",
    "Con estas técnicas, puedes aliviar el problema de los gradientes inestables y entrenar a un RNN de manera mucho más eficiente. Ahora veamos cómo lidiar con el problema de la memoria a corto plazo.\n",
    "\n",
    "\n",
    "#### TIP\n",
    "\n",
    "Al pronosticar series temporales, suele resultar útil tener algunas barras de error junto con las predicciones. Para esto, un enfoque es usar la deserción de MC, presentada en el Capítulo 11: usar `recurrent_dropout` durante el entrenamiento, luego mantener la deserción activa en el momento de la inferencia llamando al modelo usando `model(X, training=True)`. Repita esto varias veces para obtener múltiples pronósticos ligeramente diferentes, luego calcule la media y la desviación estándar de estas predicciones para cada paso de tiempo.\n",
    "\n",
    "#### --------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "## Abordar el problema de la memoria a corto plazo\n",
    "\n",
    "\n",
    "Debido a las transformaciones por las que pasan los datos al atravesar un RNN, se pierde parte de información en cada paso del tiempo. Después de un tiempo, el estado de la RNN no contiene prácticamente ningún rastro de las primeras entradas. Esto puede ser un espectáculo. Imagina a Dory el pez⁠ tratando de traducir una frase larga; para cuando ha terminado de leerla, no tiene ni idea de cómo comenzó. Para abordar este problema, se han introducido varios tipos de células con memoria a largo plazo. Han demostrado ser tan exitosos que las células básicas ya no se usan mucho. Echemos un vistazo primero a la más popular de estas células de memoria a largo plazo: la célula LSTM.\n",
    "\n",
    "\n",
    "### Células LSTM\n",
    "\n",
    "La célula de memoria a largo plazo (LSTM) fue propuesta en 1997⁠ por Sepp Hochreiter y Jürgen Schmidhuber y mejorada gradualmente a lo largo de los años por varios investigadores, como Alex Graves, Haşim Sak⁠ y Wojciech Zaremba.⁠ Si Considere la celda LSTM como una caja negra, se puede usar de manera muy similar a una celda básica, excepto que funcionará mucho mejor; el entrenamiento convergerá más rápido y detectará patrones a más largo plazo en los datos. En Keras, simplemente puedes usar la capa `LSTM` en lugar de la capa `SimpleRNN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970e2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 5]),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a1fd2",
   "metadata": {},
   "source": [
    "Alternativamente, puede usar la capa `tf.keras.layers.RNN` de propósito general y darle un `LSTMCell` como argumento. Sin embargo, la capa `LSTM` utiliza una implementación optimizada cuando se ejecuta en una GPU (consulte el Capítulo 19), por lo que en general es preferible usarla (la capa `RNN` es más útil cuando define celdas personalizadas, como hicimos antes).\n",
    "\n",
    "Entonces, ¿cómo funciona una celda LSTM? Su arquitectura se muestra en la Figura 15-12. Si no miras lo que hay dentro de la caja, la celda LSTM se ve exactamente como una celda normal, excepto que su estado se divide en dos vectores: h(t) y c(t) (\"c\" significa \"célula\"). Puedes pensar en h(t) como el estado a corto plazo y c(t) como el estado a largo plazo.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1512.png)\n",
    "\n",
    "(_Figura 15-12. Una celda LSTM_)\n",
    "\n",
    "¡Ahora vamos a abrir la caja! La idea clave es que la red pueda aprender qué almacenar a largo plazo, qué tirar y qué leer de ella. A medida que el estado a largo plazo c(t-1) atraviesa la red de izquierda a derecha, se puede ver que primero pasa por una puerta de olvido, dejando caer algunos recuerdos, y luego agrega algunos recuerdos nuevos a través de la operación de adición (que agrega los recuerdos que fueron seleccionados por una puerta de entrada). El resultado c(t) se envía directamente, sin ninguna transformación adicional. Por lo tanto, en cada paso, se eliminan algunos recuerdos y se añaden algunos recuerdos. Además, después de la operación de adición, el estado a largo plazo se copia y se pasa a través de la función tanh, y luego el resultado se filtra por la puerta de salida. Esto produce el estado a corto plazo h(t) (que es igual a la salida de la celda para este paso de tiempo, y(t)). Ahora veamos de dónde vienen los nuevos recuerdos y cómo funcionan las puertas.\n",
    "\n",
    "En primer lugar, el vector de entrada actual x(t) y el anterior stateh(t-1) a corto plazo se alimentan a cuatro capas diferentes completamente conectadas. Todos tienen un propósito diferente:\n",
    "\n",
    "\n",
    "* La capa principal es la que emite g(t). Tiene el papel habitual de analizar las entradas actuales x(t) y el estado anterior (a corto plazo) h(t–1). En una celda básica, no hay nada más que esta capa, y su salida va directamente a y(t) y h(t). Pero en una celda LSTM, la salida de esta capa no sale directamente; en su lugar, sus partes más importantes se almacenan en el estado a largo plazo (y el resto se elimina).\n",
    "\n",
    "- Las otras tres capas son controladores de puerta. Dado que utilizan la función de activación logística, las salidas oscilan entre 0 y 1. Como puede ver, las salidas de los controladores de la puerta se alimentan a operaciones de multiplicación por elementos: si producen 0s, cierran la puerta, y si emiten 1s, la abren. Específicamente:\n",
    "\n",
    "\n",
    "    * La _puerta de olvido_ (controlada por **f(t)**) controla qué partes del estado a largo plazo deben borrarse.\n",
    "\n",
    "    * La _puerta de entrada_ (controlada por **i(t)**) controla qué partes deg(t) deben añadirse al estado a largo plazo.\n",
    "\n",
    "    * Finalmente, la _puerta de salida_ (controlada por **o(t)**) controla qué partes del estado a largo plazo deben leerse y salir en este paso, tanto a **h(t)** como a **y(t)**.\n",
    "    \n",
    "    \n",
    "En resumen, una celda LSTM puede aprender a reconocer una entrada importante (ese es el papel de la puerta de entrada), almacenarla en el estado a largo plazo, conservarla durante el tiempo que sea necesario (ese es el papel de la puerta de olvido) y extraerla cuando sea necesaria. Esto explica por qué estas células han tenido un éxito increíble en la captura de patrones a largo plazo en series temporales, textos largos, grabaciones de audio y más.\n",
    "\n",
    "La ecuación 15-4 resume cómo calcular el estado a largo plazo de la celda, su estado a corto plazo y su salida en cada paso de tiempo para una sola instancia (las ecuaciones para un mini lote completo son muy similares).\n",
    "\n",
    "\n",
    "### Ecuación 15-4. Cálculos de LSTM\n",
    "\n",
    "<a href=\"https://ibb.co/rMMQpGf\"><img src=\"https://i.ibb.co/TRRw0Bq/Captura-de-pantalla-2024-03-24-a-las-18-21-41.png\" alt=\"Captura-de-pantalla-2024-03-24-a-las-18-21-41\" border=\"0\"></a><br /><a target='_blank' href='https://es.imgbb.com/'>no puedo ver mis fotos en facebook</a><br />\n",
    "\n",
    "En esta ecuación:\n",
    "\n",
    "* **Wxi, Wxf, Wxo y Wxg** son las matrices de peso de cada una de las cuatro capas para su conexión con el vector de entrada x(t).\n",
    "\n",
    "- Whi, **Whf**, Who y **Whg** son las matrices de peso de cada una de las cuatro capas para su conexión con el estado anterior a corto plazo(t-1).\n",
    "\n",
    "* bi, bf, bo y bg son los términos de sesgo para cada una de las cuatro capas. Tenga en cuenta que TensorFlow inicializa bf a un vector lleno de 1s en lugar de 0s. Esto evita olvidar todo al comienzo del entrenamiento.\n",
    "\n",
    "Hay varias variantes de la célula LSTM. Una variante particularmente popular es la celda GRU, que veremos ahora.\n",
    "\n",
    "\n",
    "### Células GRU\n",
    "\n",
    "La celda de unidad recurrente cerrada (GRU) (ver Figura 15-13) fue propuesta por Kyunghyun Cho et al. en un documento de 2014⁠ que también introdujo la red de codificador-decodificador que discutimos anteriormente.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1513.png)\n",
    "\n",
    "(_Figura 15-13. Célula GRU_)\n",
    "\n",
    "La celda GRU es una versión simplificada de la celda LSTM, y parece funcionar igual⁠ (lo que explica su creciente popularidad). \n",
    "\n",
    "\n",
    "Estas son las principales simplificaciones:\n",
    "\n",
    "\n",
    "* Ambos vectores de estado se fusionan en un solo vector **h(t)**.\n",
    "\n",
    "- Un solo controlador de puerta z(t) controla tanto la puerta de olvido como la puerta de entrada. Si el controlador de la puerta emite un 1, la puerta de olvido está abierta (= 1) y la puerta de entrada está cerrada (1 - 1 = 0). Si emite un 0, sucede lo contrario. En otras palabras, cada vez que se debe almacenar una memoria, primero se borra la ubicación donde se almacenará. En realidad, esta es una variante frecuente de la célula LSTM en sí misma.\n",
    "\n",
    "* No hay puerta de salida; el vector de estado completo se sale en cada paso del tiempo. Sin embargo, hay un nuevo controlador de puerta r(t) que controla qué parte del estado anterior se mostrará a la capa principal (g(t)).\n",
    "\n",
    "La ecuación 15-5 resume cómo calcular el estado de la celda en cada paso de tiempo para una sola instancia.\n",
    "\n",
    "\n",
    "### Ecuación 15-5. Cálculos de GRU\n",
    "\n",
    "\n",
    "<a href=\"https://ibb.co/j4NGvRM\"><img src=\"https://i.ibb.co/7yfVJ4W/Captura-de-pantalla-2024-03-24-a-las-18-29-39.png\" alt=\"Captura-de-pantalla-2024-03-24-a-las-18-29-39\" border=\"0\"></a>\n",
    "\n",
    "Keras proporciona una capa `tf.keras.layers.GRU`: usarla es solo cuestión de reemplazar `SimpleRNN` o `LSTM` con `GRU`. También proporciona `tf.keras.layers.GRUCell`, en caso de que desee crear una celda personalizada basada en una celda GRU.\n",
    "\n",
    "Las células LSTM y GRU son una de las principales razones detrás del éxito de los RNN. Sin embargo, si bien pueden abordar secuencias mucho más largas que los RNN simples, todavía tienen una memoria a corto plazo bastante limitada, y tienen dificultades para aprender patrones a largo plazo en secuencias de 100 pasos de tiempo o más, como muestras de audio, series de tiempo largas o oraciones largas. Una forma de resolver esto es acortar las secuencias de entrada; por ejemplo, usando capas convolucionales 1D.\n",
    "\n",
    "\n",
    "## Uso de capas convolucionales 1D para procesar secuencias\n",
    "\n",
    "\n",
    "En el Capítulo 14, vimos que una capa convolucional 2D funciona deslizando varios núcleos (o filtros) bastante pequeños a través de una imagen, produciendo múltiples mapas de características 2D (uno por núcleo). De manera similar, una capa convolucional 1D desliza varios núcleos a lo largo de una secuencia, produciendo un mapa de características 1D por núcleo. Cada núcleo aprenderá a detectar un único patrón secuencial muy corto (no más largo que el tamaño del núcleo). Si usa 10 núcleos, entonces la salida de la capa estará compuesta por 10 secuencias 1D (todas de la misma longitud) o, de manera equivalente, puede ver esta salida como una única secuencia 10D. Esto significa que puede construir una red neuronal compuesta por una combinación de capas recurrentes y capas convolucionales 1D (o incluso capas de agrupación 1D). Si utiliza una capa convolucional 1D con un paso de 1 y el `\"same\"` relleno, entonces la secuencia de salida tendrá la misma longitud que la secuencia de entrada. Pero si usa un relleno `\"valid\"` o una zancada mayor que 1, entonces la secuencia de salida será más corta que la secuencia de entrada, así que asegúrese de ajustar los objetivos en consecuencia.\n",
    "\n",
    "Por ejemplo, el siguiente modelo es el mismo que el anterior, excepto que comienza con una capa convolucional 1D que reduce la secuencia de entrada en un factor de 2, usando un paso de 2. El tamaño del núcleo es mayor que el paso, por lo que todas las entradas usarse para calcular la salida de la capa y, por lo tanto, el modelo puede aprender a preservar la información útil, eliminando solo los detalles sin importancia. Al acortar las secuencias, la capa convolucional puede ayudar a las capas `GRU` a detectar patrones más largos, por lo que podemos permitirnos duplicar la longitud de la secuencia de entrada a 112 días. Tenga en cuenta que también debemos recortar los primeros tres pasos de tiempo en los objetivos: de hecho, el tamaño del núcleo es 4, por lo que la primera salida de la capa convolucional se basará en los pasos de tiempo de entrada 0 a 3, y los primeros pronósticos serán para los pasos de tiempo 4 a 17 (en lugar de los pasos de tiempo 1 a 14). Además, debemos reducir la muestra de los objetivos en un factor de 2, debido al paso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8322ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_rnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=4, strides=2,\n",
    "                           activation=\"relu\", input_shape=[None, 5]),\n",
    "    tf.keras.layers.GRU(32, return_sequences=True),\n",
    "    tf.keras.layers.Dense(14)\n",
    "])\n",
    "\n",
    "longer_train = to_seq2seq_dataset(mulvar_train, seq_length=112,\n",
    "                                       shuffle=True, seed=42)\n",
    "longer_valid = to_seq2seq_dataset(mulvar_valid, seq_length=112)\n",
    "downsampled_train = longer_train.map(lambda X, Y: (X, Y[:, 3::2]))\n",
    "downsampled_valid = longer_valid.map(lambda X, Y: (X, Y[:, 3::2]))\n",
    "[...]  # compile and fit the model using the downsampled datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13b15e",
   "metadata": {},
   "source": [
    "Si entrenas y evalúas este modelo, encontrarás que supera al modelo anterior (por un pequeño margen). De hecho, ¡en realidad es posible usar solo capas convolucionales 1D y soltar las capas recurrentes por completo!\n",
    "\n",
    "\n",
    "## WaveNet\n",
    "\n",
    "\n",
    "En un artículo de 2016, Aaron van den Oord y otros investigadores de DeepMind presentaron una nueva arquitectura llamada WaveNet. Apilaron capas convolucionales 1D, duplicando la tasa de dilatación (qué tan separadas están las entradas de cada neurona) en cada capa: la primera capa convolucional tiene una visión de solo dos pasos de tiempo a la vez, mientras que la siguiente ve cuatro pasos de tiempo (su campo receptivo tiene cuatro pasos de tiempo), la siguiente ve ocho pasos de tiempo, y así suce de (ver Figura 15-14). De esta manera, las capas inferiores aprenden patrones a corto plazo, mientras que las capas superiores aprenden patrones a largo plazo. Gracias a la tasa de dilatación de duplicación, la red puede procesar secuencias extremadamente grandes de manera muy eficiente.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1514.png)\n",
    "\n",
    "(_Figura 15-14. Arquitectura WaveNet_)\n",
    "\n",
    "\n",
    "Los autores del artículo en realidad apilaron 10 capas de convolución con tasas de dilatación de 1, 2, 4, 8, ... , 256, 512, luego apilaron otro grupo de 10 capas idénticas (también con tasas de dilatación 1, 2, 4, 8, ... , 256, 512), y luego de nuevo otro grupo idéntico de 10 capas. Justificaron esta arquitectura señalando que una sola pila de 10 capas convolucionales con estas tasas de dilatación actuará como una capa convolucional súper eficiente con un núcleo de tamaño 1.024 (excepto mucho más rápido, más potente y utilizando significativamente menos parámetros). También rellenaron a la izquierda las secuencias de entrada con un número de ceros igual a la tasa de dilatación antes de cada capa, para preservar la misma longitud de secuencia en toda la red.\n",
    "\n",
    "Aquí está cómo implementar una WaveNet simplificada para abordar las mismas secuencias que antes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavenet_model = tf.keras.Sequential()\n",
    "wavenet_model.add(tf.keras.layers.Input(shape=[None, 5]))\n",
    "for rate in (1, 2, 4, 8) * 2:\n",
    "    wavenet_model.add(tf.keras.layers.Conv1D(\n",
    "        filters=32, kernel_size=2, padding=\"causal\", activation=\"relu\",\n",
    "        dilation_rate=rate))\n",
    "wavenet_model.add(tf.keras.layers.Conv1D(filters=14, kernel_size=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6c2f8",
   "metadata": {},
   "source": [
    "Este modelo `Sequential` comienza con una capa de entrada explícita; esto es más sencillo que intentar establecer `input_shape` solo en la primera capa. Luego continúa con una capa convolucional 1D usando un relleno `\"causal\"`, que es como el `\"same\"` relleno excepto que los ceros se agregan solo al inicio de la secuencia de entrada, en lugar de en ambos lados. Esto garantiza que la capa convolucional no mire hacia el futuro al hacer predicciones. Luego agregamos pares similares de capas usando tasas de dilatación crecientes: 1, 2, 4, 8, y nuevamente 1, 2, 4, 8. Finalmente, agregamos la capa de salida: una capa convolucional con 14 filtros de tamaño 1 y sin ningún función de activación. Como vimos anteriormente, una capa convolucional de este tipo equivale a una capa `Dense` con 14 unidades. Gracias al relleno causal, cada capa convolucional genera una secuencia de la misma longitud que su secuencia de entrada, por lo que los objetivos que usamos durante el entrenamiento pueden ser secuencias completas de 112 días: no es necesario recortarlas ni reducirlas.\n",
    "\n",
    "Los modelos que hemos discutido en esta sección ofrecen un rendimiento similar para la tarea de pronóstico del número de pasajeros, pero pueden variar significativamente dependiendo de la tarea y de la cantidad de datos disponibles. En el documento de WaveNet, los autores lograron un rendimiento de última generación en varias tareas de audio (de ahí el nombre de la arquitectura), incluidas las tareas de texto a voz, produciendo voces increíblemente realistas en varios idiomas. También utilizaron el modelo para generar música, una muestra de audio a la vez. Esta hazaña es aún más impresionante cuando te das cuenta de que un solo segundo de audio puede contener decenas de miles de pasos de tiempo, incluso los LSTM y los GRU no pueden manejar secuencias tan largas.\n",
    "\n",
    "### ADVERTENCIA\n",
    "\n",
    "Si evalúas nuestros mejores modelos de pasajeros de Chicago en el período de prueba, a partir de 2020, ¡te darás cuenta de que funcionan mucho peor de lo esperado! ¿Por qué es eso? Bueno, ahí fue cuando comenzó la pandemia de Covid-19, que afectó en gran medida al transporte público. Como se mencionó anteriormente, estos modelos solo funcionarán bien si los patrones que aprendieron del pasado continúan en el futuro. En cualquier caso, antes de implementar un modelo en producción, verifique que funcione bien con datos recientes. Y una vez que esté en producción, asegúrate de controlar su rendimiento con regularidad.\n",
    "\n",
    "### ------------------------------------------------------------------------\n",
    "\n",
    "¡Con eso, ahora puedes abordar todo tipo de series temporales! En el capítulo 16, continuaremos explorando los RNN, y veremos cómo también pueden abordar varias tareas de PNL.\n",
    "\n",
    "\n",
    "# Ejercicios\n",
    "\n",
    "\n",
    "1. ¿Se te ocurren algunas aplicaciones para un RNN de secuencia a secuencia? ¿Qué tal un RNN de secuencia a vector y un RNN de vector a secuencia?\n",
    "\n",
    "2. ¿Cuántas dimensiones deben tener las entradas de una capa RNN? ¿Qué representa cada dimensión? ¿Qué pasa con sus resultados?\n",
    "\n",
    "3. Si quieres construir un RNN de secuencia a secuencia profunda, ¿qué capas de RNN deberían tener return_sequences=True? ¿Qué tal un RNN de secuencia a vector?\n",
    "\n",
    "4. Supongamos que tienes una serie temporal univariable diaria y quieres pronosticar los próximos siete días. ¿Qué arquitectura RNN deberías usar?\n",
    "\n",
    "5. ¿Cuáles son las principales dificultades al entrenar a los RNN? ¿Cómo puedes manejarlos?\n",
    "\n",
    "6. ¿Puedes esbozar la arquitectura de la celda LSTM?\n",
    "\n",
    "7. ¿Por qué querrías usar capas convolucionales 1D en un RNN?\n",
    "\n",
    "8. ¿Qué arquitectura de red neuronal podrías usar para clasificar los vídeos?\n",
    "\n",
    "9. Entrena un modelo de clasificación para el conjunto de datos SketchRNN, disponible en TensorFlow Datasets.\n",
    "\n",
    "10. Descargue el conjunto de datos de corales de Bach y descomprima. Está compuesto por 382 corales compuestos por Johann Sebastian Bach. Cada coral tiene de 100 a 640 pasos de tiempo de duración, y cada paso de tiempo contiene 4 números enteros, donde cada número entero corresponde al índice de una nota en un piano (excepto el valor 0, lo que significa que no se toca ninguna nota). Entrena un modelo, recurrente, convolucional o ambos, que pueda predecir el siguiente paso de tiempo (cuatro notas), dado una secuencia de pasos de tiempo de un coral. Luego use este modelo para generar música similar a Bach, una nota a la vez: puede hacer esto dándole al modelo el comienzo de un coral y pidiéndole que prediga el siguiente paso de tiempo, luego agregando estos pasos de tiempo a la secuencia de entrada y pidiendo al modelo la siguiente nota, y así sucede. También asegúrate de echar un vistazo al modelo Coconet de Google, que se utilizó para un bonito garabato de Google sobre Bach.\n",
    "\n",
    "Las soluciones a estos ejercicios están disponibles al final del cuaderno de este capítulo, en https://homl.info/colab3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067cbd2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
