{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73b5b05c",
   "metadata": {},
   "source": [
    "Los pájaros nos inspiraron a volar, las plantas de bardana inspiraron el velcro y la naturaleza ha inspirado innumerables inventos más. Parece lógico, entonces, mirar la arquitectura del cerebro en busca de inspiración sobre cómo construir una máquina inteligente. \n",
    "\n",
    "Esta es la lógica que desencadenó las redes neuronales artificiales (ANN), modelos de aprendizaje automático inspirados en las redes de neuronas biológicas que se encuentran en nuestros cerebros. Sin embargo, aunque los aviones se inspiraron en las aves, no tienen que batir sus alas para volar. Del mismo modo, los ANN se han vuelto gradualmente bastante diferentes de sus primos biológicos. \n",
    "\n",
    "Algunos investigadores incluso argumentan que deberíamos abandonar la analogía biológica por completo (por ejemplo, diciendo \"unidades\" en lugar de \"neurones\"), para que no restrinjamos nuestra creatividad a sistemas biológicamente plausibles.⁠\n",
    "\n",
    "Los ANN son el núcleo del aprendizaje profundo. Son versátiles, potentes y escalables, lo que los hace ideales para abordar tareas de aprendizaje automático grandes y altamente complejas, como clasificar miles de millones de imágenes (por ejemplo, Google Images), potenciar los servicios de reconocimiento de voz (por ejemplo, Siri de Apple), recomendar los mejores vídeos para ver a cientos de millones de usuarios todos los días (por ejemplo, YouTube) o aprender a vencer al campeón del mundo en el juego de Go (AlphaGo de DeepMind).\n",
    "\n",
    "La primera parte de este capítulo presenta redes neuronales artificiales, comenzando con un rápido recorrido por las primeras arquitecturas de ANN y llevando a los perceptrones multicapa, que se utilizan mucho hoy en día (otras arquitecturas se explorarán en los próximos capítulos). En la segunda parte, veremos cómo implementar redes neuronales utilizando la API Keras de TensorFlow. \n",
    "\n",
    "Esta es una API de alto nivel muy bien diseñada y sencilla para construir, entrenar, evaluar y ejecutar redes neuronales. Pero no te dejes engañar por su simplicidad: es lo suficientemente expresivo y flexible como para que puedas construir una amplia variedad de arquitecturas de redes neuronales. De hecho, probablemente será suficiente para la mayoría de sus casos de uso. Y si alguna vez necesita flexibilidad adicional, siempre puede escribir componentes personalizados de Keras utilizando su API de nivel inferior, o incluso usar TensorFlow directamente, como verá en el capítulo 12.\n",
    "\n",
    "Pero primero, ¡vamos atrás en el tiempo para ver cómo surgieron las redes neuronales artificiales!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38730ead",
   "metadata": {},
   "source": [
    "# De las neuronas biológicas a las artificiales\n",
    "\n",
    "Sorprendentemente, los ANN han existido durante bastante tiempo: fueron introducidos por primera vez en 1943 por el neurofisiólogo Warren McCulloch y el matemático Walter Pitts. En su artículo histórico⁠2 \"Un cálculo lógico de ideas inmanentes en la actividad nerviosa\", McCulloch y Pitts presentaron un modelo computacional simplificado de cómo las neuronas biológicas podrían trabajar juntas en los cerebros animales para realizar cálculos complejos utilizando la lógica proposicional. Esta fue la primera arquitectura de red neuronal artificial. Desde entonces se han inventado muchas otras arquitecturas, como verás.\n",
    "\n",
    "\n",
    "Los primeros éxitos de los ANN llevaron a la creencia generalizada de que pronto estaríamos conversando con máquinas verdaderamente inteligentes. Cuando quedó claro en la década de 1960 que esta promesa no se cumpliría (al menos durante bastante tiempo), la financiación voló a otro lugar, y los ANN entraron en un largo invierno. A principios de la década de 1980, se inventaron nuevas arquitecturas y se desarrollaron mejores técnicas de entrenamiento, lo que provocó un resurgimiento del interés en el conexionismo, el estudio de las redes neuronales. Pero el progreso era lento, y en la década de 1990 se habían inventado otras poderosas técnicas de aprendizaje automático, como las máquinas vectoriales de soporte (véase el capítulo 5). Estas técnicas parecían ofrecer mejores resultados y bases teóricas más sólidas que las ANN, por lo que una vez más se suspendo el estudio de las redes neuronales.\n",
    "\n",
    "\n",
    "Ahora estamos siendo testigos de otra ola de interés en los ANN. ¿Esta ola se apague como las anteriores? Bueno, aquí hay algunas buenas razones para creer que esta vez es diferente y que el renovado interés en los ANN tendrá un impacto mucho más profundo en nuestras vidas:\n",
    "\n",
    "\n",
    "* Ahora hay una gran cantidad de datos disponibles para entrenar las redes neuronales, y los ANN con frecuencia superan a otras técnicas de aprendizaje automático en problemas muy grandes y complejos.\n",
    "\n",
    "* El tremendo aumento de la potencia informática desde la década de 1990 ahora hace posible entrenar grandes redes neuronales en un período de tiempo razonable. Esto se debe en parte a la ley de Moore (el número de componentes en los circuitos integrados se ha duplicado aproximadamente cada 2 años en los últimos 50 años), pero también gracias a la industria de los juegos, que ha estimulado la producción de potentes tarjetas GPU por millones. Además, las plataformas en la nube han hecho que este poder sea accesible para todos.\n",
    "\n",
    "* Se han mejorado los algoritmos de entrenamiento. Para ser justos, solo son ligeramente diferentes de los utilizados en la década de 1990, pero estos ajustes relativamente pequeños han tenido un gran impacto positivo.\n",
    "\n",
    "* Algunas limitaciones teóricas de los ANN han resultado ser benignas en la práctica. Por ejemplo, muchas personas pensaron que los algoritmos de entrenamiento de ANN estaban condenados porque era probable que se quedaran atascados en la optima local, pero resulta que esto no es un gran problema en la práctica, especialmente para las redes neuronales más grandes: la optima local a menudo funciona casi tan bien como el óptimo global.\n",
    "\n",
    "* Los ANN parecen haber entrado en un círculo virtuoso de financiación y progreso. Los productos increíbles basados en ANN regularmente aparecen en los titulares, lo que atrae cada vez más atención y financiación hacia ellos, lo que resulta en más y más progreso y productos aún más increíbles.\n",
    "\n",
    "\n",
    "## Neuronas biológicas\n",
    "\n",
    "\n",
    "Antes de hablar sobre las neuronas artificiales, echemos un vistazo rápido a una neurona biológica (representada en la Figura 10-1). Es una célula de aspecto inusual que se encuentra principalmente en los cerebros de los animales. \n",
    "\n",
    "Está compuesto por un cuerpo celular que contiene el núcleo y la mayoría de los componentes complejos de la célula, muchas extensiones ramificadas llamadas dendritas, además de una extensión muy larga llamada axón. \n",
    "\n",
    "La longitud del axón puede ser solo unas pocas veces más larga que la del cuerpo celular, o hasta decenas de miles de veces más larga. Cerca de su extremo, el axón se divide en muchas ramas llamadas telodendria, y en la punta de estas ramas hay estructuras minúsculas llamadas terminales sinápticos (o simplemente sinapsis), que están conectadas a las dendritas o cuerpos celulares de otras neuronas. \n",
    "\n",
    "Las neuronas biológicas producen impulsos eléctricos cortos llamados potenciales de acción (AP, o simplemente señales), que viajan a lo largo de los axones y hacen que las sinapsis liberen señales químicas llamadas neurotransmisores. \n",
    "\n",
    "Cuando una neurona recibe una cantidad suficiente de estos neurotransmisores en unos pocos milisegundos, dispara sus propios impulsos eléctricos (en realidad, depende de los neurotransmisores, ya que algunos de ellos inhiben el disparo de la neurona).\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1001.png)\n",
    "\n",
    "_Figura 10-1. Una neurona biológica⁠_\n",
    "\n",
    "\n",
    "Por lo tanto, las neuronas biológicas individuales parecen comportarse de una manera simple, pero están organizadas en una vasta red de miles de millones, con cada neurona típicamente conectada a miles de otras neuronas. \n",
    "\n",
    "Los cálculos altamente complejos pueden ser realizados por una red de neuronas bastante simples, al igual que una hormiguero compleja puede surgir de los esfuerzos combinados de las hormigas simples. \n",
    "\n",
    "La arquitectura de las redes neuronales biológicas (BNN)⁠5 es objeto de investigación activa, pero se han mapeado algunas partes del cerebro. \n",
    "\n",
    "Estos esfuerzos muestran que las neuronas a menudo están organizadas en capas consecutivas, especialmente en la corteza cerebral (la capa externa del cerebro), como se muestra en la Figura 10-2.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1002.png)\n",
    "\n",
    "_Figura 10-2. Múltiples capas en una red neuronal biológica (corteza humana)⁠_\n",
    "\n",
    "\n",
    "## Cálculos lógicos con neuronas\n",
    "\n",
    "McCulloch y Pitts propusieron un modelo muy simple de la neurona biológica, que más tarde se conoció como una neurona artificial: tiene una o más entradas binarias (on/apagado) y una salida binaria. La neurona artificial activa su salida cuando más de un cierto número de sus entradas están activas. \n",
    "\n",
    "En su artículo, McCulloch y Pitts mostraron que incluso con un modelo tan simplificado es posible construir una red de neuronas artificiales que puedan calcular cualquier proposición lógica que desee. \n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1003.png)\n",
    "\n",
    "_Figura 10-3. ANN que realizan cálculos lógicos simples_\n",
    "\n",
    "\n",
    "Veamos qué hacen estas redes:\n",
    "\n",
    "* La primera red de la izquierda es la función de identidad: si la neurona A se activa, entonces la neurona C también se activa (ya que recibe dos señales de entrada de la neurona A); pero si la neurona A está desactivada, entonces la neurona C también está desactivada.\n",
    "\n",
    "\n",
    "* La segunda red realiza una lógica AND: la neurona C se activa solo cuando ambas neuronas A y B están activadas (una sola señal de entrada no es suficiente para activar la neurona C).\n",
    "\n",
    "\n",
    "* La tercera red realiza un OR lógico: la neurona C se activa si se activa la neurona A o la neurona B (o ambas).\n",
    "\n",
    "\n",
    "* Finalmente, si suponemos que una conexión de entrada puede inhibir la actividad de la neurona (que es el caso de las neuronas biológicas), entonces la cuarta red calcula una propuesta lógica ligeramente más compleja: la neurona C se activa solo si la neurona A está activa y la neurona B está desactivada. Si la neurona A está activa todo el tiempo, entonces obtienes un NO lógico: la neurona C está activa cuando la neurona B está apagada, y viceversa.\n",
    "\n",
    "\n",
    "Puedes imaginar cómo estas redes se pueden combinar para calcular expresiones lógicas complejas (ver los ejercicios al final del capítulo para ver un ejemplo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58d23e8",
   "metadata": {},
   "source": [
    "## El Perceptrón\n",
    "\n",
    "El perceptrón es una de las arquitecturas ANN más simples, inventada en 1957 por Frank Rosenblatt. Se basa en una neurona artificial ligeramente diferente (ver Figura 10-4) llamada unidad lógica de umbral (TLU), o a veces una unidad de umbral lineal (LTU). \n",
    "\n",
    "Las entradas y la salida son números (en lugar de valores binarios de encendido/apagado), y cada conexión de entrada está asociada con un peso. La TLU calcula primero una función lineal de sus entradas: z = w1 x1 + w2 x2 + ⋯ + wn xn + b = **w⊺ x + b**. \n",
    "\n",
    "Luego aplica una función de paso al resultado: hw(x) = step(z). Así que es casi como una regresión logística, excepto que utiliza una función de paso en lugar de la función logística (Capítulo 4). \n",
    "\n",
    "Al igual que en la regresión logística, los parámetros del modelo son los pesos de entrada **w** y el término de sesgo b.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1004.png)\n",
    "\n",
    "_Figura 10-4. TLU: una neurona artificial que calcula una suma ponderada de sus entradas w⊺ x, más un término de sesgo b, y luego aplica una función de paso_\n",
    "\n",
    "\n",
    "La función de paso más común utilizada en los perceptrones es la función de paso Heaviside (ver Ecuación 10-1). A veces se utiliza la función de signo en su lugar.\n",
    "\n",
    "\n",
    "### Ecuación 10-1. Funciones de paso comunes utilizadas en los perceptrones (suponiendo umbral = 0)\n",
    "\n",
    "<a href=\"https://ibb.co/wsHsXnv\"><img src=\"https://i.ibb.co/74c4539/Captura-de-pantalla-2023-12-01-a-las-15-17-57.png\" alt=\"Captura-de-pantalla-2023-12-01-a-las-15-17-57\" border=\"0\"></a>\n",
    "\n",
    "Se puede utilizar una sola TLU para la clasificación binaria lineal simple. \n",
    "\n",
    "Calcula una función lineal de sus entradas, y si el resultado supera un umbral, produce la clase positiva. De lo contrario, produce la clase negativa. Esto puede recordarle la regresión logística (Capítulo 4) o la clasificación lineal de SVM (Capítulo 5). \n",
    "Podrías, por ejemplo, usar una sola TLU para clasificar las flores de iris en función de la longitud y el ancho del pétalo. \n",
    "\n",
    "El entrenamiento de tal TLU requeriría encontrar los valores correctos para w1, w2 y b (el algoritmo de entrenamiento se discutirá en breve).\n",
    "\n",
    "Un perceptrón está compuesto por una o más TLU organizadas en una sola capa, donde cada TLU está conectada a cada entrada. Tal capa se llama capa completamente conectada, o capa densa. \n",
    "Las entradas constituyen la capa de entrada. Y dado que la capa de TLU produce las salidas finales, se llama capa de salida. \n",
    "\n",
    "Por ejemplo, un perceptrón con dos entradas y tres salidas se representa en la Figura 10-5.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1005.png)\n",
    "\n",
    "_Figura 10-5. Arquitectura de un perceptrón con dos entradas y tres neuronas de salida_\n",
    "\n",
    "\n",
    "Este perceptrón puede clasificar instancias simultáneamente en tres clases binarias diferentes, lo que lo convierte en un clasificador multietiqueta. También se puede utilizar para la clasificación multiclase.\n",
    "\n",
    "Gracias a la magia del álgebra lineal, la ecuación 10-2 se puede utilizar para calcular de manera eficiente las salidas de una capa de neuronas artificiales para varias instancias a la vez.\n",
    "\n",
    "\n",
    "### Ecuación 10-2. Computación de las salidas de una capa totalmente conectada\n",
    "\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/9VgB3QP/Captura-de-pantalla-2023-12-01-a-las-15-20-16.png\" alt=\"Captura-de-pantalla-2023-12-01-a-las-15-20-16\" border=\"0\"></a><br /><br />\n",
    "\n",
    "\n",
    "En esta ecuación:\n",
    "\n",
    "* Como siempre, X representa la matriz de características de entrada. Tiene una fila por instancia y una columna por característica.\n",
    "\n",
    "\n",
    "* La matriz de peso W contiene todos los pesos de conexión. Tiene una fila por entrada y una columna por neurona.\n",
    "\n",
    "\n",
    "* El vector de sesgo b contiene todos los términos de sesgo: uno por neurona.\n",
    "\n",
    "\n",
    "* La función φ se llama función de activación: cuando las neuronas artificiales son TLU, es una función de paso (en breve discutiremos otras funciones de activación).\n",
    "\n",
    "\n",
    "#### NOTA --------------------------------------------------------------------------\n",
    "\n",
    "En matemáticas, la suma de una matriz y un vector no está definida. \n",
    "Sin embargo, en la ciencia de datos, permitimos la \"difusión\": añadir un vector a una matriz significa añadirlo a cada fila de la matriz. Por lo tanto, XW + b primero multiplica X por W, lo que da como resultado una matriz con una fila por instancia y una columna por salida, luego agrega el vector b a cada fila de esa matriz, lo que agrega cada término de sesgo a la salida correspondiente, para cada instancia. Además, φ se aplica a cada elemento de la matriz resultante.\n",
    "\n",
    "#### ----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Entonces, ¿cómo se entrena un perceptrón? El algoritmo de entrenamiento de perceptrón propuesto por Rosenblatt se inspiró en gran medida en la regla de Hebb. En su libro de 1949 The Organization of Behavior (Wiley), Donald Hebb sugirió que cuando una neurona biológica desencadena otra neurona a menudo, la conexión entre estas dos neuronas se hace más fuerte. Siegrid Löwel más tarde resumió la idea de Hebb en la frase pegadiza, \"Células que se disparan juntas, se conectan juntas\"; es decir, el peso de conexión entre dos neuronas tiende a aumentar cuando se disparan simultáneamente. Esta regla más tarde se conoció como la regla de Hebb (o aprendizaje hebbio). Los perceptrones se entrenan utilizando una variante de esta regla que tiene en cuenta el error cometido por la red cuando hace una predicción; la regla de aprendizaje del perceptrón refuerza las conexiones que ayudan a reducir el error. Más específicamente, el perceptrón se alimenta con una instancia de entrenamiento a la vez, y para cada instancia hace sus predicciones. Para cada neurona de salida que produjo una predicción incorrecta, refuerza los pesos de conexión de las entradas que habrían contribuido a la predicción correcta. La regla se muestra en la ecuación 10-3.\n",
    "\n",
    "\n",
    "### Ecuación 10-3. Regla de aprendizaje de Perceptron (actualización de peso)\n",
    "\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/smFhXMB/Captura-de-pantalla-2023-12-01-a-las-15-23-18.png\" alt=\"Captura-de-pantalla-2023-12-01-a-las-15-23-18\" border=\"0\"></a>\n",
    "\n",
    "\n",
    "En esta ecuación:\n",
    "\n",
    "* **wi, j** es el peso de conexión entre la entrada ith y la jthneuron.\n",
    "\n",
    "* **xi** es el valor de entrada de la instancia de entrenamiento actual.\n",
    "\n",
    "* **y^j** es la salida de la neurona de salida jth para la instancia de entrenamiento actual.\n",
    "\n",
    "* **yj** es la salida objetivo de la neurona de salida jth para la instancia de entrenamiento actual.\n",
    "\n",
    "* **η** es la tasa de aprendizaje (véase el capítulo 4).\n",
    "\n",
    "\n",
    "El límite de decisión de cada neurona de salida es lineal, por lo que los perceptrones son incapaces de aprender patrones complejos (al igual que los clasificadores de regresión logística). Sin embargo, si las instancias de entrenamiento son linealmente separables, Rosenblatt demostró que este algoritmo convergería a una solución.⁠ \n",
    "\n",
    "Esto se llama el **teorema de convergencia del perceptrón**.\n",
    "\n",
    "Scikit-Learn proporciona una clase Perceptron que se puede usar más o menos como cabría esperar, por ejemplo, en el conjunto de datos del iris (presentado en el capítulo 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b3ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = (iris.target == 0)  # Iris setosa\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "y_pred = per_clf.predict(X_new)  # predice True y False para esas dos flores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c5e0b",
   "metadata": {},
   "source": [
    "Es posible que haya notado que el algoritmo de aprendizaje del perceptrón se parece mucho al descenso de gradiente estocástico (presentado en el Capítulo 4). \n",
    "\n",
    "\n",
    "De hecho, la clase `Perceptro` de Scikit-Learn equivale a usar un `SGDClassifier` con los siguientes hiperparámetros: \n",
    "\n",
    "\n",
    "`loss=\"perceptron\"`, `learning_rate=\"constant\"`, `eta0=1` (la tasa de aprendizaje) y `penality=None` (sin regularización).\n",
    "\n",
    "\n",
    "En su monografía de 1969 Perceptrones, Marvin Minsky y Seymour Papert destacaron una serie de debilidades graves de los perceptrones, en particular, el hecho de que son incapaces de resolver algunos problemas triviales (por ejemplo, el problema de clasificación exclusiva de OR (XOR); véase el lado izquierdo de la Figura 10-6). Esto es cierto para cualquier otro modelo de clasificación lineal (como los clasificadores de regresión logística), pero los investigadores habían esperado mucho más de los perceptrones, y algunos estaban tan decepcionados que abandonaron por completo las redes neuronales en favor de problemas de nivel superior como la lógica, la resolución de problemas y la búsqueda. La falta de aplicaciones prácticas tampoco ayudó.\n",
    "\n",
    "\n",
    "Resulta que algunas de las limitaciones de los perceptrones se pueden eliminar apilando múltiples perceptrones. \n",
    "\n",
    "El ANN resultante se llama **perceptrón multicapa (MLP)**. \n",
    "\n",
    "Un MLP puede resolver el problema XOR, ya que puede verificar calculando la salida del MLP representado en el lado derecho de la Figura 10-6: con entradas (0, 0) o (1, 1), las salidas de red 0, y con entradas (0, 1) o (1, 0) sale 1. ¡Intenta verificar que esta red realmente resuelve el problema de XOR!\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1006.png)\n",
    "\n",
    "_Figura 10-6. Problema de clasificación XOR y un MLP que lo resuelve_\n",
    "\n",
    "#### NOTA --------------------------------------------------------------------------\n",
    "\n",
    "A diferencia de los clasificadores de regresión logística, los perceptrones no producen una probabilidad de clase. Esta es una de las razones para preferir la regresión logística a los perceptrones. \n",
    "Además, los perceptrones no utilizan ninguna regularización por defecto, y el entrenamiento se detiene tan pronto como no hay más errores de predicción en el conjunto de entrenamiento, por lo que el modelo normalmente no generaliza tan bien como la regresión logística o un clasificador lineal de SVM. \n",
    "Sin embargo, los perceptrones pueden entrenar un poco más rápido.\n",
    "#### ---------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "## El perceptrón multicapa y la retropropagación\n",
    "\n",
    "\n",
    "Un MLP se compone de una capa de entrada, una o más capas de TLU llamadas capas ocultas y una capa final de TLU llamada capa de salida (ver Figura 10-7). Las capas cercanas a la capa de entrada generalmente se llaman capas inferiores, y las cercanas a las salidas generalmente se llaman capas superiores.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1007.png)\n",
    "\n",
    "_Figura 10-7. Arquitectura de un perceptrón multicapa con dos entradas, una capa oculta de cuatro neuronas y tres neuronas de salida_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab3ad2",
   "metadata": {},
   "source": [
    "#### NOTA ---------------------------------------------------------------------------\n",
    "\n",
    "La señal fluye solo en una dirección (desde las entradas hasta las salidas), por lo que esta arquitectura es un ejemplo de una red neuronal de avance (FNN).\n",
    "#### -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed77154",
   "metadata": {},
   "source": [
    "Cuando un ANN contiene una pila profunda de capas ocultas, ⁠9 se llama red neuronal profunda (DNN). El campo del aprendizaje profundo estudia los DNN, y más en general está interesado en modelos que contengan pilas profundas de cálculos. Aun así, muchas personas hablan de aprendizaje profundo siempre que hay redes neuronales involucradas (incluso las superficiales).\n",
    "\n",
    "Durante muchos años, los investigadores lucharon por encontrar una manera de entrenar a los MLP, sin éxito. A principios de la década de 1960, varios investigadores discutieron la posibilidad de usar el descenso de gradiente para entrenar redes neuronales, pero como vimos en el Capítulo 4, esto requiere calcular los gradientes del error del modelo con respecto a los parámetros del modelo; no estaba claro en ese momento cómo hacer esto de manera eficiente con un modelo tan complejo que contenía tantos parámetros, especialmente con las computadoras que tenían en ese entonces.\n",
    "\n",
    "Luego, en 1970, un investigador llamado Seppo Linnainmaa introdujo en su tesis de maestría una técnica para calcular todos los gradientes de forma automática y eficiente. Este algoritmo ahora se llama diferenciación automática de modo inverso (o diferencia automática de modo inverso para abreviar). En solo dos pasadas a través de la red (una hacia adelante, otra hacia atrás), es capaz de calcular los gradientes del error de la red neuronal con respecto a cada parámetro del modelo. En otras palabras, puede averiguar cómo se debe ajustar cada peso de conexión y cada sesgo para reducir el error de la red neuronal. Estos gradientes se pueden usar para realizar un paso de descenso de gradiente. Si repite este proceso de calcular los gradientes automáticamente y dar un paso de descenso de gradiente, el error de la red neuronal caerá gradualmente hasta que finalmente alcance un mínimo. Esta combinación de disdiff automático de modo inverso y descenso de gradiente ahora se llama backpropagation (o backprop para abreviar).\n",
    "\n",
    "#### NOTA\n",
    "\n",
    "Hay varias técnicas de autodiff, con diferentes pros y contras. La diferencia automática de modo inverso es adecuada cuando la función para diferenciar tiene muchas variables (por ejemplo, pesos de conexión y sesgos) y pocas salidas (por ejemplo, una pérdida). Si quieres obtener más información sobre autodiff, echa un vistazo al Apéndice B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ddfa9c",
   "metadata": {},
   "source": [
    "La retropropagación se puede aplicar a todo tipo de gráficos computacionales, no solo a las redes neuronales: de hecho, la tesis de maestría de Linnainmaa no era sobre redes neuronales, era más general. pasaron varios años más antes de que el backprop comenzara a usarse para entrenar redes neuronales, pero todavía no era la corriente principal. Luego, en 1985, David Rumelhart, Geoffrey Hinton y Ronald Williams publicaron un innovador documento⁠10 que analizaba cómo la retropropagación permitía a las redes neuronales aprender representaciones internas útiles. Sus resultados fueron tan impresionantes que la retropropagación se popularizó rápidamente en el campo. Hoy en día, es, con mucho, la técnica de entrenamiento más popular para las redes neuronales.\n",
    "\n",
    "Revisémos cómo funciona la retropropagación de nuevo con un poco más de detalle:\n",
    "\n",
    "\n",
    "* Maneja un mini lote a la vez (por ejemplo, que contiene 32 instancias cada uno), y pasa por el conjunto de entrenamiento completo varias veces. Cada pase se llama una época.\n",
    "\n",
    "\n",
    "* Cada mini-lote entra en la red a través de la capa de entrada. A continuación, el algoritmo calcula la salida de todas las neuronas de la primera capa oculta, para cada instancia del mini-lote. El resultado se pasa a la siguiente capa, su salida se calcula y se pasa a la siguiente capa, y así su así hasta que obtengamos la salida de la última capa, la capa de salida. Este es el pase hacia adelante: es exactamente como hacer predicciones, excepto que todos los resultados intermedios se conservan, ya que son necesarios para el pase hacia atrás.\n",
    "\n",
    "\n",
    "* A continuación, el algoritmo mide el error de salida de la red (es decir, utiliza una función de pérdida que compara la salida deseada y la salida real de la red, y devuelve alguna medida del error).\n",
    "\n",
    "\n",
    "* Luego calcula cuánto contribuyeron al error cada sesgo de salida y cada conexión a la capa de salida. Esto se hace analíticamente aplicando la regla de la cadena (tal vez la regla más fundamental en el cálculo), lo que hace que este paso sea rápido y preciso.\n",
    "\n",
    "\n",
    "* A continuación, el algoritmo mide cuánto de estas contribuciones de error provienen de cada conexión en la capa de abajo, de nuevo usando la regla de la cadena, trabajando hacia atrás hasta que llega a la capa de entrada. Como se explicó anteriormente, este paso inverso mide de manera eficiente el gradiente de error a través de todos los pesos y sesgos de conexión en la red propagando el gradiente de error hacia atrás a través de la red (de ahí el nombre del algoritmo).\n",
    "\n",
    "\n",
    "* Finalmente, el algoritmo realiza un paso de descenso de gradiente para ajustar todos los pesos de conexión en la red, utilizando los gradientes de error que acaba de calcular.\n",
    "\n",
    "\n",
    "#### ADVERTENCIA\n",
    "\n",
    "Es importante inicializar los pesos de conexión de todas las capas ocultas al azar, de lo contrario el entrenamiento fallará. Por ejemplo, si inicializas todos los pesos y sesgos a cero, entonces todas las neuronas de una capa dada serán perfectamente idénticas y, por lo tanto, la retropropagación las afectará exactamente de la misma manera, por lo que seguirán siendo idénticas. En otras palabras, a pesar de tener cientos de neuronas por capa, su modelo actuará como si solo tuviera una neurona por capa: no será demasiado inteligente. Si en cambio inicializas los pesos al azar, rompes la simetría y permites que la retropropagación entrene a un equipo diverso de neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0144764",
   "metadata": {},
   "source": [
    "En resumen, la retropropagación hace predicciones para un mini-batch (paso hacia adelante), mide el error, luego pasa por cada capa a la inversa para medir la contribución de error de cada parámetro (paso inverso) y finalmente ajusta los pesos y sesgos de conexión para reducir el error (paso de descenso de gradiente).\n",
    "\n",
    "Para que el backprop funcione correctamente, Rumelhart y sus colegas hicieron un cambio clave en la arquitectura del MLP: reemplazaron la función de paso con la función logística, **σ(z) = 1 / (1 + exp(-z))**, también llamada función sigmoide. Esto fue esencial porque la función de paso contiene solo segmentos planos, por lo que no hay gradiente con el que trabajar (el descenso del gradiente no se puede mover en una superficie plana), mientras que la función sigmoide tiene una derivada distinta de cero bien definida en todas partes, lo que permite que el descenso del gradiente haga algún progreso en cada paso. De hecho, el algoritmo de retropropagación funciona bien con muchas otras funciones de activación, no solo con la función sigmoide. Aquí hay otras dos opciones populares:\n",
    "\n",
    "\n",
    "- La **función tangente hiperbólica: tanh(z) = 2σ(2z) - 1**\n",
    "    \n",
    "    Al igual que la función sigmoide, esta función de activación tiene forma de S, es continua y diferenciable, pero su valor de salida varía de -1 a 1 (en lugar de 0 a 1 en el caso de la función sigmoide). Ese rango tiende a hacer que la producción de cada capa esté más o menos centrada alrededor de 0 al comienzo del entrenamiento, lo que a menudo ayuda a acelerar la convergencia.\n",
    "\n",
    "\n",
    "- La **función de la unidad lineal rectificada: ReLU(z) = max(0, z)**\n",
    "\n",
    "    La función ReLU es continua, pero desafortunadamente no es diferenciable en z = 0 (la pendiente cambia abruptamente, lo que puede hacer que el descenso de gradiente rebote), y su derivada es 0 para z < 0. En la práctica, sin embargo, funciona muy bien y tiene la ventaja de ser rápido de calcular, por lo que se ha convertido en el valor predeterminado.⁠11 Es importante destacar que el hecho de que no tenga un valor de salida máximo ayuda a reducir algunos problemas durante el descenso del gradiente (regresemos a esto en el capítulo 11)\n",
    "    \n",
    "Estas funciones de activación populares y sus derivados están representados en la Figura 10-8. ¡Pero espera! ¿Por qué necesitamos funciones de activación en primer lugar? Bueno, si encadenas varias transformaciones lineales, todo lo que obtienes es una transformación lineal. Por ejemplo, si f(x) = 2x + 3 y g(x) = 5x - 1, entonces encadenar estas dos funciones lineales le da otra función lineal: f(g(x)) = 2(5x - 1) + 3 = 10x + 1. Así que si no tienes algo de no linealidad entre capas, entonces incluso una pila profunda de capas es equivalente a una sola capa, y no puedes resolver problemas muy complejos con eso. Por el contrario, un DNN lo suficientemente grande con activaciones no lineales puede aproximarse teóricamente a cualquier función continua.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1008.png)\n",
    "\n",
    "_Figura 10-8. Funciones de activación (izquierda) y sus derivadas (derecha)_\n",
    "\n",
    "¡vale! Sabes de dónde vienen las redes neuronales, cuál es su arquitectura y cómo calcular sus salidas. También has aprendido sobre el algoritmo de retropropagación. \n",
    "\n",
    "Pero, ¿qué puedes hacer exactamente con las redes neuronales?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc5b65b",
   "metadata": {},
   "source": [
    "## MLP de regresión\n",
    "\n",
    "\n",
    "En primer lugar, los MLP se pueden utilizar para tareas de regresión. Si quieres predecir un solo valor (por ejemplo, el precio de una casa, dadas muchas de sus características), entonces solo necesitas una sola neurona de salida: su salida es el valor predicho. Para la regresión multivariada (es decir, para predecir múltiples valores a la vez), se necesita una neurona de salida por dimensión de salida. Por ejemplo, para localizar el centro de un objeto en una imagen, necesitas predecir las coordenadas 2D, por lo que necesitas dos neuronas de salida. Si también quieres colocar un cuadro delimitante alrededor del objeto, entonces necesitas dos números más: el ancho y la altura del objeto. Por lo tanto, terminas con cuatro neuronas de salida.\n",
    "\n",
    "\n",
    "Scikit-Learn incluye una clase `MLPRegressor`, así que usémosla para construir un MLP con tres capas ocultas compuestas de 50 neuronas cada una y entrenémoslo en el conjunto de datos de viviendas de California. Para simplificar, usaremos la función `fetch_california_housing()` de Scikit-Learn para cargar los datos. Este conjunto de datos es más simple que el que usamos en el Capítulo 2, ya que contiene solo características numéricas (no hay ninguna característica de `ocean_proximity`) y no faltan valores. \n",
    "\n",
    "\n",
    "El siguiente código comienza obteniendo y dividiendo el conjunto de datos, luego crea una canalización para estandarizar las características de entrada antes de enviarlas al `MLPRegressor`. Esto es muy importante para las redes neuronales porque se entrenan utilizando el descenso de gradiente y, como vimos en el Capítulo 4, el descenso de gradiente no converge muy bien cuando las características tienen escalas muy diferentes. Finalmente, el código entrena el modelo y evalúa su error de validación. \n",
    "\n",
    "\n",
    "El modelo utiliza la función de activación ReLU en las capas ocultas y utiliza una variante de descenso de gradiente llamada Adam (consulte el Capítulo 11) para minimizar el error cuadrático medio, con un poco de regularización ℓ2 (que puede controlar mediante el hiperparámetro `alfa`). ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6030cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)  # about 0.505"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ead1e",
   "metadata": {},
   "source": [
    "Tenemos un RMSE de validación de aproximadamente 0,505, que es comparable a lo que se obtenería con un clasificador de bosques aleatorio. ¡No está mal para un primer intento!\n",
    "\n",
    "\n",
    "Tenga en cuenta que este MLP no utiliza ninguna función de activación para la capa de salida, por lo que es libre de generar cualquier valor que desee. En general, esto está bien, pero si desea garantizar que la salida siempre será positiva, entonces debe usar la función de activación ReLU en la capa de salida, o la función de activación softplus, que es una variante suave de ReLU: \n",
    "\n",
    "**softplus(z) = iniciar sesión(1 + exp(z))**. \n",
    "\n",
    "Softplus está cerca de 0 cuando z es negativo y cerca de z cuando z es positivo. Finalmente, si desea garantizar que las predicciones siempre estarán dentro de un rango determinado de valores, entonces debe usar la función sigmoidea o la tangente hiperbólica y escalar los objetivos al rango apropiado: 0 a 1 para sigmoide y –1 a 1 para tanh. \n",
    "\n",
    "Lamentablemente, la clase `MLPRegressor` no admite funciones de activación en la capa de salida.\n",
    "\n",
    "\n",
    "#### ADVERTENCIA ---------------------------------------------------------------\n",
    "\n",
    "Construir y entrenar un MLP estándar con Scikit-Learn en solo unas pocas líneas de código es muy conveniente, pero las características de la red neuronal son limitadas. Es por eso que cambiaremos a Keras en la segunda parte de este capítulo.\n",
    "#### ---------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "La clase `MLPRegressor` usa el error cuadrático medio, que generalmente es lo que desea para la regresión, pero si tiene muchos valores atípicos en el conjunto de entrenamiento, es posible que prefiera usar el error absoluto medio. Alternativamente, es posible que desee utilizar la pérdida de Huber, que es una combinación de ambas. Es cuadrático cuando el error es menor que un umbral δ (típicamente 1) pero lineal cuando el error es mayor que δ. La parte lineal la hace menos sensible a los valores atípicos que el error cuadrático medio, y la parte cuadrática le permite converger más rápido y ser más precisa que el error absoluto medio. Sin embargo, `MLPRegressor` solo admite MSE.\n",
    "\n",
    "La tabla 10-1 resume la arquitectura típica de un MLP de regresión.\n",
    "\n",
    "Tabla 10-1. **Arquitectura MLP de regresión típica**\n",
    "\n",
    "\n",
    "| Hiperparámetro             | Valor típico                                                                                            |\n",
    "|----------------------------|---------------------------------------------------------------------------------------------------------|\n",
    "| # capas ocultas            | Depende del problema, pero normalmente de 1 a 5                                                         |\n",
    "| # neuronas por capa oculta | Depende del problema, pero normalmente de 10 a 100                                                      |\n",
    "| # neuronas de salida       | 1 por dimensión de predicción                                                                           |\n",
    "| Activación oculta          | ReLU                                                                                                    |\n",
    "| Activación de salida       | Ninguno, o ReLU/softplus (si las salidas son positivas) o sigmoid/tanh (si las salidas están limitadas) |\n",
    "| Función de pérdida         | MSE, o Huber si son valores atípicos                                                                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59e558",
   "metadata": {},
   "source": [
    "## Clasificación MLP\n",
    "\n",
    "\n",
    "Los MLP también se pueden utilizar para tareas de clasificación. Para un problema de clasificación binaria, solo necesita una sola neurona de salida que utilice la función de activación sigmoide: la salida será un número entre 0 y 1, que puede interpretar como la probabilidad estimada de la clase positiva. La probabilidad estimada de la clase negativa es igual a uno menos ese número.\n",
    "\n",
    "Los MLP también pueden manejar fácilmente tareas de clasificación binaria multimarca (véase el capítulo 3). Por ejemplo, podría tener un sistema de clasificación de correo electrónico que predice si cada correo electrónico entrante es jamón o spam, y al mismo tiempo predice si es un correo electrónico urgente o no urgente. En este caso, necesitaría dos neuronas de salida, ambas utilizando la función de activación sigmoide: la primera generaría la probabilidad de que el correo electrónico sea spam y la segunda generaría la probabilidad de que sea urgente. De manera más general, dedicarías una neurona de salida para cada clase positiva. Tenga en cuenta que las probabilidades de salida no suman necesariamente 1. Esto permite que el modelo genere cualquier combinación de etiquetas: puede tener jamón no urgente, jamón urgente, spam no urgente y tal vez incluso spam urgente (aunque eso probablemente sería un error).\n",
    "\n",
    "\n",
    "Si cada instancia puede pertenecer solo a una sola clase, de tres o más clases posibles (por ejemplo, clases del 0 al 9 para la clasificación de imágenes de dígitos), entonces necesita tener una neurona de salida por clase, y debe usar la función de activación softmax para toda la capa de salida (consulte la Figura 10-9). La función softmax (introducida en el capítulo 4) garantizará que todas las probabilidades estimadas estén entre 0 y 1 y que sumen 1, ya que las clases son exclusivas. Como viste en el capítulo 3, esto se llama clasificación multiclase.\n",
    "\n",
    "\n",
    "En cuanto a la función de pérdida, ya que estamos prediciendo distribuciones de probabilidad, la pérdida de entropía cruzada (o entropía x o pérdida de registro para abreviar, véase el Capítulo 4) es generalmente una buena opción.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1009.png)\n",
    "\n",
    "_Figura 10-9. Un MLP moderno (incluyendo ReLU y softmax) para la clasificación_\n",
    "\n",
    "\n",
    "Scikit-Learn tiene una clase `MLPClassifier` en el paquete `sklearn.neural_network`. Es casi idéntica a la clase `MLPRegressor`, excepto que minimiza la entropía cruzada en lugar del MSE. Pruébelo ahora, por ejemplo en el conjunto de datos del iris. Es casi una tarea lineal, por lo que una sola capa con 5 a 10 neuronas debería ser suficiente (asegúrate de escalar las características).\n",
    "\n",
    "La tabla 10-2 resume la arquitectura típica de una clasificación MLP.\n",
    "\n",
    "\n",
    "Tabla 10-2. **Clasificación típica de la arquitectura MLP**\n",
    "\n",
    "| Hiperparametro                  | Clasificación binaria                               | Clasificación binaria multimarca                    | Clasificación multiclase                            |\n",
    "|---------------------------------|-----------------------------------------------------|-----------------------------------------------------|-----------------------------------------------------|\n",
    "| # capas ocultas                 | Normalmente de 1 a 5 capas, dependiendo de la tarea | Normalmente de 1 a 5 capas, dependiendo de la tarea | Normalmente de 1 a 5 capas, dependiendo de la tarea |\n",
    "| # neuronas de salida            | 1                                                   | 1 por etiqueta binaria                              | 1 por clase                                         |\n",
    "| Activación de la capa de salida | Sigmoide                                            | Sigmoide                                            | Softmax                                             |\n",
    "| Función de pérdida              | X-entropía                                          | X-entropía                                          | X-entropía                                          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5485e",
   "metadata": {},
   "source": [
    "##### TIP\n",
    "\n",
    "Antes de seguir, te recomiendo que pases por el ejercicio 1 al final de este capítulo. Jugarás con varias arquitecturas de redes neuronales y visualizarás sus salidas usando el patio de recreo TensorFlow (TensorFlow Playground). Esto será muy útil para comprender mejor los MLP, incluidos los efectos de todos los hiperparámetros (número de capas y neuronas, funciones de activación y más).\n",
    "\n",
    "¡Ahora tienes todos los conceptos que necesitas para empezar a implementar MLP con Keras!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03059889",
   "metadata": {},
   "source": [
    "# Implementación de MLP con Keras\n",
    "\n",
    "\n",
    "Keras es la API de aprendizaje profundo de alto nivel de TensorFlow: te permite construir, entrenar, evaluar y ejecutar todo tipo de redes neuronales. \n",
    "\n",
    "La biblioteca original de Keras fue desarrollada por François Chollet como parte de un proyecto de investigación y fue lanzada como un proyecto independiente de código abierto en marzo de 2015. \n",
    "\n",
    "Rápidamente ganó popularidad, debido a su facilidad de uso, flexibilidad y hermoso diseño."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b36ff",
   "metadata": {},
   "source": [
    "##### NOTA\n",
    "\n",
    "Keras solía admitir múltiples backends, incluidos TensorFlow, PlaidML, Theano y Microsoft Cognitive Toolkit (CNTK) (los dos últimos están tristemente obsoletos), pero desde la versión 2.4, Keras es solo para TensorFlow. \n",
    "\n",
    "Del mismo modo, TensorFlow solía incluir múltiples API de alto nivel, pero Keras fue elegida oficialmente como su API de alto nivel preferida cuando salió TensorFlow 2. \n",
    "\n",
    "La instalación de TensorFlow también instalará automáticamente Keras, y Keras no funcionará sin TensorFlow instalado. \n",
    "\n",
    "En resumen, Keras y TensorFlow se enamoraron y se casaron. Otras bibliotecas populares de aprendizaje profundo incluyen PyTorch de Facebook y JAX de Google.\n",
    "##### ------------------------------------------------------------------------------------------\n",
    "\n",
    "¡Ahora usemos Keras! Comenzaremos construyendo un MLP para la clasificación de imágenes.\n",
    "\n",
    "##### ------------------------------------------------------------------------------------------\n",
    "\n",
    "##### NOTA\n",
    "\n",
    "Los tiempos de ejecución de Colab vienen con versiones recientes de TensorFlow y Keras preinstaladas. Sin embargo, si desea instalarlos en su propia máquina, consulte las instrucciones de instalación en https://homl.info/install.\n",
    "\n",
    "\n",
    "## Creación de un clasificador de imágenes utilizando la API secuencial\n",
    "\n",
    "\n",
    "Primero, necesitamos cargar un conjunto de datos. \n",
    "Utilizaremos Fashion MNIST, que es un reemplazo directo de MNIST (introducido en el capítulo 3). \n",
    "\n",
    "Tiene exactamente el mismo formato que MNIST (70.000 imágenes en escala de grises de 28 × 28 píxeles cada una, con 10 clases), pero las imágenes representan artículos de moda en lugar de dígitos escritos a mano, por lo que cada clase es más diversa, y el problema resulta ser significativamente más desafiante que el MNIST. \n",
    "\n",
    "Por ejemplo, un modelo lineal simple alcanza una precisión de alrededor del 92 % en MNIST, pero solo alrededor del 83 % en Fashion MNIST.\n",
    "\n",
    "### Uso de Keras para cargar el conjunto de datos\n",
    "\n",
    "Keras proporciona algunas funciones de utilidad para obtener y cargar conjuntos de datos comunes, incluyendo MNIST, Fashion MNIST y algunos más. Vamos a cargar Fashion MNIST. Ya está mezclado y dividido en un conjunto de entrenamiento (60.000 imágenes) y un conjunto de pruebas (10.000 imágenes), pero mantendré las últimas 5.000 imágenes del conjunto de entrenamiento para su validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821f8179",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3k/rj832x716_563czpglqh2mmw0000gn/T/ipykernel_1038/161806128.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfashion_mnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9848a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc875642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
