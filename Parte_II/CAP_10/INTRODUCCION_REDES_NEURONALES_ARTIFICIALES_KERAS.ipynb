{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73b5b05c",
   "metadata": {},
   "source": [
    "Los pájaros nos inspiraron a volar, las plantas de bardana inspiraron el velcro y la naturaleza ha inspirado innumerables inventos más. Parece lógico, entonces, mirar la arquitectura del cerebro en busca de inspiración sobre cómo construir una máquina inteligente. \n",
    "\n",
    "Esta es la lógica que desencadenó las redes neuronales artificiales (ANN), modelos de aprendizaje automático inspirados en las redes de neuronas biológicas que se encuentran en nuestros cerebros. Sin embargo, aunque los aviones se inspiraron en las aves, no tienen que batir sus alas para volar. Del mismo modo, los ANN se han vuelto gradualmente bastante diferentes de sus primos biológicos. \n",
    "\n",
    "Algunos investigadores incluso argumentan que deberíamos abandonar la analogía biológica por completo (por ejemplo, diciendo \"unidades\" en lugar de \"neurones\"), para que no restrinjamos nuestra creatividad a sistemas biológicamente plausibles.⁠\n",
    "\n",
    "Los ANN son el núcleo del aprendizaje profundo. Son versátiles, potentes y escalables, lo que los hace ideales para abordar tareas de aprendizaje automático grandes y altamente complejas, como clasificar miles de millones de imágenes (por ejemplo, Google Images), potenciar los servicios de reconocimiento de voz (por ejemplo, Siri de Apple), recomendar los mejores vídeos para ver a cientos de millones de usuarios todos los días (por ejemplo, YouTube) o aprender a vencer al campeón del mundo en el juego de Go (AlphaGo de DeepMind).\n",
    "\n",
    "La primera parte de este capítulo presenta redes neuronales artificiales, comenzando con un rápido recorrido por las primeras arquitecturas de ANN y llevando a los perceptrones multicapa, que se utilizan mucho hoy en día (otras arquitecturas se explorarán en los próximos capítulos). En la segunda parte, veremos cómo implementar redes neuronales utilizando la API Keras de TensorFlow. \n",
    "\n",
    "Esta es una API de alto nivel muy bien diseñada y sencilla para construir, entrenar, evaluar y ejecutar redes neuronales. Pero no te dejes engañar por su simplicidad: es lo suficientemente expresivo y flexible como para que puedas construir una amplia variedad de arquitecturas de redes neuronales. De hecho, probablemente será suficiente para la mayoría de sus casos de uso. Y si alguna vez necesita flexibilidad adicional, siempre puede escribir componentes personalizados de Keras utilizando su API de nivel inferior, o incluso usar TensorFlow directamente, como verá en el capítulo 12.\n",
    "\n",
    "Pero primero, ¡vamos atrás en el tiempo para ver cómo surgieron las redes neuronales artificiales!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38730ead",
   "metadata": {},
   "source": [
    "# De las neuronas biológicas a las artificiales\n",
    "\n",
    "Sorprendentemente, los ANN han existido durante bastante tiempo: fueron introducidos por primera vez en 1943 por el neurofisiólogo Warren McCulloch y el matemático Walter Pitts. En su artículo histórico⁠2 \"Un cálculo lógico de ideas inmanentes en la actividad nerviosa\", McCulloch y Pitts presentaron un modelo computacional simplificado de cómo las neuronas biológicas podrían trabajar juntas en los cerebros animales para realizar cálculos complejos utilizando la lógica proposicional. Esta fue la primera arquitectura de red neuronal artificial. Desde entonces se han inventado muchas otras arquitecturas, como verás.\n",
    "\n",
    "\n",
    "Los primeros éxitos de los ANN llevaron a la creencia generalizada de que pronto estaríamos conversando con máquinas verdaderamente inteligentes. Cuando quedó claro en la década de 1960 que esta promesa no se cumpliría (al menos durante bastante tiempo), la financiación voló a otro lugar, y los ANN entraron en un largo invierno. A principios de la década de 1980, se inventaron nuevas arquitecturas y se desarrollaron mejores técnicas de entrenamiento, lo que provocó un resurgimiento del interés en el conexionismo, el estudio de las redes neuronales. Pero el progreso era lento, y en la década de 1990 se habían inventado otras poderosas técnicas de aprendizaje automático, como las máquinas vectoriales de soporte (véase el capítulo 5). Estas técnicas parecían ofrecer mejores resultados y bases teóricas más sólidas que las ANN, por lo que una vez más se suspendo el estudio de las redes neuronales.\n",
    "\n",
    "\n",
    "Ahora estamos siendo testigos de otra ola de interés en los ANN. ¿Esta ola se apague como las anteriores? Bueno, aquí hay algunas buenas razones para creer que esta vez es diferente y que el renovado interés en los ANN tendrá un impacto mucho más profundo en nuestras vidas:\n",
    "\n",
    "\n",
    "* Ahora hay una gran cantidad de datos disponibles para entrenar las redes neuronales, y los ANN con frecuencia superan a otras técnicas de aprendizaje automático en problemas muy grandes y complejos.\n",
    "\n",
    "* El tremendo aumento de la potencia informática desde la década de 1990 ahora hace posible entrenar grandes redes neuronales en un período de tiempo razonable. Esto se debe en parte a la ley de Moore (el número de componentes en los circuitos integrados se ha duplicado aproximadamente cada 2 años en los últimos 50 años), pero también gracias a la industria de los juegos, que ha estimulado la producción de potentes tarjetas GPU por millones. Además, las plataformas en la nube han hecho que este poder sea accesible para todos.\n",
    "\n",
    "* Se han mejorado los algoritmos de entrenamiento. Para ser justos, solo son ligeramente diferentes de los utilizados en la década de 1990, pero estos ajustes relativamente pequeños han tenido un gran impacto positivo.\n",
    "\n",
    "* Algunas limitaciones teóricas de los ANN han resultado ser benignas en la práctica. Por ejemplo, muchas personas pensaron que los algoritmos de entrenamiento de ANN estaban condenados porque era probable que se quedaran atascados en la optima local, pero resulta que esto no es un gran problema en la práctica, especialmente para las redes neuronales más grandes: la optima local a menudo funciona casi tan bien como el óptimo global.\n",
    "\n",
    "* Los ANN parecen haber entrado en un círculo virtuoso de financiación y progreso. Los productos increíbles basados en ANN regularmente aparecen en los titulares, lo que atrae cada vez más atención y financiación hacia ellos, lo que resulta en más y más progreso y productos aún más increíbles.\n",
    "\n",
    "\n",
    "## Neuronas biológicas\n",
    "\n",
    "\n",
    "Antes de hablar sobre las neuronas artificiales, echemos un vistazo rápido a una neurona biológica (representada en la Figura 10-1). Es una célula de aspecto inusual que se encuentra principalmente en los cerebros de los animales. \n",
    "\n",
    "Está compuesto por un cuerpo celular que contiene el núcleo y la mayoría de los componentes complejos de la célula, muchas extensiones ramificadas llamadas dendritas, además de una extensión muy larga llamada axón. \n",
    "\n",
    "La longitud del axón puede ser solo unas pocas veces más larga que la del cuerpo celular, o hasta decenas de miles de veces más larga. Cerca de su extremo, el axón se divide en muchas ramas llamadas telodendria, y en la punta de estas ramas hay estructuras minúsculas llamadas terminales sinápticos (o simplemente sinapsis), que están conectadas a las dendritas o cuerpos celulares de otras neuronas. \n",
    "\n",
    "Las neuronas biológicas producen impulsos eléctricos cortos llamados potenciales de acción (AP, o simplemente señales), que viajan a lo largo de los axones y hacen que las sinapsis liberen señales químicas llamadas neurotransmisores. \n",
    "\n",
    "Cuando una neurona recibe una cantidad suficiente de estos neurotransmisores en unos pocos milisegundos, dispara sus propios impulsos eléctricos (en realidad, depende de los neurotransmisores, ya que algunos de ellos inhiben el disparo de la neurona).\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1001.png)\n",
    "\n",
    "_Figura 10-1. Una neurona biológica⁠_\n",
    "\n",
    "\n",
    "Por lo tanto, las neuronas biológicas individuales parecen comportarse de una manera simple, pero están organizadas en una vasta red de miles de millones, con cada neurona típicamente conectada a miles de otras neuronas. \n",
    "\n",
    "Los cálculos altamente complejos pueden ser realizados por una red de neuronas bastante simples, al igual que una hormiguero compleja puede surgir de los esfuerzos combinados de las hormigas simples. \n",
    "\n",
    "La arquitectura de las redes neuronales biológicas (BNN)⁠5 es objeto de investigación activa, pero se han mapeado algunas partes del cerebro. \n",
    "\n",
    "Estos esfuerzos muestran que las neuronas a menudo están organizadas en capas consecutivas, especialmente en la corteza cerebral (la capa externa del cerebro), como se muestra en la Figura 10-2.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1002.png)\n",
    "\n",
    "_Figura 10-2. Múltiples capas en una red neuronal biológica (corteza humana)⁠_\n",
    "\n",
    "\n",
    "## Cálculos lógicos con neuronas\n",
    "\n",
    "McCulloch y Pitts propusieron un modelo muy simple de la neurona biológica, que más tarde se conoció como una neurona artificial: tiene una o más entradas binarias (on/apagado) y una salida binaria. La neurona artificial activa su salida cuando más de un cierto número de sus entradas están activas. \n",
    "\n",
    "En su artículo, McCulloch y Pitts mostraron que incluso con un modelo tan simplificado es posible construir una red de neuronas artificiales que puedan calcular cualquier proposición lógica que desee. \n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1003.png)\n",
    "\n",
    "_Figura 10-3. ANN que realizan cálculos lógicos simples_\n",
    "\n",
    "\n",
    "Veamos qué hacen estas redes:\n",
    "\n",
    "* La primera red de la izquierda es la función de identidad: si la neurona A se activa, entonces la neurona C también se activa (ya que recibe dos señales de entrada de la neurona A); pero si la neurona A está desactivada, entonces la neurona C también está desactivada.\n",
    "\n",
    "\n",
    "* La segunda red realiza una lógica AND: la neurona C se activa solo cuando ambas neuronas A y B están activadas (una sola señal de entrada no es suficiente para activar la neurona C).\n",
    "\n",
    "\n",
    "* La tercera red realiza un OR lógico: la neurona C se activa si se activa la neurona A o la neurona B (o ambas).\n",
    "\n",
    "\n",
    "* Finalmente, si suponemos que una conexión de entrada puede inhibir la actividad de la neurona (que es el caso de las neuronas biológicas), entonces la cuarta red calcula una propuesta lógica ligeramente más compleja: la neurona C se activa solo si la neurona A está activa y la neurona B está desactivada. Si la neurona A está activa todo el tiempo, entonces obtienes un NO lógico: la neurona C está activa cuando la neurona B está apagada, y viceversa.\n",
    "\n",
    "\n",
    "Puedes imaginar cómo estas redes se pueden combinar para calcular expresiones lógicas complejas (ver los ejercicios al final del capítulo para ver un ejemplo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58d23e8",
   "metadata": {},
   "source": [
    "## El Perceptrón\n",
    "\n",
    "El perceptrón es una de las arquitecturas ANN más simples, inventada en 1957 por Frank Rosenblatt. Se basa en una neurona artificial ligeramente diferente (ver Figura 10-4) llamada unidad lógica de umbral (TLU), o a veces una unidad de umbral lineal (LTU). \n",
    "\n",
    "Las entradas y la salida son números (en lugar de valores binarios de encendido/apagado), y cada conexión de entrada está asociada con un peso. La TLU calcula primero una función lineal de sus entradas: z = w1 x1 + w2 x2 + ⋯ + wn xn + b = **w⊺ x + b**. \n",
    "\n",
    "Luego aplica una función de paso al resultado: hw(x) = step(z). Así que es casi como una regresión logística, excepto que utiliza una función de paso en lugar de la función logística (Capítulo 4). \n",
    "\n",
    "Al igual que en la regresión logística, los parámetros del modelo son los pesos de entrada **w** y el término de sesgo b.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1004.png)\n",
    "\n",
    "_Figura 10-4. TLU: una neurona artificial que calcula una suma ponderada de sus entradas w⊺ x, más un término de sesgo b, y luego aplica una función de paso_\n",
    "\n",
    "\n",
    "La función de paso más común utilizada en los perceptrones es la función de paso Heaviside (ver Ecuación 10-1). A veces se utiliza la función de signo en su lugar.\n",
    "\n",
    "\n",
    "### Ecuación 10-1. Funciones de paso comunes utilizadas en los perceptrones (suponiendo umbral = 0)\n",
    "\n",
    "<a href=\"https://ibb.co/wsHsXnv\"><img src=\"https://i.ibb.co/74c4539/Captura-de-pantalla-2023-12-01-a-las-15-17-57.png\" alt=\"Captura-de-pantalla-2023-12-01-a-las-15-17-57\" border=\"0\"></a>\n",
    "\n",
    "Se puede utilizar una sola TLU para la clasificación binaria lineal simple. \n",
    "\n",
    "Calcula una función lineal de sus entradas, y si el resultado supera un umbral, produce la clase positiva. De lo contrario, produce la clase negativa. Esto puede recordarle la regresión logística (Capítulo 4) o la clasificación lineal de SVM (Capítulo 5). \n",
    "Podrías, por ejemplo, usar una sola TLU para clasificar las flores de iris en función de la longitud y el ancho del pétalo. \n",
    "\n",
    "El entrenamiento de tal TLU requeriría encontrar los valores correctos para w1, w2 y b (el algoritmo de entrenamiento se discutirá en breve).\n",
    "\n",
    "Un perceptrón está compuesto por una o más TLU organizadas en una sola capa, donde cada TLU está conectada a cada entrada. Tal capa se llama capa completamente conectada, o capa densa. \n",
    "Las entradas constituyen la capa de entrada. Y dado que la capa de TLU produce las salidas finales, se llama capa de salida. \n",
    "\n",
    "Por ejemplo, un perceptrón con dos entradas y tres salidas se representa en la Figura 10-5.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1005.png)\n",
    "\n",
    "_Figura 10-5. Arquitectura de un perceptrón con dos entradas y tres neuronas de salida_\n",
    "\n",
    "\n",
    "Este perceptrón puede clasificar instancias simultáneamente en tres clases binarias diferentes, lo que lo convierte en un clasificador multietiqueta. También se puede utilizar para la clasificación multiclase.\n",
    "\n",
    "Gracias a la magia del álgebra lineal, la ecuación 10-2 se puede utilizar para calcular de manera eficiente las salidas de una capa de neuronas artificiales para varias instancias a la vez.\n",
    "\n",
    "\n",
    "### Ecuación 10-2. Computación de las salidas de una capa totalmente conectada\n",
    "\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/9VgB3QP/Captura-de-pantalla-2023-12-01-a-las-15-20-16.png\" alt=\"Captura-de-pantalla-2023-12-01-a-las-15-20-16\" border=\"0\"></a><br /><br />\n",
    "\n",
    "\n",
    "En esta ecuación:\n",
    "\n",
    "* Como siempre, X representa la matriz de características de entrada. Tiene una fila por instancia y una columna por característica.\n",
    "\n",
    "\n",
    "* La matriz de peso W contiene todos los pesos de conexión. Tiene una fila por entrada y una columna por neurona.\n",
    "\n",
    "\n",
    "* El vector de sesgo b contiene todos los términos de sesgo: uno por neurona.\n",
    "\n",
    "\n",
    "* La función φ se llama función de activación: cuando las neuronas artificiales son TLU, es una función de paso (en breve discutiremos otras funciones de activación).\n",
    "\n",
    "\n",
    "#### NOTA --------------------------------------------------------------------------\n",
    "\n",
    "En matemáticas, la suma de una matriz y un vector no está definida. \n",
    "Sin embargo, en la ciencia de datos, permitimos la \"difusión\": añadir un vector a una matriz significa añadirlo a cada fila de la matriz. Por lo tanto, XW + b primero multiplica X por W, lo que da como resultado una matriz con una fila por instancia y una columna por salida, luego agrega el vector b a cada fila de esa matriz, lo que agrega cada término de sesgo a la salida correspondiente, para cada instancia. Además, φ se aplica a cada elemento de la matriz resultante.\n",
    "\n",
    "#### ----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Entonces, ¿cómo se entrena un perceptrón? El algoritmo de entrenamiento de perceptrón propuesto por Rosenblatt se inspiró en gran medida en la regla de Hebb. En su libro de 1949 The Organization of Behavior (Wiley), Donald Hebb sugirió que cuando una neurona biológica desencadena otra neurona a menudo, la conexión entre estas dos neuronas se hace más fuerte. Siegrid Löwel más tarde resumió la idea de Hebb en la frase pegadiza, \"Células que se disparan juntas, se conectan juntas\"; es decir, el peso de conexión entre dos neuronas tiende a aumentar cuando se disparan simultáneamente. Esta regla más tarde se conoció como la regla de Hebb (o aprendizaje hebbio). Los perceptrones se entrenan utilizando una variante de esta regla que tiene en cuenta el error cometido por la red cuando hace una predicción; la regla de aprendizaje del perceptrón refuerza las conexiones que ayudan a reducir el error. Más específicamente, el perceptrón se alimenta con una instancia de entrenamiento a la vez, y para cada instancia hace sus predicciones. Para cada neurona de salida que produjo una predicción incorrecta, refuerza los pesos de conexión de las entradas que habrían contribuido a la predicción correcta. La regla se muestra en la ecuación 10-3.\n",
    "\n",
    "\n",
    "### Ecuación 10-3. Regla de aprendizaje de Perceptron (actualización de peso)\n",
    "\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/smFhXMB/Captura-de-pantalla-2023-12-01-a-las-15-23-18.png\" alt=\"Captura-de-pantalla-2023-12-01-a-las-15-23-18\" border=\"0\"></a>\n",
    "\n",
    "\n",
    "En esta ecuación:\n",
    "\n",
    "* **wi, j** es el peso de conexión entre la entrada ith y la jthneuron.\n",
    "\n",
    "* **xi** es el valor de entrada de la instancia de entrenamiento actual.\n",
    "\n",
    "* **y^j** es la salida de la neurona de salida jth para la instancia de entrenamiento actual.\n",
    "\n",
    "* **yj** es la salida objetivo de la neurona de salida jth para la instancia de entrenamiento actual.\n",
    "\n",
    "* **η** es la tasa de aprendizaje (véase el capítulo 4).\n",
    "\n",
    "\n",
    "El límite de decisión de cada neurona de salida es lineal, por lo que los perceptrones son incapaces de aprender patrones complejos (al igual que los clasificadores de regresión logística). Sin embargo, si las instancias de entrenamiento son linealmente separables, Rosenblatt demostró que este algoritmo convergería a una solución.⁠ \n",
    "\n",
    "Esto se llama el **teorema de convergencia del perceptrón**.\n",
    "\n",
    "Scikit-Learn proporciona una clase Perceptron que se puede usar más o menos como cabría esperar, por ejemplo, en el conjunto de datos del iris (presentado en el capítulo 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b3ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = (iris.target == 0)  # Iris setosa\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "y_pred = per_clf.predict(X_new)  # predice True y False para esas dos flores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c5e0b",
   "metadata": {},
   "source": [
    "Es posible que haya notado que el algoritmo de aprendizaje del perceptrón se parece mucho al descenso de gradiente estocástico (presentado en el Capítulo 4). \n",
    "\n",
    "\n",
    "De hecho, la clase `Perceptron` de Scikit-Learn equivale a usar un `SGDClassifier` con los siguientes hiperparámetros: \n",
    "\n",
    "\n",
    "`loss=\"perceptron\"`, `learning_rate=\"constant\"`, `eta0=1` (la tasa de aprendizaje) y `penality=None` (sin regularización).\n",
    "\n",
    "\n",
    "En su monografía de 1969 Perceptrones, Marvin Minsky y Seymour Papert destacaron una serie de debilidades graves de los perceptrones, en particular, el hecho de que son incapaces de resolver algunos problemas triviales (por ejemplo, el problema de clasificación exclusiva de OR (XOR); véase el lado izquierdo de la Figura 10-6). Esto es cierto para cualquier otro modelo de clasificación lineal (como los clasificadores de regresión logística), pero los investigadores habían esperado mucho más de los perceptrones, y algunos estaban tan decepcionados que abandonaron por completo las redes neuronales en favor de problemas de nivel superior como la lógica, la resolución de problemas y la búsqueda. La falta de aplicaciones prácticas tampoco ayudó.\n",
    "\n",
    "\n",
    "Resulta que algunas de las limitaciones de los perceptrones se pueden eliminar apilando múltiples perceptrones. \n",
    "\n",
    "El ANN resultante se llama **perceptrón multicapa (MLP)**. \n",
    "\n",
    "Un MLP puede resolver el problema XOR, ya que puede verificar calculando la salida del MLP representado en el lado derecho de la Figura 10-6: con entradas (0, 0) o (1, 1), las salidas de red 0, y con entradas (0, 1) o (1, 0) sale 1. ¡Intenta verificar que esta red realmente resuelve el problema de XOR!\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1006.png)\n",
    "\n",
    "_Figura 10-6. Problema de clasificación XOR y un MLP que lo resuelve_\n",
    "\n",
    "#### NOTA --------------------------------------------------------------------------\n",
    "\n",
    "A diferencia de los clasificadores de regresión logística, los perceptrones no producen una probabilidad de clase. Esta es una de las razones para preferir la regresión logística a los perceptrones. \n",
    "Además, los perceptrones no utilizan ninguna regularización por defecto, y el entrenamiento se detiene tan pronto como no hay más errores de predicción en el conjunto de entrenamiento, por lo que el modelo normalmente no generaliza tan bien como la regresión logística o un clasificador lineal de SVM. \n",
    "Sin embargo, los perceptrones pueden entrenar un poco más rápido.\n",
    "#### ---------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "## El perceptrón multicapa y la retropropagación\n",
    "\n",
    "\n",
    "Un MLP se compone de una capa de entrada, una o más capas de TLU llamadas capas ocultas y una capa final de TLU llamada capa de salida (ver Figura 10-7). Las capas cercanas a la capa de entrada generalmente se llaman capas inferiores, y las cercanas a las salidas generalmente se llaman capas superiores.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1007.png)\n",
    "\n",
    "_Figura 10-7. Arquitectura de un perceptrón multicapa con dos entradas, una capa oculta de cuatro neuronas y tres neuronas de salida_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab3ad2",
   "metadata": {},
   "source": [
    "#### NOTA ---------------------------------------------------------------------------\n",
    "\n",
    "La señal fluye solo en una dirección (desde las entradas hasta las salidas), por lo que esta arquitectura es un ejemplo de una red neuronal de avance (FNN).\n",
    "#### -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed77154",
   "metadata": {},
   "source": [
    "Cuando un ANN contiene una pila profunda de capas ocultas, ⁠9 se llama red neuronal profunda (DNN). El campo del aprendizaje profundo estudia los DNN, y más en general está interesado en modelos que contengan pilas profundas de cálculos. Aun así, muchas personas hablan de aprendizaje profundo siempre que hay redes neuronales involucradas (incluso las superficiales).\n",
    "\n",
    "Durante muchos años, los investigadores lucharon por encontrar una manera de entrenar a los MLP, sin éxito. A principios de la década de 1960, varios investigadores discutieron la posibilidad de usar el descenso de gradiente para entrenar redes neuronales, pero como vimos en el Capítulo 4, esto requiere calcular los gradientes del error del modelo con respecto a los parámetros del modelo; no estaba claro en ese momento cómo hacer esto de manera eficiente con un modelo tan complejo que contenía tantos parámetros, especialmente con las computadoras que tenían en ese entonces.\n",
    "\n",
    "Luego, en 1970, un investigador llamado Seppo Linnainmaa introdujo en su tesis de maestría una técnica para calcular todos los gradientes de forma automática y eficiente. Este algoritmo ahora se llama diferenciación automática de modo inverso (o diferencia automática de modo inverso para abreviar). En solo dos pasadas a través de la red (una hacia adelante, otra hacia atrás), es capaz de calcular los gradientes del error de la red neuronal con respecto a cada parámetro del modelo. En otras palabras, puede averiguar cómo se debe ajustar cada peso de conexión y cada sesgo para reducir el error de la red neuronal. Estos gradientes se pueden usar para realizar un paso de descenso de gradiente. Si repite este proceso de calcular los gradientes automáticamente y dar un paso de descenso de gradiente, el error de la red neuronal caerá gradualmente hasta que finalmente alcance un mínimo. Esta combinación de disdiff automático de modo inverso y descenso de gradiente ahora se llama backpropagation (o backprop para abreviar).\n",
    "\n",
    "#### NOTA\n",
    "\n",
    "Hay varias técnicas de autodiff, con diferentes pros y contras. La diferencia automática de modo inverso es adecuada cuando la función para diferenciar tiene muchas variables (por ejemplo, pesos de conexión y sesgos) y pocas salidas (por ejemplo, una pérdida). Si quieres obtener más información sobre autodiff, echa un vistazo al Apéndice B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ddfa9c",
   "metadata": {},
   "source": [
    "La retropropagación se puede aplicar a todo tipo de gráficos computacionales, no solo a las redes neuronales: de hecho, la tesis de maestría de Linnainmaa no era sobre redes neuronales, era más general. pasaron varios años más antes de que el backprop comenzara a usarse para entrenar redes neuronales, pero todavía no era la corriente principal. Luego, en 1985, David Rumelhart, Geoffrey Hinton y Ronald Williams publicaron un innovador documento⁠10 que analizaba cómo la retropropagación permitía a las redes neuronales aprender representaciones internas útiles. Sus resultados fueron tan impresionantes que la retropropagación se popularizó rápidamente en el campo. Hoy en día, es, con mucho, la técnica de entrenamiento más popular para las redes neuronales.\n",
    "\n",
    "Revisémos cómo funciona la retropropagación de nuevo con un poco más de detalle:\n",
    "\n",
    "\n",
    "* Maneja un mini lote a la vez (por ejemplo, que contiene 32 instancias cada uno), y pasa por el conjunto de entrenamiento completo varias veces. Cada pase se llama una época.\n",
    "\n",
    "\n",
    "* Cada mini-lote entra en la red a través de la capa de entrada. A continuación, el algoritmo calcula la salida de todas las neuronas de la primera capa oculta, para cada instancia del mini-lote. El resultado se pasa a la siguiente capa, su salida se calcula y se pasa a la siguiente capa, y así su así hasta que obtengamos la salida de la última capa, la capa de salida. Este es el pase hacia adelante: es exactamente como hacer predicciones, excepto que todos los resultados intermedios se conservan, ya que son necesarios para el pase hacia atrás.\n",
    "\n",
    "\n",
    "* A continuación, el algoritmo mide el error de salida de la red (es decir, utiliza una función de pérdida que compara la salida deseada y la salida real de la red, y devuelve alguna medida del error).\n",
    "\n",
    "\n",
    "* Luego calcula cuánto contribuyeron al error cada sesgo de salida y cada conexión a la capa de salida. Esto se hace analíticamente aplicando la regla de la cadena (tal vez la regla más fundamental en el cálculo), lo que hace que este paso sea rápido y preciso.\n",
    "\n",
    "\n",
    "* A continuación, el algoritmo mide cuánto de estas contribuciones de error provienen de cada conexión en la capa de abajo, de nuevo usando la regla de la cadena, trabajando hacia atrás hasta que llega a la capa de entrada. Como se explicó anteriormente, este paso inverso mide de manera eficiente el gradiente de error a través de todos los pesos y sesgos de conexión en la red propagando el gradiente de error hacia atrás a través de la red (de ahí el nombre del algoritmo).\n",
    "\n",
    "\n",
    "* Finalmente, el algoritmo realiza un paso de descenso de gradiente para ajustar todos los pesos de conexión en la red, utilizando los gradientes de error que acaba de calcular.\n",
    "\n",
    "\n",
    "#### ADVERTENCIA\n",
    "\n",
    "Es importante inicializar los pesos de conexión de todas las capas ocultas al azar, de lo contrario el entrenamiento fallará. Por ejemplo, si inicializas todos los pesos y sesgos a cero, entonces todas las neuronas de una capa dada serán perfectamente idénticas y, por lo tanto, la retropropagación las afectará exactamente de la misma manera, por lo que seguirán siendo idénticas. En otras palabras, a pesar de tener cientos de neuronas por capa, su modelo actuará como si solo tuviera una neurona por capa: no será demasiado inteligente. Si en cambio inicializas los pesos al azar, rompes la simetría y permites que la retropropagación entrene a un equipo diverso de neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0144764",
   "metadata": {},
   "source": [
    "En resumen, la retropropagación hace predicciones para un mini-batch (paso hacia adelante), mide el error, luego pasa por cada capa a la inversa para medir la contribución de error de cada parámetro (paso inverso) y finalmente ajusta los pesos y sesgos de conexión para reducir el error (paso de descenso de gradiente).\n",
    "\n",
    "Para que el backprop funcione correctamente, Rumelhart y sus colegas hicieron un cambio clave en la arquitectura del MLP: reemplazaron la función de paso con la función logística, **σ(z) = 1 / (1 + exp(-z))**, también llamada función sigmoide. Esto fue esencial porque la función de paso contiene solo segmentos planos, por lo que no hay gradiente con el que trabajar (el descenso del gradiente no se puede mover en una superficie plana), mientras que la función sigmoide tiene una derivada distinta de cero bien definida en todas partes, lo que permite que el descenso del gradiente haga algún progreso en cada paso. De hecho, el algoritmo de retropropagación funciona bien con muchas otras funciones de activación, no solo con la función sigmoide. Aquí hay otras dos opciones populares:\n",
    "\n",
    "\n",
    "- La **función tangente hiperbólica: tanh(z) = 2σ(2z) - 1**\n",
    "    \n",
    "    Al igual que la función sigmoide, esta función de activación tiene forma de S, es continua y diferenciable, pero su valor de salida varía de -1 a 1 (en lugar de 0 a 1 en el caso de la función sigmoide). Ese rango tiende a hacer que la producción de cada capa esté más o menos centrada alrededor de 0 al comienzo del entrenamiento, lo que a menudo ayuda a acelerar la convergencia.\n",
    "\n",
    "\n",
    "- La **función de la unidad lineal rectificada: ReLU(z) = max(0, z)**\n",
    "\n",
    "    La función ReLU es continua, pero desafortunadamente no es diferenciable en z = 0 (la pendiente cambia abruptamente, lo que puede hacer que el descenso de gradiente rebote), y su derivada es 0 para z < 0. En la práctica, sin embargo, funciona muy bien y tiene la ventaja de ser rápido de calcular, por lo que se ha convertido en el valor predeterminado.⁠11 Es importante destacar que el hecho de que no tenga un valor de salida máximo ayuda a reducir algunos problemas durante el descenso del gradiente (regresemos a esto en el capítulo 11)\n",
    "    \n",
    "Estas funciones de activación populares y sus derivados están representados en la Figura 10-8. ¡Pero espera! ¿Por qué necesitamos funciones de activación en primer lugar? Bueno, si encadenas varias transformaciones lineales, todo lo que obtienes es una transformación lineal. Por ejemplo, si f(x) = 2x + 3 y g(x) = 5x - 1, entonces encadenar estas dos funciones lineales le da otra función lineal: f(g(x)) = 2(5x - 1) + 3 = 10x + 1. Así que si no tienes algo de no linealidad entre capas, entonces incluso una pila profunda de capas es equivalente a una sola capa, y no puedes resolver problemas muy complejos con eso. Por el contrario, un DNN lo suficientemente grande con activaciones no lineales puede aproximarse teóricamente a cualquier función continua.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1008.png)\n",
    "\n",
    "_Figura 10-8. Funciones de activación (izquierda) y sus derivadas (derecha)_\n",
    "\n",
    "¡vale! Sabes de dónde vienen las redes neuronales, cuál es su arquitectura y cómo calcular sus salidas. También has aprendido sobre el algoritmo de retropropagación. \n",
    "\n",
    "Pero, ¿qué puedes hacer exactamente con las redes neuronales?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc5b65b",
   "metadata": {},
   "source": [
    "## MLP de regresión\n",
    "\n",
    "\n",
    "En primer lugar, los MLP se pueden utilizar para tareas de regresión. Si quieres predecir un solo valor (por ejemplo, el precio de una casa, dadas muchas de sus características), entonces solo necesitas una sola neurona de salida: su salida es el valor predicho. Para la regresión multivariada (es decir, para predecir múltiples valores a la vez), se necesita una neurona de salida por dimensión de salida. Por ejemplo, para localizar el centro de un objeto en una imagen, necesitas predecir las coordenadas 2D, por lo que necesitas dos neuronas de salida. Si también quieres colocar un cuadro delimitante alrededor del objeto, entonces necesitas dos números más: el ancho y la altura del objeto. Por lo tanto, terminas con cuatro neuronas de salida.\n",
    "\n",
    "\n",
    "Scikit-Learn incluye una clase `MLPRegressor`, así que usémosla para construir un MLP con tres capas ocultas compuestas de 50 neuronas cada una y entrenémoslo en el conjunto de datos de viviendas de California. Para simplificar, usaremos la función `fetch_california_housing()` de Scikit-Learn para cargar los datos. Este conjunto de datos es más simple que el que usamos en el Capítulo 2, ya que contiene solo características numéricas (no hay ninguna característica de `ocean_proximity`) y no faltan valores. \n",
    "\n",
    "\n",
    "El siguiente código comienza obteniendo y dividiendo el conjunto de datos, luego crea una canalización para estandarizar las características de entrada antes de enviarlas al `MLPRegressor`. Esto es muy importante para las redes neuronales porque se entrenan utilizando el descenso de gradiente y, como vimos en el Capítulo 4, el descenso de gradiente no converge muy bien cuando las características tienen escalas muy diferentes. Finalmente, el código entrena el modelo y evalúa su error de validación. \n",
    "\n",
    "\n",
    "El modelo utiliza la función de activación ReLU en las capas ocultas y utiliza una variante de descenso de gradiente llamada Adam (consulte el Capítulo 11) para minimizar el error cuadrático medio, con un poco de regularización ℓ2 (que puede controlar mediante el hiperparámetro `alfa`). ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6030cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline.fit(X_train, y_train)     # Conjuntos de entrenamiento (X_train, Y_train)\n",
    "y_pred = pipeline.predict(X_valid) # Conjunto para hacer predicciones (X_valid)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)  # about 0.505 # Conjunto para evaluar como han salido esas predicciones (y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ead1e",
   "metadata": {},
   "source": [
    "Tenemos un RMSE de validación de aproximadamente 0,505, que es comparable a lo que se obtenería con un clasificador de bosques aleatorio. ¡No está mal para un primer intento!\n",
    "\n",
    "\n",
    "Tenga en cuenta que este MLP no utiliza ninguna función de activación para la capa de salida, por lo que es libre de generar cualquier valor que desee. En general, esto está bien, pero si desea garantizar que la salida siempre será positiva, entonces debe usar la función de activación ReLU en la capa de salida, o la función de activación softplus, que es una variante suave de ReLU: \n",
    "\n",
    "**softplus(z) = iniciar sesión(1 + exp(z))**. \n",
    "\n",
    "Softplus está cerca de 0 cuando z es negativo y cerca de z cuando z es positivo. Finalmente, si desea garantizar que las predicciones siempre estarán dentro de un rango determinado de valores, entonces debe usar la función sigmoidea o la tangente hiperbólica y escalar los objetivos al rango apropiado: 0 a 1 para sigmoide y –1 a 1 para tanh. \n",
    "\n",
    "Lamentablemente, la clase `MLPRegressor` no admite funciones de activación en la capa de salida.\n",
    "\n",
    "\n",
    "#### ADVERTENCIA ---------------------------------------------------------------\n",
    "\n",
    "Construir y entrenar un MLP estándar con Scikit-Learn en solo unas pocas líneas de código es muy conveniente, pero las características de la red neuronal son limitadas. Es por eso que cambiaremos a Keras en la segunda parte de este capítulo.\n",
    "#### ---------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "La clase `MLPRegressor` usa el error cuadrático medio, que generalmente es lo que desea para la regresión, pero si tiene muchos valores atípicos en el conjunto de entrenamiento, es posible que prefiera usar el error absoluto medio. Alternativamente, es posible que desee utilizar la pérdida de Huber, que es una combinación de ambas. Es cuadrático cuando el error es menor que un umbral δ (típicamente 1) pero lineal cuando el error es mayor que δ. La parte lineal la hace menos sensible a los valores atípicos que el error cuadrático medio, y la parte cuadrática le permite converger más rápido y ser más precisa que el error absoluto medio. Sin embargo, `MLPRegressor` solo admite MSE.\n",
    "\n",
    "La tabla 10-1 resume la arquitectura típica de un MLP de regresión.\n",
    "\n",
    "Tabla 10-1. **Arquitectura MLP de regresión Media**\n",
    "\n",
    "\n",
    "| Hiperparámetro             | Valor típico                                                                                            |\n",
    "|----------------------------|---------------------------------------------------------------------------------------------------------|\n",
    "| # capas ocultas            | Depende del problema, pero normalmente de 1 a 5                                                         |\n",
    "| # neuronas por capa oculta | Depende del problema, pero normalmente de 10 a 100                                                      |\n",
    "| # neuronas de salida       | 1 por dimensión de predicción                                                                           |\n",
    "| Activación oculta          | ReLU                                                                                                    |\n",
    "| Activación de salida       | Ninguno, o ReLU/softplus (si las salidas son positivas) o sigmoid/tanh (si las salidas están limitadas) |\n",
    "| Función de pérdida         | MSE, o Huber si son valores atípicos                                                                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59e558",
   "metadata": {},
   "source": [
    "## Clasificación MLP\n",
    "\n",
    "\n",
    "Los MLP también se pueden utilizar para tareas de clasificación. Para un problema de clasificación binaria, solo necesita una sola neurona de salida que utilice la función de activación sigmoide: la salida será un número entre 0 y 1, que puede interpretar como la probabilidad estimada de la clase positiva. La probabilidad estimada de la clase negativa es igual a uno menos ese número.\n",
    "\n",
    "Los MLP también pueden manejar fácilmente tareas de clasificación binaria multimarca (véase el capítulo 3). Por ejemplo, podría tener un sistema de clasificación de correo electrónico que predice si cada correo electrónico entrante es jamón o spam, y al mismo tiempo predice si es un correo electrónico urgente o no urgente. En este caso, necesitaría dos neuronas de salida, ambas utilizando la función de activación sigmoide: la primera generaría la probabilidad de que el correo electrónico sea spam y la segunda generaría la probabilidad de que sea urgente. De manera más general, dedicarías una neurona de salida para cada clase positiva. Tenga en cuenta que las probabilidades de salida no suman necesariamente 1. Esto permite que el modelo genere cualquier combinación de etiquetas: puede tener jamón no urgente, jamón urgente, spam no urgente y tal vez incluso spam urgente (aunque eso probablemente sería un error).\n",
    "\n",
    "\n",
    "Si cada instancia puede pertenecer solo a una sola clase, de tres o más clases posibles (por ejemplo, clases del 0 al 9 para la clasificación de imágenes de dígitos), entonces necesita tener una neurona de salida por clase, y debe usar la función de activación softmax para toda la capa de salida (consulte la Figura 10-9). La función softmax (introducida en el capítulo 4) garantizará que todas las probabilidades estimadas estén entre 0 y 1 y que sumen 1, ya que las clases son exclusivas. Como viste en el capítulo 3, esto se llama clasificación multiclase.\n",
    "\n",
    "\n",
    "En cuanto a la función de pérdida, ya que estamos prediciendo distribuciones de probabilidad, la pérdida de entropía cruzada (o entropía x o pérdida de registro para abreviar, véase el Capítulo 4) es generalmente una buena opción.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1009.png)\n",
    "\n",
    "_Figura 10-9. Un MLP moderno (incluyendo ReLU y softmax) para la clasificación_\n",
    "\n",
    "\n",
    "Scikit-Learn tiene una clase `MLPClassifier` en el paquete `sklearn.neural_network`. Es casi idéntica a la clase `MLPRegressor`, excepto que minimiza la entropía cruzada en lugar del MSE. Pruébelo ahora, por ejemplo en el conjunto de datos del iris. Es casi una tarea lineal, por lo que una sola capa con 5 a 10 neuronas debería ser suficiente (asegúrate de escalar las características).\n",
    "\n",
    "La tabla 10-2 resume la arquitectura típica de una clasificación MLP.\n",
    "\n",
    "\n",
    "Tabla 10-2. **Clasificación típica de la arquitectura MLP**\n",
    "\n",
    "| Hiperparametro                  | Clasificación binaria                               | Clasificación binaria multimarca                    | Clasificación multiclase                            |\n",
    "|---------------------------------|-----------------------------------------------------|-----------------------------------------------------|-----------------------------------------------------|\n",
    "| # capas ocultas                 | Normalmente de 1 a 5 capas, dependiendo de la tarea | Normalmente de 1 a 5 capas, dependiendo de la tarea | Normalmente de 1 a 5 capas, dependiendo de la tarea |\n",
    "| # neuronas de salida            | 1                                                   | 1 por etiqueta binaria                              | 1 por clase                                         |\n",
    "| Activación de la capa de salida | Sigmoide                                            | Sigmoide                                            | Softmax                                             |\n",
    "| Función de pérdida              | X-entropía                                          | X-entropía                                          | X-entropía                                          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5485e",
   "metadata": {},
   "source": [
    "##### TIP\n",
    "\n",
    "Antes de seguir, te recomiendo que pases por el ejercicio 1 al final de este capítulo. Jugarás con varias arquitecturas de redes neuronales y visualizarás sus salidas usando el patio de recreo TensorFlow (TensorFlow Playground). Esto será muy útil para comprender mejor los MLP, incluidos los efectos de todos los hiperparámetros (número de capas y neuronas, funciones de activación y más).\n",
    "\n",
    "¡Ahora tienes todos los conceptos que necesitas para empezar a implementar MLP con Keras!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03059889",
   "metadata": {},
   "source": [
    "# Implementación de MLP con Keras\n",
    "\n",
    "\n",
    "Keras es la API de aprendizaje profundo de alto nivel de TensorFlow: te permite construir, entrenar, evaluar y ejecutar todo tipo de redes neuronales. \n",
    "\n",
    "La biblioteca original de Keras fue desarrollada por François Chollet como parte de un proyecto de investigación y fue lanzada como un proyecto independiente de código abierto en marzo de 2015. \n",
    "\n",
    "Rápidamente ganó popularidad, debido a su facilidad de uso, flexibilidad y hermoso diseño."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b36ff",
   "metadata": {},
   "source": [
    "##### NOTA\n",
    "\n",
    "Keras solía admitir múltiples backends, incluidos TensorFlow, PlaidML, Theano y Microsoft Cognitive Toolkit (CNTK) (los dos últimos están tristemente obsoletos), pero desde la versión 2.4, Keras es solo para TensorFlow. \n",
    "\n",
    "Del mismo modo, TensorFlow solía incluir múltiples API de alto nivel, pero Keras fue elegida oficialmente como su API de alto nivel preferida cuando salió TensorFlow 2. \n",
    "\n",
    "La instalación de TensorFlow también instalará automáticamente Keras, y Keras no funcionará sin TensorFlow instalado. \n",
    "\n",
    "En resumen, Keras y TensorFlow se enamoraron y se casaron. Otras bibliotecas populares de aprendizaje profundo incluyen PyTorch de Facebook y JAX de Google.\n",
    "##### ------------------------------------------------------------------------------------------\n",
    "\n",
    "¡Ahora usemos Keras! Comenzaremos construyendo un MLP para la clasificación de imágenes.\n",
    "\n",
    "##### ------------------------------------------------------------------------------------------\n",
    "\n",
    "##### NOTA\n",
    "\n",
    "Los tiempos de ejecución de Colab vienen con versiones recientes de TensorFlow y Keras preinstaladas. Sin embargo, si desea instalarlos en su propia máquina, consulte las instrucciones de instalación en https://homl.info/install.\n",
    "\n",
    "\n",
    "## Creación de un clasificador de imágenes utilizando la API secuencial\n",
    "\n",
    "\n",
    "Primero, necesitamos cargar un conjunto de datos. \n",
    "Utilizaremos Fashion MNIST, que es un reemplazo directo de MNIST (introducido en el capítulo 3). \n",
    "\n",
    "Tiene exactamente el mismo formato que MNIST (70.000 imágenes en escala de grises de 28 × 28 píxeles cada una, con 10 clases), pero las imágenes representan **artículos de moda en lugar de dígitos escritos a mano**, por lo que cada clase es más diversa, y el problema resulta ser significativamente más desafiante que el MNIST. \n",
    "\n",
    "Por ejemplo, un modelo lineal simple alcanza una precisión de alrededor del 92 % en MNIST, pero solo alrededor del 83 % en Fashion MNIST.\n",
    "\n",
    "### Uso de Keras para cargar el conjunto de datos\n",
    "\n",
    "Keras proporciona algunas funciones de utilidad para obtener y cargar conjuntos de datos comunes, incluyendo MNIST, Fashion MNIST y algunos más. Vamos a cargar Fashion MNIST. Ya está mezclado y dividido en un conjunto de entrenamiento (60.000 imágenes) y un conjunto de pruebas (10.000 imágenes), pero mantendré las últimas 5.000 imágenes del conjunto de entrenamiento para su validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821f8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9848a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualizamos varias imágenes como ejemplo\n",
    "\n",
    "fig, axes = plt.subplots(1, 3)  # Crear una fila de 3 subgráficos\n",
    "axes[0].imshow(X_train[0], cmap='gray')  # Mostrar la primera imagen en el primer subgráfico\n",
    "axes[1].imshow(X_train[1], cmap='gray')  # Mostrar la segunda imagen en el segundo subgráfico\n",
    "axes[2].imshow(X_train[2], cmap='gray')  # Mostrar la tercera imagen en el tercer subgráfico\n",
    "\n",
    "plt.show()  # Mostrar todas las imágenes juntas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38541af",
   "metadata": {},
   "source": [
    "### TIP\n",
    "\n",
    "TensorFlow generalmente se importa como `t`, y la API de Keras está disponible a través de `tf.keras`.\n",
    "\n",
    "--------------------------------------------------------\n",
    "\n",
    "\n",
    "Al cargar MNIST o Fashion MNIST utilizando Keras en lugar de Scikit-Learn, una diferencia importante es que cada imagen se representa como una matriz de 28 × 28 en lugar de una matriz 1D de tamaño 784. \n",
    "\n",
    "**Además, las intensidades de los píxeles se representan como enteros (de 0 a 255) en lugar de flotantes (de 0,0 a 255,0)**. \n",
    "\n",
    "Echemos un vistazo a la forma y el tipo de datos del conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da6e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533135e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b1ca5",
   "metadata": {},
   "source": [
    "Para simplificar, **escalaremos** las intensidades de los píxeles hasta el rango 0-1 dividiéndolas por 255,0 (esto también las convierte en flotadores):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddffa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b688964",
   "metadata": {},
   "source": [
    "Con MNIST, cuando la etiqueta es igual a 5, significa que la imagen representa el dígito 5 escrito a mano. Fácil. Sin embargo, para Fashion MNIST, necesitamos la lista de nombres de clases para saber con qué estamos tratando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9751dde9",
   "metadata": {},
   "source": [
    "Por ejemplo, la primera imagen del conjunto de entrenamiento representa una zapatilla tipo botín (Ankle boot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89361adf",
   "metadata": {},
   "source": [
    "La figura siguiente muestra algunas muestras del conjunto de datos de Fashion MNIST.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1010.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3776eb02",
   "metadata": {},
   "source": [
    "## Crear el modelo usando la API secuencial\n",
    "\n",
    "¡Ahora construyamos la red neuronal! Aquí hay una clasificación MLP con dos capas ocultas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa082cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# capa de entrada\n",
    "model.add(tf.keras.layers.Input(shape=[28, 28]))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# capas ocultas\n",
    "model.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97485dae",
   "metadata": {},
   "source": [
    "* En primer lugar, establezca la semilla aleatoria de TensorFlow para que los resultados sean reproducibles: los pesos aleatorios de las capas ocultas y la capa de salida serán los mismos cada vez que ejecute el cuaderno. También puede optar por usar la función the `tf.keras.utils.set_random_seed()`, que establece convenientemente las semillas aleatorias para TensorFlow, Python (`random.seed()`) y NumPy(`np.random.seed()`).\n",
    "\n",
    "* La siguiente línea crea un modelo Sequential. Este es el tipo más simple de modelo de Keras para redes neuronales que están compuestas de una sola pila de capas conectadas secuencialmente. Esto se llama API secuencial.\n",
    "\n",
    "* A continuación, construimos la primera capa (una capa de `Input`) y la agregamos al modelo. Especificamos la `shape` de entrada, que no incluye el tamaño del lote, solo la forma de las instancias. Keras necesita conocer la forma de las entradas para poder determinar la forma de la matriz de peso de conexión de la primera capa oculta.\n",
    "\n",
    "* Luego añadimos una capa Flatten. Su función es convertir cada imagen de entrada en una matriz 1D: por ejemplo, si recibe un lote de formas [32, 28, 28], la remodelará a [32, 784]. En otras palabras, si recibe datos de entrada X, calcula X.reshape(-1, 784) Esta capa no tiene ningún parámetro; solo está ahí para hacer un preprocesamiento simple.\n",
    "\n",
    "* A continuación agregamos una capa oculta densa `Dense` con 300 neuronas. Utilizará la función de activación ReLU. Cada capa Densa gestiona su propia matriz de pesos, que contiene todos los pesos de conexión entre las neuronas y sus entradas. También gestiona un vector de términos de sesgo (uno por neurona). Cuando recibe algunos datos de entrada, calcula la ecuación 10-2.\n",
    "\n",
    "* Luego agregamos una segunda capa oculta densa `Dense` con 100 neuronas, también usando la función de activación ReLU.\n",
    "\n",
    "* Finalmente, agregamos una capa de salida Densa con 10 neuronas (una por clase), usando la función de activación softmax porque las clases son exclusivas.\n",
    "\n",
    "\n",
    "### TIP\n",
    "\n",
    "Especificar `activation=\"relu\"` es esquivalente a especificar `activation=tf.keras.activations.relu`.\n",
    "\n",
    "Otras funciones de activación están disponibles en el paquete `tf.keras.activations`.\n",
    "\n",
    "Vamos a usar muchas de ellas y se pueden resumir todas en la lista https://keras.io/api/layers/activations.\n",
    "\n",
    "También podemos crear nuestras propias funciones de activación.\n",
    "\n",
    "-----------------------------------------------------------\n",
    "\n",
    "En lugar de añadir las capas una por una como hemos hecho antes, puede ser más conveniente crear el modelo secuencial `Sequential`.\n",
    "\n",
    "También puedes soltar la capa de `Input` y en su lugar especificar `input_shape` en la primera capa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df08d74",
   "metadata": {},
   "source": [
    "El método `summary()` del modelo muestra todas las capas del modelo, incluido el nombre de cada capa (que se genera automáticamente a menos que lo configure al crear la capa), su forma de salida (`None` significa que el tamaño del lote puede ser cualquier cosa) y su número. de parámetros. \n",
    "\n",
    "El resumen finaliza con el número total de parámetros, incluidos los parámetros entrenables y no entrenables. \n",
    "\n",
    "Aquí solo tenemos parámetros entrenables (verá algunos parámetros no entrenables más adelante en este capítulo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f18aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eafbab8",
   "metadata": {},
   "source": [
    "Tenga en cuenta que las capas densas `Dense` suelen tener muchos parámetros. Por ejemplo, la primera capa oculta tiene pesos de conexión de 784 × 300, más 300 términos de sesgo, ¡lo que suma 235.500 parámetros! Esto le da al modelo bastante flexibilidad para ajustarse a los datos de entrenamiento, pero también significa que el modelo corre el riesgo de sobreajustarse, especialmente cuando no se tienen muchos datos de entrenamiento. Vamos a volver a esto más adelante.\n",
    "\n",
    "Cada capa de un modelo debe tener un nombre único (por ejemplo, `\"dense_2\"`). Puede configurar los nombres de las capas explícitamente usando el argumento de nombre `name` del constructor, pero generalmente es más sencillo dejar que Keras nombre las capas automáticamente, como acabamos de hacer. Keras toma el nombre de la clase de la capa y lo convierte en caso de serpiente (por ejemplo, una capa de la clase `MyCoolLayer` se llama `\"my_cool_layer\"` de forma predeterminada). Keras también garantiza que el nombre sea globalmente único, incluso entre modelos, agregando un índice si es necesario, como en `\"dense_2\"`. Pero, ¿por qué se molesta en hacer que los nombres sean únicos en todos los modelos? Bueno, esto hace posible fusionar modelos fácilmente sin generar conflictos de nombres.\n",
    "\n",
    "\n",
    "### TIP\n",
    "\n",
    "Todo el estado global administrado por Keras se almacena en una sesión de Keras, que puedes borrar usando `tf.keras.backend.clear_session()`. En particular, esto restablece los contadores de nombres.\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "Puedes obtener fácilmente la lista de capas `layers` de un modelo usando el atributo de capas, o usar el método `get_layer()` para acceder a una capa por su nombre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d54b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32219f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a33001",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf650c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer('dense_3') is hidden1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25f5fa0",
   "metadata": {},
   "source": [
    "Se puede acceder a todos los parámetros de una capa utilizando sus métodos `get_weights()` y `set_weights()`. Para una capa `Dense`, esto incluye tanto los pesos de conexión como los términos de polarización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb5a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41044a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46688876",
   "metadata": {},
   "outputs": [],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180c765",
   "metadata": {},
   "source": [
    "Observe que la capa `Densa` inicializó los pesos de la conexión de forma **aleatoria** (lo cual es necesario para romper la simetría, como se analizó anteriormente) y los sesgos se inicializaron a **ceros**, lo cual está bien. Si desea utilizar un **método de inicialización diferente**, puede configurar `kernel_initializer` (kernel es otro nombre para la matriz de pesos de conexión) o sesgo_initializer al crear la capa. Hablaremos más sobre los inicializadores en el Capítulo 11 y la lista completa se encuentra en https://keras.io/api/layers/initializers.\n",
    "\n",
    "### NOTA\n",
    "\n",
    "La forma de la matriz de peso depende de la cantidad de entradas, razón por la cual especificamos `input_shape` al crear el modelo. Si no especifica la forma de entrada, está bien: Keras simplemente esperará hasta conocer la forma de entrada antes de construir los parámetros del modelo. Esto sucederá cuando le proporciones algunos datos (por ejemplo, durante el entrenamiento) o cuando llames a su método `build()`. Hasta que se creen los parámetros del modelo, no podrá hacer ciertas cosas, como mostrar el resumen del modelo o guardar el modelo. Por lo tanto, si conoce la forma de entrada al crear el modelo, es mejor especificarla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813fa6bf",
   "metadata": {},
   "source": [
    "## Compilación del modelo\n",
    "\n",
    "\n",
    "Después de crear un modelo, debe llamar a su método `compile()` para especificar la función de pérdida y el optimizador que se utilizará. Opcionalmente, puede especificar una lista de métricas adicionales para calcular durante la capacitación y la evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1bde91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0171bcb",
   "metadata": {},
   "source": [
    "### NOTA\n",
    "\n",
    "Usar `loss=\"sparse_categorical_crossentropy` es equivalente a usar `loss=tf.keras.losses.sparse_categorical_cross⁠entropy`. De forma similar, usar `optimizer=\"sgd\"` es el equivalente a usar `optimizer=tf.keras.optimizers.SGD()`, y usar `metrics=[\"accuracy\"]` es equivalente a usar `metrics=[tf.keras.metrics.sparse_categorical_accuracy]` (cuando usamos sus pesos). Vamos a usar muchos otros pesos, optimizadores y métricas; para ver la lista completa: https://keras.io/api/losses, https://keras.io/api/optimizers, and https://keras.io/api/metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce58133",
   "metadata": {},
   "source": [
    "## IMPORTANTE:\n",
    "\n",
    "Este código requiere explicación. Usamos la pérdida `sparse_categorical_crossentropy` porque tenemos etiquetas escasas (es decir, para cada instancia, solo hay un índice de clase objetivo, de 0 a 9 en este caso), y las clases son exclusivas. Si, en cambio, tuviéramos una probabilidad objetivo por clase para cada instancia (como vectores one-hot, por ejemplo, `[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]` para representar la clase 3), entonces necesitaríamos usar la pérdida `categorical_crossentropy` en su lugar. Si estuviéramos haciendo una clasificación binaria o una clasificación binaria de etiquetas múltiples, entonces usaríamos la función de activación `sigmoid` en la capa de salida en lugar de la función de activación `softmax`, y usaríamos la pérdida `binary_crossentropy`.\n",
    "\n",
    "\n",
    "\n",
    "### TIP\n",
    "\n",
    "Si desea convertir etiquetas dispersas (es decir, índices de clase) en etiquetas vectoriales únicas, utilice la función `tf.keras.utils.to_categorical()`. Para hacerlo al revés, use la función `np.argmax()` con `axis=1`.\n",
    "\n",
    "Con respecto al optimizador, `\"sgd\"` significa que entrenaremos el modelo utilizando un descenso de gradiente estocástico. En otras palabras, Keras realizará el algoritmo de retropropagación descrito anteriormente (es decir, autodiff en modo inverso más descenso de gradiente). Analizaremos optimizadores más eficientes en el Capítulo 11. Mejoran el descenso de gradiente, no la diferenciación automática.\n",
    "\n",
    "\n",
    "### NOTA\n",
    "\n",
    "Cuando se utiliza el optimizador SGD, es importante ajustar la **tasa de aprendizaje**. Por lo tanto, generalmente querrás utilizar `optimizer=tf.keras.opti⁠mizers.SGD(learning_rate=__???__)` para establecer la tasa de aprendizaje, en lugar de `optimizer=\"sgd\"`, que por defecto es una tasa de aprendizaje de **0,01**.\n",
    "\n",
    "\n",
    "Por último, dado que se trata de un clasificador, es útil **medir su precisión** durante el entrenamiento y la evaluación, por lo que establecemos `metrics=[\"accuracy\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec5eed5",
   "metadata": {},
   "source": [
    "## Formación y evaluación del modelo\n",
    "\n",
    "\n",
    "Ahora el modelo está listo para ser entrenado. Para esto, simplemente tenemos que llamar a su método `fit()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df09267",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479fdfb9",
   "metadata": {},
   "source": [
    "Le pasamos las características de entrada (`X_train`) y las clases objetivo (`y_train`), así como el número de épocas para entrenar (o de lo contrario, por defecto sería solo 1, lo que definitivamente no sería suficiente para converger a una buena solución). También pasamos un conjunto de validación (esto es opcional). Keras medirá la pérdida y las métricas adicionales en este conjunto al final de cada época, lo que es muy útil para ver qué tan bien funciona realmente el modelo. Si el rendimiento en el conjunto de entrenamiento es mucho mejor que en el conjunto de validación, su modelo probablemente esté sobreajustando el conjunto de entrenamiento, o hay un error, como un desajuste de datos entre el conjunto de entrenamiento y el conjunto de validación.\n",
    "\n",
    "\n",
    "### TIP\n",
    "\n",
    "Los errores de forma son bastante comunes, especialmente al comenzar, por lo que debes familiarizarte con los mensajes de error: intenta ajustar un modelo con entradas y/o etiquetas de la forma incorrecta y observa los errores que obtienes. De manera similar, intente compilar el modelo con `loss=\"categorical_crossentropy\"` en lugar de `loss=\"sparse_cat⁠egorical_crossentropy\"`. O puedes quitar la capa Aplanar.\n",
    "\n",
    "\n",
    "\n",
    "**¡Y eso es todo!** La red neuronal está entrenada. En cada época durante el entrenamiento, Keras muestra el número de mini lotes procesados hasta ahora en el lado izquierdo de la barra de progreso. El tamaño del lote es de 32 por defecto, y dado que el conjunto de entrenamiento tiene 55.000 imágenes, el modelo pasa por 1.719 lotes por época: 1.718 de tamaño 32 y 1 de tamaño 24. Después de la barra de progreso, puede ver el tiempo medio de entrenamiento por muestra, y la pérdida y la precisión (o cualquier otra métrica adicional que haya pedido) tanto en el conjunto de entrenamiento como en el conjunto de validación. \n",
    "\n",
    "Tenga en cuenta que la pérdida de entrenamiento se redujo, lo cual es una buena señal, y la precisión de la validación alcanzó el 88,94 % después de 30 épocas. Eso está ligeramente por debajo de la precisión del entrenamiento, por lo que hay un poco de sobreajuste, pero no una gran cantidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392a529",
   "metadata": {},
   "source": [
    "### TIP\n",
    "\n",
    "En lugar de pasar un conjunto de validación usando el argumento validation_data, puede establecer `validation_split` en la proporción del conjunto de entrenamiento que desea que Keras use para la validación. Por ejemplo, `validation_split=0.1` le dice a Keras que use el último 10% de los datos (antes de barajar) para la validación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2ac0e",
   "metadata": {},
   "source": [
    "Si el conjunto de entrenamiento estuviera muy sesgado, con algunas clases sobrerrepresentadas y otras subrepresentadas, sería útil establecer el argumento `class_weight` al llamar al método `fit()`, para dar un peso mayor a las clases subrepresentadas y un peso menor a las clases sobrerrepresentadas. Keras utilizaría estos pesos al calcular la pérdida. Si necesita ponderaciones por instancia, establezca el argumento `sample_weight`. Si se proporcionan `class_weight` y `sample_weight`, Keras los multiplica.\n",
    "\n",
    "Las ponderaciones por instancia podrían ser útiles, por ejemplo, si algunas instancias fueron etiquetadas por expertos mientras que otras fueron etiquetadas mediante una plataforma de crowdsourcing: es posible que desee darle más peso a las primeras. \n",
    "\n",
    "También puede proporcionar ponderaciones de muestra (pero no ponderaciones de clase) para el conjunto de validación agregándolas como un tercer elemento en la tupla `validation_data`.\n",
    "\n",
    "El método `fit()` devuelve un objeto `History` que contiene los parámetros de entrenamiento (`history.params`), la lista de épocas por las que pasó (`history.epoch`) y, lo más importante, un diccionario (`history.history`) que contiene las pérdidas y las métricas adicionales que midió. al final de cada época en el conjunto de entrenamiento y en el conjunto de validación (si corresponde). \n",
    "\n",
    "Si usa este diccionario para crear un Pandas DataFrame y llama a su método `plot()`, obtendrá las curvas de aprendizaje que se muestran en la Figura 10-11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b238ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5), xlim=[0, 29], ylim=[0, 1], grid=True, xlabel=\"Epoch\",\n",
    "    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06f81c",
   "metadata": {},
   "source": [
    "Figura 10-11. Curvas de aprendizaje: la pérdida media de entrenamiento y la precisión medidas en cada época, y la pérdida media de validación y la precisión medidas al final de cada época"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62525327",
   "metadata": {},
   "source": [
    "Puedes ver que tanto la precisión del entrenamiento como la precisión de validación aumentan constantemente durante el entrenamiento, mientras que la pérdida de entrenamiento y la pérdida de validación disminuyen. Esto está bien. Las curvas de validación están relativamente cerca unas de otras al principio, pero se separan más con el tiempo, lo que demuestra que hay un poco de sobreajuste. En este caso en particular, el modelo parece que funcionó mejor en el conjunto de validación que en el conjunto de entrenamiento al comienzo del entrenamiento, pero en realidad ese no es el caso. El error de validación se calcula al final de cada época, mientras que el error de entrenamiento se calcula utilizando una media de ejecución durante cada época, por lo que la curva de entrenamiento debe cambiar media época a la izquierda. Si haces eso, verás que las curvas de entrenamiento y validación se superponen casi perfectamente al comienzo del entrenamiento.\n",
    "\n",
    "El rendimiento del conjunto de entrenamiento termina superando el rendimiento de la validación, como suele ser el caso cuando entrenas el tiempo suficiente. Puedes decir que el modelo aún no ha convergido del todo, ya que la pérdida de validación todavía está bajando, por lo que probablemente deberías continuar entrenando. Esto es tan simple como volver a llamar al método fit(), ya que Keras continúa entrenando donde lo dejó: deberías ser capaz de alcanzar alrededor del 89,8% de precisión de validación, mientras que la precisión del entrenamiento continuará aumentando hasta el 100 % (este no siempre es el caso).\n",
    "\n",
    "Si no está satisfecho con el rendimiento de su modelo, debe regresar y ajustar los hiperparámetros. El primero a comprobar es la tasa de aprendizaje. Si eso no ayuda, pruebe con otro optimizador (y siempre vuelva a ajustar la tasa de aprendizaje después de cambiar cualquier hiperparámetro). Si el rendimiento aún no es excelente, intente ajustar los hiperparámetros del modelo, como la cantidad de capas, la cantidad de neuronas por capa y los tipos de funciones de activación que se usarán para cada capa oculta. También puede intentar ajustar otros hiperparámetros, como el tamaño del lote (se puede configurar en el método `fit()` usando el argumento `batch_size` cuyo valor predeterminado es 32). Volveremos al ajuste de hiperparámetros al final de este capítulo. Una vez que esté satisfecho con la precisión de la validación de su modelo, debe evaluarlo en el conjunto de prueba para estimar el error de generalización antes de implementar el modelo en producción. Puedes hacer esto fácilmente usando el método `evaluate()` (también admite varios otros argumentos, como `batch_size` y `sample_weight`; consulta la documentación para obtener más detalles):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad06fe",
   "metadata": {},
   "source": [
    "Como viste en el capítulo 2, es común obtener un rendimiento ligeramente inferior en el conjunto de pruebas que en el conjunto de validación, porque los hiperparámetros están sintonizados en el conjunto de validación, no en el conjunto de pruebas (sin embargo, en este ejemplo, no hicimos ningún ajuste de hiperparámetros, por lo que la menor precisión es solo mala suerte). Recuerde resistir la tentación de ajustar los hiperparámetros en el conjunto de pruebas, o de lo contrario su estimación del error de generalización será demasiado optimista.\n",
    "\n",
    "\n",
    "## Usar el modelo para hacer predicciones\n",
    "\n",
    "\n",
    "Ahora usemos el método `predict()` del modelo para hacer predicciones sobre nuevas instancias. Como no tenemos instancias nuevas reales, solo usaremos las primeras tres instancias del conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f71c331",
   "metadata": {},
   "source": [
    "Para cada instancia, el modelo estima una probabilidad por clase, desde la clase 0 hasta la clase 9. Esto es similar al resultado del método `predict_proba()` en los clasificadores Scikit-Learn. Por ejemplo, para la primera imagen estima que la probabilidad de la clase 9 (botín) es del 96%, la probabilidad de la clase 7 (zapatilla) es del 2%, la probabilidad de la clase 5 (sandalia) es del 1% y las probabilidades de las otras clases son insignificantes. En otras palabras, es muy seguro que la primera imagen sea calzado, probablemente botines, pero posiblemente zapatillas o sandalias. Si solo le importa la clase con la probabilidad estimada más alta (incluso si esa probabilidad es bastante baja), entonces puede usar el método `argmax()` para obtener el índice de clase de probabilidad más alto para cada instancia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce90c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = y_proba.argmax(axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc0e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a15bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí, el clasificador en realidad clasificó las tres imágenes correctamente (estas imágenes se muestran en la Figura 10-12):\n",
    "\n",
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af81e385",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1012.png)\n",
    "\n",
    "Figura 10-12. Imágenes de Fashion MNIST correctamente clasificadas\n",
    "\n",
    "Ahora sabes cómo usar la API secuencial para construir, entrenar y evaluar una **clasificación MLP**. Pero, ¿qué pasa con la regresión?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79725317",
   "metadata": {},
   "source": [
    "## Construyendo un MLP de regresión usando la API secuencial\n",
    "\n",
    "\n",
    "Volvamos al problema de la vivienda de California y abordémoslo usando el mismo MLP que antes, con 3 capas ocultas compuestas por 50 neuronas cada una, pero esta vez construyéndolo con Keras.\n",
    "\n",
    "Usar la API secuencial para construir, entrenar, evaluar y usar un MLP de regresión es bastante similar a lo que hicimos para la clasificación. Las principales diferencias en el siguiente ejemplo de código son el hecho de que **la capa de salida tiene una sola neurona** (ya que solo queremos predecir un valor único) y no utiliza ninguna función de activación, la función de pérdida es el error cuadrático medio, la métrica es el RMSE, y estamos usando un optimizador Adam como lo hizo `MLPRegressor` de Scikit-Learn. Además, en este ejemplo no necesitamos una capa `Flatten`, y en su lugar estamos usando una capa de `Normalization` como primera capa: hace lo mismo que `StandardScaler` de Scikit-Learn, pero debe ajustarse a los datos de entrenamiento usando su método `adapt()` antes de llamar al método `fit()` del modelo. (Keras tiene otras capas de preprocesamiento, que se tratarán en el Capítulo 13). Vamos a ver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745798ba",
   "metadata": {},
   "source": [
    "### NOTA\n",
    "\n",
    "La capa de `Normalization` aprende las medias de las características y las desviaciones estándar en los datos de entrenamiento cuando llama al método `adapt()`. Sin embargo, cuando muestra el resumen del modelo, estas estadísticas aparecen como no entrenables. Esto se debe a que estos parámetros no se ven afectados por el descenso del gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad2a5c2",
   "metadata": {},
   "source": [
    "Como puede ver, la API secuencial es bastante limpia y sencilla. Sin embargo, aunque los modelos secuenciales `Sequential` son extremadamente comunes, a veces resulta útil construir redes neuronales con topologías más complejas o con múltiples entradas o salidas. Para ello, Keras ofrece la API funcional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fabf0d",
   "metadata": {},
   "source": [
    "Construyendo modelos complejos utilizando la API funcional\n",
    "\n",
    "Un ejemplo de una red neuronal no secuencial es una red neuronal amplia y profunda. Esta arquitectura de red neuronal se introdujo en un artículo de 2016 de Heng-Tze Cheng et al. Conecta todas o parte de las entradas directamente a la capa de salida, como se muestra en la Figura 10-13. Esta arquitectura hace posible que la red neuronal aprenda tanto patrones profundos (usando la ruta profunda) como reglas simples (a través de la ruta corta). Por el contrario, un MLP regular obliga a todos los datos a fluir a través de la pila completa de capas; por lo tanto, los patrones simples en los datos pueden terminar siendo distorsionados por esta secuencia de transformaciones.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1013.png)\n",
    "\n",
    "Construyamos una red neuronal para abordar el problema de la vivienda de California:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab8f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "concat_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "normalized = normalization_layer(input_)\n",
    "hidden1 = hidden_layer1(normalized)\n",
    "hidden2 = hidden_layer2(hidden1)\n",
    "concat = concat_layer([normalized, hidden2])\n",
    "output = output_layer(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3492b7",
   "metadata": {},
   "source": [
    "En un nivel alto, las primeras cinco líneas crean todas las capas que necesitamos para construir el modelo, las siguientes seis líneas usan estas capas como funciones para ir de la entrada a la salida, y la última línea crea un objeto del `Model` Keras señalando a la entrada y a la salida. Repasemos este código con más detalle:\n",
    "\n",
    "\n",
    "- Primero, creamos cinco capas: una capa de `Normalization` para estandarizar las entradas, dos capas `Dense` con 30 neuronas cada una, usando la función de activación ReLU, una capa `Concatenate` y una capa `Dense` más con una sola neurona para la capa de salida, sin ninguna activación. función.\n",
    "\n",
    "\n",
    "* A continuación, creamos un objeto de entrada `Input` (el nombre de la variable `input_` se usa para evitar eclipsar la función `input()` incorporada de Python). Esta es una especificación del tipo de entrada que recibirá el modelo, incluida su forma `shape` y, opcionalmente, su `dtype`, que por defecto es flotante de 32 bits. En realidad, un modelo puede tener múltiples entradas, como verá en breve.\n",
    "\n",
    "\n",
    "- Luego usamos la capa de `Normalization` como una función, pasándole el objeto de entrada `Input`. Por eso se llama API funcional. Tenga en cuenta que solo le estamos diciendo a Keras cómo debe conectar las capas entre sí; todavía no se están procesando datos reales, ya que el objeto de `Input` es solo una especificación de datos. En otras palabras, es un aporte simbólico. El resultado de esta llamada también es simbólico: `normalized` no almacena ningún dato real, solo se usa para construir el modelo.\n",
    "\n",
    "\n",
    "* De la misma manera, luego pasamos `normalized` a `hidden_layer1`, que genera `hidden1`, y pasamos `hidden1` a `hidden_layer2`, que genera `hidden2`.\n",
    "\n",
    "\n",
    "- Hasta ahora hemos conectado las capas secuencialmente, pero luego usamos `concat_layer` para concatenar la entrada y la salida de la segunda capa oculta. Una vez más, todavía no se han concatenado datos reales: todo es simbólico para construir el modelo.\n",
    "\n",
    "\n",
    "* Luego pasamos `concat` a `output_layer`, que nos da el resultado `output`.\n",
    "\n",
    "\n",
    "- Por último, creamos un modelo `Model` Keras, especificando qué entradas y salidas usar.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Una vez que hayas construido este modelo de Keras, todo es exactamente como antes, por lo que no hay necesidad de repetirlo aquí: compilas el modelo, adaptas la capa `Normalization`, ajustas el modelo, lo evalúas y lo usas para hacer predicciones.\n",
    "\n",
    "Pero, ¿qué pasa si quieres enviar un subconjunto de las características a través de la ruta amplia y un subconjunto diferente (posiblemente superpuesta) a través de la ruta profunda, como se ilustra en la Figura 10-14? En este caso, una solución es usar múltiples entradas. Por ejemplo, supongamos que queremos enviar cinco características a través de la ruta amplia (características 0 a 4) y seis características a través de la ruta profunda (características 2 a 7). Podemos hacer esto de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e017302",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wide = tf.keras.layers.Input(shape=[5])  # features 0 to 4\n",
    "input_deep = tf.keras.layers.Input(shape=[6])  # features 2 to 7\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb675872",
   "metadata": {},
   "source": [
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1014.png)\n",
    "\n",
    "Hay algunas cosas que hay que tener en cuenta en este ejemplo, en comparación con el anterior:\n",
    "\n",
    "* Cada capa `Dense` se crea y se llama en la misma línea. Esta es una práctica común, ya que hace que el código sea más conciso sin perder claridad. Sin embargo, no podemos hacer esto con la capa de `Normalization` ya que necesitamos una referencia a la capa para poder llamar a su método `adapt()` antes de ajustar el modelo.\n",
    "\n",
    "- Usamos `tf.keras.layers.concatenate()`, que crea una capa Concatenate y la llama con las entradas dadas.\n",
    "\n",
    "* Especificamos `inputs=[input_wide, input_deep]` al crear el modelo, ya que hay dos entradas.\n",
    "\n",
    "\n",
    "Ahora podemos compilar el modelo como de costumbre, pero cuando llamamos al método `fit()`, en lugar de pasar una única matriz de entrada `X_train`, debemos pasar un par de matrices (`X_train_wide`, `X_train_deep`), una por entrada. Lo mismo ocurre con `X_valid`, y también con `X_test` y `X_new` cuando llamas a `evaluate()` o `predict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "X_train_wide, X_train_deep = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_wide, X_valid_deep = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_wide, X_test_deep = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_wide, X_new_deep = X_test_wide[:3], X_test_deep[:3]\n",
    "\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit((X_train_wide, X_train_deep), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_wide, X_valid_deep), y_valid))\n",
    "mse_test = model.evaluate((X_test_wide, X_test_deep), y_test)\n",
    "y_pred = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eb6cbe",
   "metadata": {},
   "source": [
    "### TIP\n",
    "\n",
    "En lugar de pasar una tupla (`X_train_wide`, `X_train_deep`), puedes pasar un diccionario {`\"input_wide\": X_train_wide`, `\"input_deep\": X_train_deep}`, si configuras `name=\"input_wide\"` y `name=\"input_deep\"` al crear las entradas. Esto es muy recomendable cuando hay muchas entradas, para aclarar el código y evitar errores en el orden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6178b5bb",
   "metadata": {},
   "source": [
    "También hay muchos casos de uso en los que es posible que desee tener múltiples salidas:\n",
    "\n",
    "- La tarea puede exigirlo. Por ejemplo, es posible que desee localizar y clasificar el objeto principal en una imagen. Se trata tanto de una tarea de regresión como de una tarea de clasificación.\n",
    "\n",
    "\n",
    "* Del mismo modo, puede tener varias tareas independientes basadas en los mismos datos. Claro, podrías entrenar una red neuronal por tarea, pero en muchos casos obtendrás mejores resultados en todas las tareas entrenando una sola red neuronal con una salida por tarea. Esto se debe a que la red neuronal puede aprender características en los datos que son útiles en todas las tareas. Por ejemplo, podría realizar una clasificación multitarea en imágenes de rostros, utilizando una salida para clasificar la expresión facial de la persona (sonriendo, sorprendida, etc.) y otra salida para identificar si está usando gafas o no.\n",
    "\n",
    "\n",
    "- Otro caso de uso es como una técnica de regularización (es decir, una restricción de entrenamiento cuyo objetivo es reducir el sobreajuste y, por lo tanto, mejorar la capacidad del modelo para generalizar). Por ejemplo, es posible que desee agregar una salida auxiliar en una arquitectura de red neuronal (consulte la Figura 10-15) para asegurarse de que la parte subyacente de la red aprenda algo útil por sí sola, sin depender del resto de la red.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1015.png)\n",
    "\n",
    "(Figura 10-15. Manejar múltiples salidas, en este ejemplo para agregar una salida auxiliar para la regularización)\n",
    "\n",
    "Añadir una salida adicional es bastante fácil: solo la conectamos a la capa adecuada y la añadimos a la lista de salidas del modelo. Por ejemplo, el siguiente código construye la red representada en la Figura 10-15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee305cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "[...]  # Same as above, up to the main output layer\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "aux_output = tf.keras.layers.Dense(1)(hidden2)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep],\n",
    "                       outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6111749",
   "metadata": {},
   "source": [
    "Cada salida necesitará su propia función de pérdida. Por lo tanto, cuando compilemos el modelo, deberíamos pasar una lista de pérdidas. Si pasamos una sola pérdida, Keras asumirá que se debe utilizar la misma pérdida para todas las salidas. De forma predeterminada, Keras calculará todas las pérdidas y simplemente las sumará para que la pérdida final se utilice para el entrenamiento. Dado que nos preocupamos mucho más por la salida principal que por la salida auxiliar (ya que solo se utiliza para la regularización), queremos dar a la pérdida de la salida principal un peso mucho mayor. Afortunadamente, es posible establecer todos los pesos de pérdida al compilar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42080f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=(\"mse\", \"mse\"), loss_weights=(0.9, 0.1), optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65239ccf",
   "metadata": {},
   "source": [
    "### TIP\n",
    "\n",
    "En lugar de pasar una tupla `loss=(\"mse\", \"mse\")`, puede pasar un diccionario `loss={\"output\": \"mse\", \"aux_output\": \"mse\"}`, asumiendo que creó las capas de salida con `name =\"output\"` y `name=\"aux_output\"`. Al igual que con las entradas, esto aclara el código y evita errores cuando hay varias salidas. También puedes pasar un diccionario para loss_weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb22b0",
   "metadata": {},
   "source": [
    "Ahora, cuando entrenemos el modelo, debemos proporcionar etiquetas para cada salida. En este ejemplo, la salida principal y la salida auxiliar deberían intentar predecir lo mismo, por lo que deberían utilizar las mismas etiquetas. Entonces, en lugar de pasar `y_train`, debemos pasar (`y_train`, `y_train`) o un diccionario `{\"output\": y_train, \"aux_output\": y_train}` si las salidas se denominaron `\"output\"` y `\"aux_output\"`. \n",
    "Lo mismo ocurre con `y_valid` y `y_test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=20,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289abd2f",
   "metadata": {},
   "source": [
    "Cuando evaluamos el modelo, Keras devuelve la suma ponderada de las pérdidas, así como todas las pérdidas y métricas individuales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fa072",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse = eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0fa12",
   "metadata": {},
   "source": [
    "### TIP\n",
    "\n",
    "Si pones `return_dict=True`, y después `evaluate()` retornará un diccionario en lugar de una gran tupla.\n",
    "\n",
    "De forma similar, el método `predict()` retornará predicciones para cada salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e3b6c",
   "metadata": {},
   "source": [
    "El método `predict()` devuelve una tupla y no tiene un argumento `return_dict` para obtener un diccionario. Sin embargo, puedes crear uno usando `model.output_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dbe94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tuple = model.predict((X_new_wide, X_new_deep))\n",
    "y_pred = dict(zip(model.output_names, y_pred_tuple))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e23608",
   "metadata": {},
   "source": [
    "Como puedes ver, puedes construir todo tipo de arquitecturas con la API funcional. A continuación, veremos una última forma de construir modelos de Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047c17f",
   "metadata": {},
   "source": [
    "## Uso de la API de subclasificación para construir modelos dinámicos\n",
    "\n",
    "\n",
    "Tanto la API secuencial como la API funcional son declarativas: comienzas por declarar qué capas quieres usar y cómo deben conectarse, y solo entonces puedes comenzar a alimentar al modelo algunos datos para entrenamiento o inferencia. Esto tiene muchas ventajas: el modelo se puede guardar, clonar y compartir fácilmente; su estructura se puede mostrar y analizar; el marco puede inferir formas y tipos de verificación, por lo que los errores se pueden detectar temprano (es decir, antes de que cualquier dato pase por el modelo). También es bastante fácil de depurar, ya que todo el modelo es un gráfico estático de capas. Pero la otra cara es solo eso: es estático. \n",
    "\n",
    "Algunos modelos implican bucles, formas variables, ramificaciones condicionales y otros comportamientos dinámicos. Para tales casos, o simplemente si prefiere un estilo de programación más imperativo, la API de subclasificación es para usted.\n",
    "\n",
    "Con este enfoque, subclasificas la clase `Model`, creas las capas que necesitas en el constructor y las utilizas para realizar los cálculos que deseas en el método `call()`. Por ejemplo, crear una instancia de la siguiente clase `WideAndDeepModel` nos proporciona un modelo equivalente al que acabamos de crear con la API funcional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbe85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(tf.keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)  # needed to support naming the model\n",
    "        self.norm_layer_wide = tf.keras.layers.Normalization()\n",
    "        self.norm_layer_deep = tf.keras.layers.Normalization()\n",
    "        self.hidden1 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = tf.keras.layers.Dense(1)\n",
    "        self.aux_output = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_wide, input_deep = inputs\n",
    "        norm_wide = self.norm_layer_wide(input_wide)\n",
    "        norm_deep = self.norm_layer_deep(input_deep)\n",
    "        hidden1 = self.hidden1(norm_deep)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "        output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\", name=\"my_cool_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85765e11",
   "metadata": {},
   "source": [
    "Este ejemplo se parece al anterior, excepto que separamos la creación de las capas⁠ en el constructor de su uso en el método `call()`. Y no necesitamos crear los objetos de `Input`: podemos usar el argumento de `Input` para el método `call()`.\n",
    "\n",
    "Ahora que tenemos una instancia de modelo, podemos compilarla, adaptar sus capas de normalización (por ejemplo, usando `model.norm_layer_wide.adapt(...)` y `model.norm_​layer_deep.adapt(...)`), ajustarla, evaluar y usarlo para hacer predicciones, exactamente como lo hicimos con la API funcional.\n",
    "\n",
    "La gran diferencia con esta API es que puedes incluir prácticamente cualquier cosa que quieras en el método `call()`: bucles `for`, sentencias `if`, operaciones de TensorFlow de bajo nivel... ¡tu imaginación es el límite (consulta el Capítulo 12)! Esto la convierte en una excelente API a la hora de experimentar con nuevas ideas, especialmente para los investigadores. Sin embargo, esta flexibilidad adicional tiene un costo: la arquitectura de su modelo está oculta dentro del método `call()`, por lo que Keras no puede inspeccionarla fácilmente; el modelo no se puede clonar usando `tf.keras.models.clone_model()`; y cuando llamas al método `summary()`, solo obtienes una lista de capas, sin ninguna información sobre cómo están conectadas entre sí. Además, Keras no puede comprobar los tipos y formas con antelación, y es más fácil cometer errores. Entonces, a menos que realmente necesite esa flexibilidad adicional, probablemente debería ceñirse a la API secuencial o la API funcional.\n",
    "\n",
    "\n",
    "### TIP\n",
    "\n",
    "Los modelos de Keras se pueden utilizar como capas normales, por lo que puede combinarlos fácilmente para construir arquitecturas complejas.\n",
    "\n",
    "\n",
    "Ahora que sabes cómo construir y entrenar redes neuronales usando Keras, **¡querrás salvarlas!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be19976e",
   "metadata": {},
   "source": [
    "## Guardar y restaurar un modelo\n",
    "\n",
    "Guardar un modelo de Keras entrenado es lo más simple que se pone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7981db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558c345",
   "metadata": {},
   "source": [
    "Cuando estableces `save_format=\"tf\"` Keras guarda el modelo usando el formato _SavedModel_ de TensorFlow: este es un directorio (con el nombre dado) que contiene varios archivos y subdirectorios. En particular, el archivo _saved_model.pb_ contiene la arquitectura y la lógica del modelo en forma de un gráfico de cálculo serializado, por lo que no es necesario implementar el código fuente del modelo para usarlo en producción; el SavedModel es suficiente (verá cómo funciona esto en el capítulo 12). El archivo Thekeras_metadata.pb contiene información adicional que necesita Keras. El subdirectorio de variables contiene todos los valores de los parámetros (incluidos los pesos de conexión, los sesgos, las estadísticas de normalización y los parámetros del optimizador), posiblemente divididos en varios archivos si el modelo es muy grande. Por último, el directorio de activos puede contener archivos adicionales, como muestras de datos, nombres de características, nombres de clases, etc. De forma predeterminada, el directorio de activos está vacío. Dado que el optimizador también se guarda, incluidos sus hiperparámetros y cualquier estado que pueda tener, después de cargar el modelo puede continuar entrenando si lo desea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bea5a48",
   "metadata": {},
   "source": [
    "### NOTA\n",
    "\n",
    "Si configura `save_format=\"h5\"` o usa un nombre de archivo que termina en _.h5, .hdf5 o .keras_, Keras guardará el modelo en un solo archivo usando un formato específico de Keras basado en el formato HDF5. Sin embargo, la mayoría de las herramientas de implementación de TensorFlow requieren el formato SavedModel.\n",
    "\n",
    "----------------------------------------------------------------------------\n",
    "\n",
    "Por lo general, tendrá un script que entrena un modelo y lo guarda, y uno o más scripts (o servicios web) que cargan el modelo y lo utilizan para evaluarlo o hacer predicciones. Cargar el modelo es tan fácil como guardarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35128eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"my_keras_model\")\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655929fd",
   "metadata": {},
   "source": [
    "También puede utilizar `save_weights()` y `load_weights()` para guardar y cargar solo los valores de los parámetros. Esto incluye los pesos de conexión, los sesgos, las estadísticas de preprocesamiento, el estado del optimizador, etc. Los valores de los parámetros se guardan en uno o más archivos como _my_weights.data-00004-of-00052_, además de un archivo de índice como _my_weights.index_.\n",
    "\n",
    "Guardar solo los pesos es más rápido y utiliza menos espacio en disco que guardar todo el modelo, por lo que es perfecto para guardar puntos de control rápidos durante el entrenamiento. Si está entrenando un modelo grande y le lleva horas o días, debe guardar puntos de control con regularidad en caso de que la computadora falle. Pero, ¿cómo se puede indicar al método `fit()` que guarde los puntos de control? Utilice devoluciones de llamada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c6c365",
   "metadata": {},
   "source": [
    "## Uso de Callbacks (devoluciones de llamada)\n",
    "\n",
    "El método `fit()` acepta un argumento de devolución de llamada que le permite especificar una lista de objetos que Keras llamará antes y después del entrenamiento, antes y después de cada época, e incluso antes y después de procesar cada lote. Por ejemplo, la devolución de llamada `ModelCheckpoint` guarda los puntos de control de su modelo a intervalos regulares durante el entrenamiento, de forma predeterminada al final de cada época:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2db4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_checkpoints\", save_weights_only=True)\n",
    "\n",
    "history = model.fit([...], callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95ce482",
   "metadata": {},
   "source": [
    "Además, si utiliza un conjunto de validación durante el entrenamiento, puede configurar `save_best_only=True` al crear `ModelCheckpoint`. En este caso, sólo guardará su modelo cuando su rendimiento en el conjunto de validación sea el mejor hasta el momento. De esta manera, no necesita preocuparse por entrenar durante demasiado tiempo y sobreajustar el conjunto de entrenamiento: simplemente restaure el último modelo guardado después del entrenamiento, y este será el mejor modelo en el conjunto de validación. Esta es una forma de implementar la parada temprana (introducida en el Capítulo 4), pero en realidad no detendrá el entrenamiento.\n",
    "\n",
    "Otra forma es usar la devolución de llamada `EarlyStopping`. Interrumpirá el entrenamiento cuando no mida ningún progreso en el conjunto de validación para una serie de épocas (definidas por el argumento patience), y si `restore_best_weights=True`, volverá al mejor modelo al final del entrenamiento. Puede combinar ambas devoluciones de llamada para guardar los puntos de control de su modelo en caso de que su computadora se bloquee, e interrumpir el entrenamiento temprano cuando no haya más progreso, para evitar perder tiempo y recursos y reducir el sobreajuste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit([...], callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d68931",
   "metadata": {},
   "source": [
    "El número de épocas se puede establecer en un valor grande, ya que el entrenamiento se detendrá automáticamente cuando no haya más progreso (solo asegúrese de que la tasa de aprendizaje no sea demasiado pequeña, de lo contrario, podría seguir progresando lentamente hasta el final). La devolución de llamada `EarlyStopping` almacenará los pesos del mejor modelo en la RAM y los restaurará al final del entrenamiento.\n",
    "\n",
    "\n",
    "### TIP\n",
    "\n",
    "Muchas otras callbacks están disponibles en el paquete `tf.keras.callbacks`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6ea55",
   "metadata": {},
   "source": [
    "Si necesitas un control adicional, puedes escribir fácilmente tus propias devoluciones de llamada personalizadas. Por ejemplo, la siguiente devolución de llamada personalizada mostrará la relación entre la pérdida de validación y la pérdida de entrenamiento durante el entrenamiento (por ejemplo, para detectar el sobreajuste):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7aa379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class PrintValTrainRatioCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        ratio = logs[\"val_loss\"] / logs[\"loss\"]\n",
    "        print(f\"Epoch={epoch}, val/train={ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4191b",
   "metadata": {},
   "source": [
    "Como era de esperar, puede implementar `on_train_begin()`, `on_train_end()`, `on_epoch_begin()`, `on_epoch_end()`, `on_batch_begin()` y `on_batch_end()`. Las devoluciones de llamada también se pueden utilizar durante la evaluación y las predicciones, en caso de que alguna vez las necesite (por ejemplo, para depurar). Para la evaluación, debe implementar `on_test_begin()`, `on_test_end()`, `on_test_batch_begin()` o `on_test_batch_end()`, que son llamados por `evaluate()`. \n",
    "\n",
    "Para la predicción, debe implementar `on_predict_begin()`, `on_predict_end()`, `on_predict_batch_begin()` o `on_predict_batch_end()`, que son llamados por `predict()`.\n",
    "\n",
    "Ahora echemos un vistazo a una herramienta más que definitivamente deberías tener en tu caja de herramientas cuando uses Keras: TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086aaed1",
   "metadata": {},
   "source": [
    "## Uso de TensorBoard para la visualización\n",
    "\n",
    "TensorBoard es una gran herramienta de visualización interactiva que puede utilizar para ver las curvas de aprendizaje durante el entrenamiento, comparar curvas y métricas entre múltiples carreras, visualizar el gráfico de cálculo, analizar las estadísticas de entrenamiento, ver imágenes generadas por su modelo, visualizar datos multidimensionales complejos proyectados en 3D y agrupados automáticamente para usted, perfilar su red (es decir, medir su velocidad para identificar cuellos de botella), ¡y más!\n",
    "\n",
    "TensorBoard se instala automáticamente cuando instalas TensorFlow. Sin embargo, necesitará un complemento de TensorBoard para visualizar los datos de perfil. Si siguió las instrucciones de instalación en https://homl.info/install para ejecutar todo localmente, entonces ya tiene el complemento instalado, pero si está utilizando Colab, debe ejecutar el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290eeace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -U tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb410e17",
   "metadata": {},
   "source": [
    "Para usar TensorBoard, debe modificar su programa para que genere los datos que desea visualizar en archivos de registro binarios especiales llamados archivos de eventos. Cada registro de datos binarios se llama resumen. El servidor TensorBoard supervisará el directorio de registro y recogerá automáticamente los cambios y actualizará las visualizaciones: esto le permite visualizar datos en vivo (con un corto retraso), como las curvas de aprendizaje durante el entrenamiento. En general, desea apuntar el servidor de TensorBoard a un directorio de registro raíz y configurar su programa para que escriba en un subdirectorio diferente cada vez que se ejecute. De esta manera, la misma instancia de servidor de TensorBoard le permitirá visualizar y comparar datos de múltiples ejecuciones de su programa, sin confundir todo.\n",
    "\n",
    "Vamos a nombrar el directorio de registro raíz my_logs, y definamos una pequeña función que genere la ruta del subdirectorio de registro en función de la fecha y hora actuales, para que sea diferente en cada ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ce6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "run_logdir = get_run_logdir()  # e.g., my_logs/run_2022_08_01_17_25_59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6453eec",
   "metadata": {},
   "source": [
    "La buena noticia es que Keras proporciona una conveniente devolución de llamada de `TensorBoard()` que se encargará de crear el directorio de registro por usted (junto con sus directorios principales si es necesario), creará archivos de eventos y les escribirá resúmenes durante el entrenamiento. Medirá la pérdida y las métricas de entrenamiento y validación de su modelo (en este caso, MSE y RMSE), y también perfilará su red neuronal. Es sencillo de utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cd1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir, profile_batch=(100, 200))\n",
    "\n",
    "history = model.fit([...], callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fddd89f",
   "metadata": {},
   "source": [
    "¡Eso es todo! En este ejemplo, perfilará la red entre los lotes 100 y 200 durante la primera época. ¿Por qué 100 y 200? Bueno, a menudo se necesitan algunos lotes para que la red neuronal se \"caliente\", por lo que no quieres perfilar demasiado pronto, y la elaboración de perfiles utiliza recursos, por lo que es mejor no hacerlo por cada lote.\n",
    "\n",
    "A continuación, intente cambiar la tasa de aprendizaje de 0,001 a 0,002, y ejecute el código de nuevo, con un nuevo subdirectorio de registro. Terminarás con una estructura de directorios similar a esta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99072de",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_logs ├── run_2022_08_01_17_25_59 │ ├── tren │ │ ├── events.out.tfevents.1659331561.my_host_name.42042.0.v2 │ │ ├── events.out.tfevents.1659331562.my_host_name.profile-empty │ │ └── plugins │ │ └── perfil │ │ └── 2022_08_01_17_26_02 │ │ ├── my_host_name.input_pipeline.pb │ │ └── [...] │ └── validación │ └── events.out.tfevents.1659331562.my_host_name.42042.1.v2 └── run_2022_08_01_17_31_12 └── [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebd901",
   "metadata": {},
   "source": [
    "Hay un directorio por ejecución, cada uno de los cuales contiene un subdirectorio para los registros de entrenamiento y otro para los registros de validación. Ambos contienen archivos de eventos, y los registros de entrenamiento también incluyen rastros de perfil.\n",
    "\n",
    "Ahora que tienes los archivos de eventos listos, es hora de iniciar el servidor TensorBoard. Esto se puede hacer directamente dentro de Jupyter o Colab utilizando la extensión Jupyter para TensorBoard, que se instala junto con la biblioteca de TensorBoard. Esta extensión está preinstalada en Colab. El siguiente código carga la extensión de Jupyter para TensorBoard, y la segunda línea inicia un servidor de TensorBoard para el directorio my_logs, se conecta a este servidor y muestra la interfaz de usuario directamente dentro de Jupyter. El servidor escucha en el primer puerto TCP disponible mayor o igual a 6006 (o puede establecer el puerto que desee utilizando la opción `--port`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f0b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539fe329",
   "metadata": {},
   "source": [
    "### TIP\n",
    "\n",
    "Si está ejecutando todo en su propia máquina, es posible iniciar TensorBoard ejecutando `tensorboard --logdir=./my_logs` en una terminal. Primero debe activar el entorno Conda en el que instaló TensorBoard e ir al directorio handson-ml3. Una vez iniciado el servidor, visite http://localhost:6006."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafcd967",
   "metadata": {},
   "source": [
    "Ahora deberías ver la interfaz de usuario de TensorBoard. Haga clic en la pestaña SCALARS para ver las curvas de aprendizaje (consulte la Figura 10-16). En la parte inferior izquierda, seleccione los registros que desea visualizar (por ejemplo, los registros de entrenamiento de la primera y la segunda ejecución) y haga clic en el `epoch_loss`. Tenga en cuenta que la pérdida de entrenamiento bajó muy bien durante ambas carreras, pero en la segunda carrera bajó un poco más rápido gracias a la mayor tasa de aprendizaje.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_1016.png)\n",
    "\n",
    "_Figura 10-16. Visualización de curvas de aprendizaje con TensorBoard_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20a8ac",
   "metadata": {},
   "source": [
    "También puede visualizar el gráfico de cálculo completo en la pestaña GRÁFICOS, los pesos aprendidos proyectados en 3D en la pestaña PROYECTOR y las trazas de perfilado en la pestaña PERFIL. La devolución de llamada de `TensorBoard()` también tiene opciones para registrar datos adicionales (consulte la documentación para obtener más detalles). Puede hacer clic en el botón de actualización (⟳) en la parte superior derecha para que TensorBoard actualice los datos, y puede hacer clic en el botón de configuración (⚙) para activar la actualización automática y especificar el intervalo de actualización.\n",
    "\n",
    "Además, TensorFlow ofrece una API de nivel inferior en el paquete `tf.summary`. El siguiente código crea un `SummaryWriter` usando la función `create_file_writer()` y usa este escritor como un contexto de Python para registrar escalares, histogramas, imágenes, audio y texto, los cuales luego se pueden visualizar usando TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(str(test_logdir))\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "\n",
    "        data = (np.random.randn(100) + 2) * step / 100  # gets larger\n",
    "        tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "\n",
    "        images = np.random.rand(2, 32, 32, 3) * step / 1000  # gets brighter\n",
    "        tf.summary.image(\"my_images\", images, step=step)\n",
    "\n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step ** 2)]\n",
    "        tf.summary.text(\"my_text\", texts, step=step)\n",
    "\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c6e76a",
   "metadata": {},
   "source": [
    "Si ejecuta este código y hace clic en el botón de actualización en TensorBoard, verá que aparecen varias pestañas: IMÁGENES, AUDIO, DISTRIBUCIONES, HISTOGRAMAS y TEXTO. Intente hacer clic en la pestaña IMÁGENES y utilice el control deslizante sobre cada imagen para ver las imágenes en diferentes pasos de tiempo. Del mismo modo, vaya a la pestaña AUDIO e intente escuchar el audio en diferentes pasos de tiempo. Como puede ver, TensorBoard es una herramienta útil incluso más allá de TensorFlow o el aprendizaje profundo.\n",
    "\n",
    "\n",
    "### TIP\n",
    "\n",
    "Puede compartir sus resultados en línea publicándolos en https://tensorboard.dev. Para esto, simplemente ejecute `!tensorboard dev upload --logdir ./my_logs`. La primera vez te pedirá que aceptes los términos y condiciones y te autentifiques. Luego se cargarán sus registros y obtendrá un enlace permanente para ver sus resultados en una interfaz de TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24080c",
   "metadata": {},
   "source": [
    "Resumamos lo que has aprendido hasta ahora en este capítulo: ahora sabes de dónde vienen las redes neuronales, qué es un MLP y cómo puedes usarlo para la clasificación y regresión, cómo usar la API secuencial de Keras para construir MLP, y cómo usar la API funcional o la API de subclasificación para construir arquitecturas de modelos más complejas (incluidos modelos Wide & Deep, así como modelos con múltiples entradas y salidas). También aprendiste a guardar y restaurar un modelo y a usar las devoluciones de llamada para las puntos de control, la detención temprana y más. Finalmente, aprendiste a usar TensorBoard para la visualización. ¡Ya puedes seguir adelante y usar redes neuronales para abordar muchos problemas! Sin embargo, es posible que te preguntes cómo elegir el número de capas ocultas, el número de neuronas en la red y todos los demás hiperparámetros. Echemos un vistazo a esto ahora.\n",
    "\n",
    "\n",
    "## Hiperparámetros de redes neuronales de ajuste fino\n",
    "\n",
    "\n",
    "La flexibilidad de las redes neuronales también es uno de sus principales inconvenientes: hay muchos hiperparámetros que ajustar. No solo puede usar cualquier arquitectura de red imaginable, sino que incluso en un MLP básico puede cambiar el número de capas, el número de neuronas y el tipo de función de activación a usar en cada capa, la lógica de inicialización de peso, el tipo de optimizador a usar, su tasa de aprendizaje, el tamaño del lote y más. ¿Cómo sabes qué combinación de hiperparámetros es la mejor para tu tarea?\n",
    "\n",
    "\n",
    "Una opción es convertir su modelo Keras en un estimador Scikit-Learn y luego usar `GridSearchCV` o `RandomizedSearchCV` para ajustar los hiperparámetros, como lo hizo en el Capítulo 2. Para esto, puede usar las clases contenedoras `KerasRegressor` y `KerasClassifier` de SciKeras. biblioteca (consulte https://github.com/adriangb/scikeras para obtener más detalles). Sin embargo, hay una manera mejor: puede usar la biblioteca Keras Tuner, que es una biblioteca de ajuste de hiperparámetros para modelos Keras. Ofrece varias estrategias de ajuste, es altamente personalizable y tiene una excelente integración con TensorBoard. Veamos cómo usarlo.\n",
    "\n",
    "Si siguió las instrucciones de instalación en https://homl.info/install para ejecutar todo localmente, entonces ya tiene Keras Tuner instalado, pero si está usando Colab, deberá ejecutar `%pip install -q -U keras-tuner`. A continuación, importe `keras_tuner`, generalmente como kt, luego escriba una función que construya, compile y devuelva un modelo de Keras. La función debe tomar un objeto `kt.HyperParameters` como argumento, que puede usar para definir hiperparámetros (enteros, flotantes, cadenas, etc.) junto con su rango de valores posibles, y estos hiperparámetros pueden usarse para construir y compilar el modelo. . Por ejemplo, la siguiente función crea y compila un MLP para clasificar imágenes MNIST de moda, utilizando hiperparámetros como el número de capas ocultas (`n_hidden`), el número de neuronas por capa (`n_neurons`), la tasa de aprendizaje (`learning_rate`) y el tipo del optimizador a utilizar (`optimizer`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
    "                             sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fab0d9",
   "metadata": {},
   "source": [
    "La primera parte de la función define los hiperparámetros. Por ejemplo, `hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)` comprueba si un hiperparámetro llamado `\"n_hidden\"` ya está presente en el objeto `HyperParameters` `hp` y, de ser así, devuelve su valor. De lo contrario, registra un nuevo hiperparámetro entero llamado `\"n_hidden\"`, cuyos valores posibles oscilan entre 0 y 8 (inclusive), y devuelve el valor predeterminado, que es 2 en este caso (cuando el valor `default` no está establecido, entonces `min_value` es devuelto). El hiperparámetro `\"n_neurons\"` se registra de forma similar. El hiperparámetro `\"learning_rate\"` se registra como un valor flotante que oscila entre 10ˆ–4 y 10ˆ–2 y, dado que `sampling=\"log\"`, las tasas de aprendizaje de todas las escalas se muestrearán por igual. Por último, el hiperparámetro del `optimizer` se registra con dos valores posibles: `\"sgd\"` o `\"adam\"` (el valor predeterminado es el primero, que en este caso es `\"sgd\"`). Dependiendo del valor del optimizador, creamos un optimizador `SGD` o un optimizador `Adam` con la tasa de aprendizaje dada.\n",
    "\n",
    "La segunda parte de la función simplemente construye el modelo utilizando los valores de los hiperparámetros. Crea un modelo `Sequential` comenzando con una capa `Flatten`, seguida del número solicitado de capas ocultas (según lo determinado por el hiperparámetro `n_hidden`) usando la función de activación ReLU y una capa de salida con 10 neuronas (una por clase) usando la función de activación softmax. . Por último, la función compila el modelo y lo devuelve.\n",
    "\n",
    "Ahora, si desea realizar una búsqueda aleatoria básica, puede crear un sintonizador `kt.RandomSearch`, pasando la función `build_model` al constructor y llamar al método `search()` del sintonizador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0dfb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model, objective=\"val_accuracy\", max_trials=5, overwrite=True,\n",
    "    directory=\"my_fashion_mnist\", project_name=\"my_rnd_search\", seed=42)\n",
    "    random_search_tuner.search(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f79ee",
   "metadata": {},
   "source": [
    "El sintonizador `RandomSearch` primero llama a `build_model()` una vez con un objeto `Hyperparameters` vacío, solo para recopilar todas las especificaciones de hiperparámetros. Luego, en este ejemplo, realiza 5 pruebas; para cada prueba, crea un modelo utilizando hiperparámetros muestreados aleatoriamente dentro de sus respectivos rangos, luego entrena ese modelo durante 10 épocas y lo guarda en un subdirectorio del directorio my_fashion_mnist/my_rnd_search. Como `overwrite=True`, el directorio my_rnd_search se elimina antes de que comience el entrenamiento. Si ejecuta este código por segunda vez pero con `overwrite=False` y `max_tri⁠als=10`, el sintonizador continuará afinando donde lo dejó, ejecutando 5 pruebas más: esto significa que no tiene que ejecutar todas las pruebas en un trago. Por último, dado que el `objetive` está establecido en `\"val_accuracy\"`, el sintonizador prefiere modelos con una mayor precisión de validación, por lo que una vez que el sintonizador haya terminado de buscar, podrá obtener los mejores modelos como este:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "best_model = top3_models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e5d01",
   "metadata": {},
   "source": [
    "También podemos llamar a `get_best_hyperparameters()` para obtener el `kt.HyperParameters` de los mejores modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd614f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_params[0].values  # mejores valores para los hiperparámetros\n",
    "\n",
    "'''\n",
    "{'n_hidden': 5,\n",
    " 'n_neurons': 70,\n",
    " 'learning_rate': 0.00041268008323824807,\n",
    " 'optimizer': 'adam'}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab99c5c5",
   "metadata": {},
   "source": [
    "Cada sintonizador es guiado por un llamado oráculo: antes de cada prueba, el sintonizador le pide al oráculo que le diga cuál debería ser la próxima prueba. El sintonizador `RandomSearch` utiliza `RandomSearchOracle`, que es bastante básico: simplemente elige la siguiente prueba al azar, como vimos anteriormente. Dado que el oráculo realiza un seguimiento de todas las pruebas, puede pedirle que le proporcione la mejor y puede mostrar un resumen de esa prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53daa2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8994b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial.summary()\n",
    "\n",
    "'''\n",
    "Trial summary\n",
    "Hyperparameters:\n",
    "n_hidden: 5\n",
    "n_neurons: 70\n",
    "learning_rate: 0.00041268008323824807\n",
    "optimizer: adam\n",
    "Score: 0.8736000061035156\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a85cc3",
   "metadata": {},
   "source": [
    "Esto muestra los mejores hiperparámetros (como antes), así como la precisión de la validación. También puedes acceder a todas las métricas directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd8fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial.metrics.get_last_value(\"val_accuracy\")\n",
    "\n",
    "#0.8736000061035156"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ac887",
   "metadata": {},
   "source": [
    "Si está satisfecho con el mejor rendimiento del modelo, puede continuar entrenándolo durante algunas épocas en el conjunto de entrenamiento completo (`X_train_full` e `y_train_full`), luego evaluarlo en el conjunto de prueba e implementarlo en producción (consulte el Capítulo 19):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train_full, y_train_full, epochs=10)\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00748aaf",
   "metadata": {},
   "source": [
    "En algunos casos, es posible que desee ajustar los hiperparámetros de preprocesamiento de datos o los argumentos `model.fit()`, como el tamaño del lote. Para esto, debes usar una técnica ligeramente diferente: en lugar de escribir una función `build_model()`, debes subclasificar la clase `kt.HyperModel` y definir dos métodos, `build()` y `fit()`. El método `build()` hace exactamente lo mismo que la función `build_model()`. El método fit() toma un objeto `HyperParameters` y un modelo compilado como argumento, así como todos los argumentos `model.fit()`, ajusta el modelo y devuelve el objeto `History`. Fundamentalmente, el método `fit()` puede utilizar hiperparámetros para decidir cómo preprocesar los datos, ajustar el tamaño del lote y más. Por ejemplo, la siguiente clase construye el mismo modelo que antes, con los mismos hiperparámetros, pero también utiliza un hiperparámetro booleano de `\"normalize\"` para controlar si se estandarizan o no los datos de entrenamiento antes de ajustar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassificationHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        return build_model(hp)\n",
    "\n",
    "    def fit(self, hp, model, X, y, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            norm_layer = tf.keras.layers.Normalization()\n",
    "            X = norm_layer(X)\n",
    "        return model.fit(X, y, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f203fe",
   "metadata": {},
   "source": [
    "Luego puede pasar una instancia de esta clase al sintonizador de su elección, en lugar de pasar la función `build_model`. Por ejemplo, creemos un sintonizador `kt.Hyperband` basado en una instancia `MyClassificationHyperModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperband_tuner = kt.Hyperband(\n",
    "    MyClassificationHyperModel(), objective=\"val_accuracy\", seed=42,\n",
    "    max_epochs=10, factor=3, hyperband_iterations=2,\n",
    "    overwrite=True, directory=\"my_fashion_mnist\", project_name=\"hyperband\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d86cba2",
   "metadata": {},
   "source": [
    "Este sintonizador es similar a la clase `HalvingRandomSearchCV` que analizamos en el Capítulo 2: comienza entrenando muchos modelos diferentes durante algunas épocas, luego elimina los peores modelos y mantiene solo los modelos de `1 / factor` superiores (es decir, el tercio superior en este caso). , repitiendo este proceso de selección hasta que quede un solo modelo. El argumento `max_epochs` controla el número máximo de épocas para las que se entrenará el mejor modelo. En este caso, todo el proceso se repite dos veces (`hyperband_iterations=2`). El número total de épocas de entrenamiento en todos los modelos para cada iteración de hiperbanda es aproximadamente `max_epochs * (log(max_epochs) / log(factor)) ** 2`, por lo que son aproximadamente 44 épocas en este ejemplo. Los demás argumentos son los mismos que para `kt.RandomSearch`.\n",
    "\n",
    "Ejecutemos el sintonizador Hyperband ahora. Usaremos la devolución de llamada de `TensorBoard`, esta vez apuntando al directorio de registro raíz (el sintonizador se encargará de usar un subdirectorio diferente para cada prueba), así como una devolución de llamada `EarlyStopping`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112bb863",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = Path(hyperband_tuner.project_dir) / \"tensorboard\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(root_logdir)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "hyperband_tuner.search(X_train, y_train, epochs=10,\n",
    "                       validation_data=(X_valid, y_valid),\n",
    "                       callbacks=[early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1ea5b1",
   "metadata": {},
   "source": [
    "Ahora, si abre TensorBoard y apunta `--logdir` al directorio my_fashion_mnist/hyperband/tensorboard, verá todos los resultados de la prueba a medida que se desarrollan. Asegúrese de visitar la pestaña HPARAMS: contiene un resumen de todas las combinaciones de hiperparámetros que se probaron, junto con las métricas correspondientes. Observe que hay tres pestañas dentro de la pestaña HPARAMS: una vista de tabla, una vista de coordenadas paralelas y una vista de matriz de diagrama de dispersión. En la parte inferior del panel izquierdo, desmarque todas las métricas excepto `validation.epoch_accuracy`: esto hará que los gráficos sean más claros. En la vista de coordenadas paralelas, intente seleccionar un rango de valores altos en la columna `validation.epoch_accuracy`: esto filtrará solo las combinaciones de hiperparámetros que alcanzaron un buen rendimiento. Haga clic en una de las combinaciones de hiperparámetros y las curvas de aprendizaje correspondientes aparecerán en la parte inferior de la página. Tómate un tiempo para revisar cada pestaña; esto le ayudará a comprender el efecto de cada hiperparámetro en el rendimiento, así como las interacciones entre los hiperparámetros.\n",
    "\n",
    "Hyperband es más inteligente que la búsqueda aleatoria pura en la forma en que asigna recursos, pero en esencia aún explora el espacio de hiperparámetros de forma aleatoria; es rápido, pero tosco. Sin embargo, Keras Tuner también incluye un sintonizador `kt.BayesianOptimization`: este algoritmo aprende gradualmente qué regiones del espacio de hiperparámetros son más prometedoras ajustando un modelo probabilístico llamado proceso gaussiano. Esto le permite acercarse gradualmente a los mejores hiperparámetros. La desventaja es que el algoritmo tiene sus propios hiperparámetros: `alpha` representa el nivel de ruido que espera en las medidas de rendimiento en todas las pruebas (el valor predeterminado es 10^-4) y `beta` especifica cuánto desea que explore el algoritmo, en lugar de simplemente explotar. las regiones buenas conocidas del espacio de hiperparámetros (el valor predeterminado es 2.6). Aparte de eso, este sintonizador se puede utilizar igual que los anteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded20d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_opt_tuner = kt.BayesianOptimization(\n",
    "    MyClassificationHyperModel(), objective=\"val_accuracy\", seed=42,\n",
    "    max_trials=10, alpha=1e-4, beta=2.6,\n",
    "    overwrite=True, directory=\"my_fashion_mnist\", project_name=\"bayesian_opt\")\n",
    "bayesian_opt_tuner.search([...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f37259",
   "metadata": {},
   "source": [
    "El ajuste de hiperparámetros sigue siendo un área activa de investigación, y se están explorando muchos otros enfoques. Por ejemplo, echa un vistazo al excelente artículo de DeepMind de 2017, donde los autores utilizaron un algoritmo evolutivo para optimizar conjuntamente una población de modelos y sus hiperparámetros. Google también ha utilizado un enfoque evolutivo, no solo para buscar hiperparámetros, sino también para explorar todo tipo de arquitecturas de modelos: impulsa su servicio AutoML en Google Vertex AI (ver Capítulo 19). El término AutoML se refiere a cualquier sistema que se encargue de una gran parte del flujo de trabajo de ML. ¡Incluso los algoritmos evolutivos se han utilizado con éxito para entrenar redes neuronales individuales, reemplazando el ubicuo descenso de gradiente! Por ejemplo, vea la publicación de 2017 de Uber donde los autores presentan su técnica de _Neuroevolución Profunda_.\n",
    "\n",
    "Pero a pesar de todo este emocionante progreso y todas estas herramientas y servicios, todavía ayuda tener una idea de qué valores son razonables para cada hiperparámetro para que pueda construir un prototipo rápido y restringir el espacio de búsqueda. Las siguientes secciones proporcionan pautas para elegir el número de capas y neuronas ocultas en un MLP y para seleccionar buenos valores para algunos de los principales hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d8906",
   "metadata": {},
   "source": [
    "## Número de capas ocultas\n",
    "\n",
    "Para muchos problemas, puedes comenzar con una sola capa oculta y obtener resultados razonables. Un MLP con una sola capa oculta puede teóricamente modelar incluso las funciones más complejas, siempre que tenga suficientes neuronas. Pero para problemas complejos, las redes profundas tienen una eficiencia de parámetros mucho mayor que las poco profundas: pueden modelar funciones complejas utilizando exponencialmente menos neuronas que redes poco profundas, lo que les permite alcanzar un rendimiento mucho mejor con la misma cantidad de datos de entrenamiento.\n",
    "\n",
    "Para entender por qué, supongamos que se le pide que dibuje un bosque usando algún software de dibujo, pero que tiene prohibido copiar y pegar cualquier cosa. Tomaría una enorme cantidad de tiempo: tendrías que dibujar cada árbol individualmente, rama por rama, hoja por hoja. Si en su lugar pudieras dibujar una hoja, copiarla y pegarla para dibujar una rama, luego copiar y pegar esa rama para crear un árbol, y finalmente copiar y pegar este árbol para hacer un bosque, estarías terminado en muy poco tiempo. Los datos del mundo real a menudo se estructuran de una manera tan jerárquica, y las redes neuronales profundas se aprovechan automáticamente de este hecho: las capas ocultas más bajas modelan estructuras de bajo nivel (por ejemplo, segmentos de línea de varias formas y orientaciones), las capas ocultas intermedias combinan estas estructuras de bajo nivel para modelar estructuras de nivel intermedio (por ejemplo, cuadrados, círculos), y las capas ocultas más altas y la capa de salida combinan estas estructuras intermedias para modelar estructuras de alto nivel (por ejemplo, caras).\n",
    "\n",
    "Esta arquitectura jerárquica no solo ayuda a los DNN a converger más rápido en una buena solución, sino que también mejora su capacidad para generalizar a nuevos conjuntos de datos. Por ejemplo, si ya has entrenado a un modelo para reconocer caras en imágenes y ahora quieres entrenar una nueva red neuronal para reconocer peinados, puedes iniciar el entrenamiento reutilizando las capas inferiores de la primera red. En lugar de inicializar al azar los pesos y sesgos de las primeras capas de la nueva red neuronal, puede inicializarlos a los valores de los pesos y sesgos de las capas inferiores de la primera red. De esta manera, la red no tendrá que aprender desde cero todas las estructuras de bajo nivel que aparecen en la mayoría de las imágenes; solo tendrá que aprender las estructuras de nivel superior (por ejemplo, peinados). Esto se llama aprendizaje por transferencia.\n",
    "\n",
    "En resumen, para muchos problemas puedes comenzar con solo una o dos capas ocultas y la red neuronal funcionará bien. Por ejemplo, puede alcanzar fácilmente una precisión superior al 97 % en el conjunto de datos de MNIST usando solo una capa oculta con unos pocos cientos de neuronas, y una precisión superior al 98 % utilizando dos capas ocultas con el mismo número total de neuronas, en aproximadamente la misma cantidad de tiempo de entrenamiento. Para problemas más complejos, puede aumentar el número de capas ocultas hasta que comience a superajar el conjunto de entrenamiento. Las tareas muy complejas, como la clasificación de imágenes grandes o el reconocimiento de voz, generalmente requieren redes con docenas de capas (o incluso cientos, pero no completamente conectadas, como verá en el capítulo 14), y necesitan una gran cantidad de datos de entrenamiento. Rara vez tendrás que entrenar tales redes desde cero: es mucho más común reutilizar partes de una red de última generación preentrenada que realice una tarea similar. La capacitación será mucho más rápida y requerirá muchos menos datos (lo discutiremos en el capítulo 11)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d81aca2",
   "metadata": {},
   "source": [
    "## Número de neuronas por capa oculta\n",
    "\n",
    "El número de neuronas en las capas de entrada y salida está determinado por el tipo de entrada y salida que requiere su tarea. Por ejemplo, la tarea de MNIST requiere 28 × 28 = 784 entradas y 10 neuronas de salida.\n",
    "\n",
    "En cuanto a las capas ocultas, solía ser común dimensionarlas para formar una pirámide, con cada vez menos neuronas en cada capa; la razón es que muchas características de bajo nivel pueden fusionarse en muchas menos características de alto nivel. Una red neuronal típica para MNIST podría tener 3 capas ocultas, la primera con 300 neuronas, la segunda con 200 y la tercera con 100. Sin embargo, esta práctica se ha abandonado en gran medida porque parece que el uso del mismo número de neuronas en todas las capas ocultas funciona igual de bien en la mayoría de los casos, o incluso mejor; además, solo hay un hiperparámetro para ajustar, en lugar de uno por capa. Dicho esto, dependiendo del conjunto de datos, a veces puede ayudar a hacer que la primera capa oculta sea más grande que las otras.\n",
    "\n",
    "Al igual que el número de capas, puedes intentar aumentar el número de neuronas gradualmente hasta que la red comience a sobreajustarse. Alternativamente, puede intentar construir un modelo con un poco más de capas y neuronas de las que realmente necesita, y luego usar la parada temprana y otras técnicas de regularización para evitar que se sobreajuste demasiado. Vincent Vanhoucke, un científico de Google, ha apodado a este el enfoque de los \"pantalones elásticos\": en lugar de perder el tiempo buscando pantalones que se ajusten perfectamente a tu talla, solo usa pantalones elásticos grandes que se encojan hasta el tamaño correcto. Con este enfoque, evitas las capas de cuello de botella que podrían arruinar tu modelo. De hecho, si una capa tiene muy pocas neuronas, no tendrá suficiente poder de representación para preservar toda la información útil de las entradas (por ejemplo, una capa con dos neuronas solo puede generar datos 2D, por lo que si obtiene datos 3D como entrada, se perderá parte de información). No importa cuán grande y potente sea el resto de la red, esa información nunca se recuperará.\n",
    "\n",
    "### TIP\n",
    "\n",
    "En general, obtendrás más por tu dinero al aumentar el número de capas en lugar del número de neuronas por capa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864b896",
   "metadata": {},
   "source": [
    "## Tasa de aprendizaje, tamaño del lote y otros hiperparámetros\n",
    "\n",
    "\n",
    "El número de capas y neuronas ocultas no son los únicos hiperparámetros que puedes ajustar en un MLP. Estos son algunos de los más importantes, así como consejos sobre cómo configurarlos:\n",
    "\n",
    "* **Tasa de aprendizaje:**\n",
    "    \n",
    "    Podría decirse que la tasa de aprendizaje es el hiperparámetro más importante. En general, la tasa de aprendizaje óptima es aproximadamente la mitad de la tasa máxima de aprendizaje (es decir, la tasa de aprendizaje por encima de la cual diverge el algoritmo de entrenamiento, como vimos en el Capítulo 4). Una forma de encontrar una buena tasa de aprendizaje es entrenar el modelo para unos pocos cientos de iteraciones, comenzando con una tasa de aprendizaje muy baja (por ejemplo, 10-5) y aumentando gradualmente hasta un valor muy grande (por ejemplo, 10). Esto se hace multiplicando la tasa de aprendizaje por un factor constante en cada iteración (por ejemplo, por (10 / 10-5)1 / 500 para pasar de 10-5 a 10 en 500 iteraciones). Si trazas la pérdida en función de la tasa de aprendizaje (usando una escala de registro para la tasa de aprendizaje), deberías verla caer al principio. Pero después de un tiempo, la tasa de aprendizaje será demasiado grande, por lo que la pérdida volverá a subir: la tasa de aprendizaje óptima será un poco más baja que el punto en el que la pérdida comienza a subir (normalmente unas 10 veces más baja que el punto de inflexión). Luego puedes reiniciar tu modelo y entrenarlo normalmente usando esta buena tasa de aprendizaje. Anderemos más técnicas de optimización de la tasa de aprendizaje en el capítulo 11.\n",
    "\n",
    "- **Optimizador:** \n",
    "\n",
    "    Elegir un mejor optimizador que el viejo descenso de gradiente de mini lotes (y ajustar sus hiperparámetros) también es bastante importante. Examinaremos varios optimizadores avanzados en el capítulo 11.\n",
    "\n",
    "* **Tamaño del lote:**\n",
    "\n",
    "    El tamaño del lote puede tener un impacto significativo en el rendimiento y el tiempo de entrenamiento de su modelo. El principal beneficio de usar lotes grandes es que las aceleradoras de hardware como las GPU pueden procesarlas de manera eficiente (ver Capítulo 19), por lo que el algoritmo de entrenamiento verá más instancias por segundo. Por lo tanto, muchos investigadores y profesionales recomiendan utilizar el tamaño de lote más grande que pueda caber en la RAM de la GPU. Sin embargo, hay un trago: en la práctica, los grandes tamaños de lotes a menudo conducen a inestabilidades en el entrenamiento, especialmente al comienzo del entrenamiento, y el modelo resultante puede no generalizarse tan bien como un modelo entrenado con un tamaño de lote pequeño. En abril de 2018, Yann LeCun incluso tuiteó \"Los amigos no permiten que los amigos usen mini lotes de más de 32\", citando un documento de 2018⁠21 de Dominic Masters y Carlo Luschi que concluyó que el uso de lotes pequeños (de 2 a 32) era preferible porque los lotes pequeños condujeron a mejores modelos en menos tiempo de entrenamiento. Sin embargo, otras investigaciones apuntan en la dirección opuesta. Por ejemplo, en 2017, los artículos de Elad Hoffer et al.⁠22 yPriya Goyal et al.⁠23 mostraron que era posible utilizar tamaños de lotes muy grandes (hasta 8.192) junto con varias técnicas como calentar la tasa de aprendizaje (es decir, comenzar la capacitación con una pequeña tasa de aprendizaje, luego aumentarla, como se discutió en el Capítulo 11) y obtener tiempos de entrenamiento muy cortos, sin ninguna brecha de generalización. Por lo tanto, una estrategia es tratar de usar un tamaño de lote grande, con calentamiento de la tasa de aprendizaje, y si el entrenamiento es inestable o el rendimiento final es decepcionante, entonces intente usar un tamaño de lote pequeño en su lugar.\n",
    "\n",
    "- **Función de activación:**\n",
    "\n",
    "    Discutimos cómo elegir la función de activación anteriormente en este capítulo: en general, la función de activación ReLU será un buen valor predeterminado para todas las capas ocultas, pero para la capa de salida realmente depende de su tarea.\n",
    "\n",
    "* **Número de iteraciones:**\n",
    "\n",
    "    En la mayoría de los casos, el número de iteraciones de entrenamiento en realidad no necesita ser ajustado: simplemente use la parada temprana en su lugar.\n",
    "\n",
    "\n",
    "### TIP\n",
    "\n",
    "La tasa de aprendizaje óptima depende de los otros hiperparámetros, especialmente el tamaño del lote, por lo que si modifica algún hiperparámetro, asegúrese de actualizar también la tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6094d",
   "metadata": {},
   "source": [
    "Para obtener más prácticas recomendadas con respecto al ajuste de los hiperparámetros de la red neuronal, echa un vistazo al excelente documento 2018⁠ de Leslie Smith.\n",
    "\n",
    "Esto concluye nuestra introducción a las redes neuronales artificiales y su implementación con Keras. En los próximos capítulos, discutiremos técnicas para entrenar redes muy profundas. También exploraremos cómo personalizar los modelos utilizando la API de nivel inferior de TensorFlow y cómo cargar y procesar previamente los datos de manera eficiente utilizando la API tf.data. Y nos sumergiremos en otras arquitecturas de redes neuronales populares: redes neuronales convolucionales para el procesamiento de imágenes, redes neuronales recurrentes y transformadores para datos secuenciales y texto, autocodificadores para el aprendizaje de la representación y redes adversarias generativas para modelar y generar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e477e",
   "metadata": {},
   "source": [
    "# Ejercicios\n",
    "\n",
    "1. El playground TensorFlow es un práctico simulador de redes neuronales creado por el equipo de TensorFlow. En este ejercicio, entrenará varios clasificadores binarios en solo unos pocos clics, y ajustará la arquitectura del modelo y sus hiperparámetros para obtener algo de intuición sobre cómo funcionan las redes neuronales y qué hacen sus hiperparámetros. Tómate un tiempo para explorar lo siguiente:\n",
    "\n",
    "* Los patrones aprendidos por una red neuronal. Intenta entrenar la red neuronal predeterminada haciendo clic en el botón Ejecutar (arriba a la izquierda). Observe cómo encuentra rápidamente una buena solución para la tarea de clasificación. Las neuronas de la primera capa oculta han aprendido patrones simples, mientras que las neuronas de la segunda capa oculta han aprendido a combinar los patrones simples de la primera capa oculta en patrones más complejos. En general, cuantas más capas haya, más complejos pueden ser los patrones.\n",
    "\n",
    "- Funciones de activación. Intente reemplazar la función de activación de tanh con una función de activación de ReLU y vuelva a entrenar la red. Tenga en cuenta que encuentra una solución aún más rápido, pero esta vez los límites son lineales. Esto se debe a la forma de la función ReLU.\n",
    "\n",
    "* El riesgo de los mínimos locales. Modifica la arquitectura de la red para que tenga solo una capa oculta con tres neuronas. Entrena varias veces (para restablecer los pesos de la red, haz clic en el botón Restablecer junto al botón Reproducir). Tenga en cuenta que el tiempo de entrenamiento varía mucho, y a veces incluso se queda atascado en un mínimo local.\n",
    "\n",
    "- ¿Qué sucede cuando las redes neuronales son demasiado pequeñas? Retira una neurona para mantener solo dos. Ten en cuenta que la red neuronal ahora es incapaz de encontrar una buena solución, incluso si lo intentas varias veces. El modelo tiene muy pocos parámetros y se adapta sistemáticamente al conjunto de entrenamiento.\n",
    "\n",
    "* ¿Qué sucede cuando las redes neuronales son lo suficientemente grandes? Establece el número de neuronas en ocho y entrena la red varias veces. Tenga en cuenta que ahora es consistentemente rápido y nunca se atasca. Esto pone de relieve un hallazgo importante en la teoría de las redes neuronales: las grandes redes neuronales rara vez se quedan atascadas en mínimos locales, e incluso cuando lo hacen, estos óptimos locales a menudo son casi tan buenos como el óptimo global. Sin embargo, todavía pueden quedarse atrapados en largas mesetas durante mucho tiempo.\n",
    "\n",
    "- El riesgo de desaparecer gradientes en redes profundas. Seleccione el conjunto de datos en espiral (el conjunto de datos inferior derecho en \"DATOS\") y cambie la arquitectura de la red para que tenga cuatro capas ocultas con ocho neuronas cada una. Tenga en cuenta que el entrenamiento lleva mucho más tiempo y a menudo se queda atascado en las mesetas durante largos períodos de tiempo. También observe que las neuronas en las capas más altas (a la derecha) tienden a evolucionar más rápido que las neuronas en las capas más bajas (a la izquierda). Este problema, llamado problema de los gradientes de desaparición, se puede aliviar con una mejor inicialización de peso y otras técnicas, mejores optimizadores (como AdaGrad o Adam) o normalización por lotes (discutido en el capítulo 11).\n",
    "\n",
    "* Ve más allá. Tómese una hora más o menos para jugar con otros parámetros y tener una idea de lo que hacen, para construir una comprensión intuitiva de las redes neuronales.\n",
    "\n",
    "2. Dibuja un ANN usando las neuronas artificiales originales (como las de la Figura 10-3) que calcula A ⊕ B (donde ⊕ representa la operación XOR). Sugerencia: A ⊕ B =(A ∧ ¬ B) ∨ (¬ A ∧ B).\n",
    "\n",
    "3. ¿Por qué es generalmente preferible usar un clasificador de regresión logística en lugar de un perceptrón clásico (es decir, una sola capa de unidades lógicas de umbral entrenadas utilizando el algoritmo de entrenamiento de perceptrón)? ¿Cómo se puede ajustar un perceptrón para que sea equivalente a un clasificador de regresión logística?\n",
    "\n",
    "4. ¿Por qué la función de activación sigmoide fue un ingrediente clave en el entrenamiento de los primeros MLP?\n",
    "\n",
    "5. Nombra tres funciones de activación populares. ¿Puedes dibujarlos?\n",
    "\n",
    "6. Supongamos que tiene un MLP compuesto por una capa de entrada con 10 neuronas de paso, seguida de una capa oculta con 50 neuronas artificiales y, finalmente, una capa de salida con 3 neuronas artificiales. Todas las neuronas artificiales utilizan la función de activación ReLU.\n",
    "\n",
    "- ¿Cuál es la forma de la matriz de entrada X?\n",
    "\n",
    "* ¿Cuáles son las formas de la matriz de peso de la capa oculta Wh y el vector de sesgo bh?\n",
    "\n",
    "- ¿Cuáles son las formas de la matriz de peso de la capa de salida Wo y el vector de sesgo bo?\n",
    "\n",
    "* ¿Cuál es la forma de la matriz de salida Y de la red?\n",
    "\n",
    "- Escribe la ecuación que calcula la matriz de salida de la red Y en función de X, Wh, bh, Wo y bo.\n",
    "\n",
    "7. ¿Cuántas neuronas necesitas en la capa de salida si quieres clasificar el correo electrónico en spam o jamón? ¿Qué función de activación deberías usar en la capa de salida? Si en su lugar quieres abordar el MNIST, ¿cuántas neuronas necesitas en la capa de salida y qué función de activación deberías usar? ¿Qué pasa con que su red prediga los precios de la vivienda, como en el capítulo 2?\n",
    "\n",
    "8. ¿Qué es la contrapropagación y cómo funciona? ¿Cuál es la diferencia entre la contrapropagación y la difusión automática en modo inverso?\n",
    "\n",
    "9. ¿Puedes enumerar todos los hiperparámetros que puedes ajustar en un MLP básico? Si el MLP se sobreajusta a los datos de entrenamiento, ¿cómo podrías ajustar estos hiperparámetros para tratar de resolver el problema?\n",
    "\n",
    "10. Entrena un MLP profundo en el conjunto de datos de MNIST (puedes cargarlo usando tf.keras.​data⁠sets.mnist.load_data()). Vea si puede obtener una precisión de más del 98 % ajustando manualmente los hiperparámetros. Intente buscar la tasa de aprendizaje óptima utilizando el enfoque presentado en este capítulo (es decir, aumentando la tasa de aprendizaje exponencialmente, trazando la pérdida y encontrando el punto en el que la pérdida se dispara). A continuación, intente ajustar los hiperparámetros usando Keras Tuner con todas las campanas y silbatos: guardar puntos de control, usar la parada temprana y trazar curvas de aprendizaje usando TensorBoard.\n",
    "\n",
    "11. Las soluciones a estos ejercicios están disponibles al final del cuaderno de este capítulo, en https://homl.info/colab3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4819add1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
