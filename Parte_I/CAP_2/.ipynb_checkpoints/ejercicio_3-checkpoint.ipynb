{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef82860",
   "metadata": {},
   "source": [
    "*Los ejercicios se basan en el conjunto de viviendas \"housing.csv\"*\n",
    "\n",
    "### Ejercicio 3\n",
    "\n",
    "Intente agregar un transformador **SelectFromModel** en el pipeline de preparación para seleccionar solo los atributos más importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535a881",
   "metadata": {},
   "source": [
    "#### Paso 1: Preparando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6649d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "\n",
    "URL = \"https://mymldatasets.s3.eu-de.cloud-object-storage.appdomain.cloud/housing.tgz\"\n",
    "PATH = \"housing.tgz\"\n",
    "\n",
    "def getData(url=URL, path=PATH):\n",
    "  r = requests.get(url)\n",
    "  with open(path, 'wb') as f:\n",
    "    f.write(r.content)\n",
    "  housing_tgz = tarfile.open(path)\n",
    "  housing_tgz.extractall()\n",
    "  housing_tgz.close()\n",
    "\n",
    "getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b272e31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('housing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "657f1fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11db4644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 16512, 4128)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2) # 20% para test y 80% para entrenamiento\n",
    "\n",
    "len(data), len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1908814d",
   "metadata": {},
   "source": [
    "#### Paso 2: Tratar los valores inexistentes (\"missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9cd826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b22c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, y_train = train.drop(['median_house_value'], axis=1), train['median_house_value'].copy() # quitar columna de targets del dataset de entrenamiento\n",
    "test_data, y_test = test.drop(['median_house_value'], axis=1), test['median_house_value'].copy() # agregar la columna de targets al set\n",
    "\n",
    "# separar variables en numéricas y categóricas\n",
    "train_num = train_data.drop(['ocean_proximity'], axis=1)\n",
    "train_cat = train_data[['ocean_proximity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40fb4771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-118.485 ,   34.25  ,   29.    , 2140.    ,  436.    , 1168.5   ,\n",
       "        411.    ,    3.5417])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") # definir imputer\n",
    "imputer.fit(train_num) # calcular mediana\n",
    "\n",
    "# mediana de cada característica o columna (7)\n",
    "imputer.statistics_ # valores calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1db391e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2246e+02,  3.8530e+01,  3.2000e+01, ...,  7.8500e+02,\n",
       "         3.0900e+02,  3.6641e+00],\n",
       "       [-1.2124e+02,  3.8750e+01,  5.0000e+00, ...,  3.6670e+03,\n",
       "         1.2940e+03,  5.4896e+00],\n",
       "       [-1.2223e+02,  3.7760e+01,  5.2000e+01, ...,  8.0500e+02,\n",
       "         3.2100e+02,  4.7188e+00],\n",
       "       ...,\n",
       "       [-1.1834e+02,  3.4190e+01,  4.3000e+01, ...,  6.1300e+02,\n",
       "         2.5500e+02,  2.6827e+00],\n",
       "       [-1.2193e+02,  3.8310e+01,  2.5000e+01, ...,  8.5000e+01,\n",
       "         3.2000e+01,  4.8750e+00],\n",
       "       [-1.2243e+02,  3.7760e+01,  5.2000e+01, ...,  8.6100e+02,\n",
       "         4.0600e+02,  4.4318e+00]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamamos a transform y le pasamos los valores que debe sustituir en cada característica\n",
    "\n",
    "X_train_num = imputer.transform(train_num) # cambiar valores inexistentes por la media\n",
    "\n",
    "X_train_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d9855",
   "metadata": {},
   "source": [
    "#### Paso 3: Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e102938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4479531 ,  1.36237038,  0.26593831, ..., -0.57477376,\n",
       "        -0.49988848, -0.10907815],\n",
       "       [-0.8391341 ,  1.4653877 , -1.87698795, ...,  1.99190044,\n",
       "         2.05386967,  0.84955467],\n",
       "       [-1.33317574,  1.00180979,  1.8532911 , ..., -0.55696201,\n",
       "        -0.46877671,  0.44478109],\n",
       "       ...,\n",
       "       [ 0.6080586 , -0.66988024,  1.13898234, ..., -0.72795487,\n",
       "        -0.63989147, -0.62444504],\n",
       "       [-1.18346615,  1.25935307, -0.28963517, ..., -1.19818526,\n",
       "        -1.21805194,  0.52680708],\n",
       "       [-1.43298214,  1.00180979,  1.8532911 , ..., -0.50708909,\n",
       "        -0.24840164,  0.29406752]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PREPROCESADO DE LAS VARIABLES NUMÉRICAS (escalado)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # también hay min-max\n",
    "\n",
    "scaler = StandardScaler() # mean y std\n",
    "scaler.fit(X_train_num)\n",
    "X_train_num_scaled = scaler.transform(X_train_num)\n",
    "X_train_num_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "114df5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16512x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PREPROCESADO DE LAS VARIABLES CATEGÓRICAS (OneHotEncoding)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "X_train_cat = cat_encoder.fit_transform(train_cat)\n",
    "X_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32226391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c20016",
   "metadata": {},
   "source": [
    "#### Paso 4: Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87e220b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "## >> CREACIÓN\n",
    "# inicializamos el pipeline y le pasamos una lista con los pasos a ejecutar\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")), # 1- imputer (rellenar huecos)\n",
    "        ('std_scaler', StandardScaler()), # 2- función para normalizar (escalado)\n",
    "    ])\n",
    "\n",
    "##  >> SEPARACIÓN \n",
    "# separo los atributos en numéricos y categóricos\n",
    "\n",
    "num_attribs = list(train_num) # atributos numéricos\n",
    "cat_attribs = [\"ocean_proximity\"] # atributos categóricos\n",
    "\n",
    "##  >> APLICACIÓN\n",
    "# tenemos la posibilidad de aplicar diferentes pipelines a diferentes columnas\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs), # aplico \"num_pipeline\" a las columnas numéricas\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs), # aplico OneHotEncoder a las columnas categóricas\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d6a081b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4479531 ,  1.36237038,  0.26593831, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.8391341 ,  1.4653877 , -1.87698795, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.33317574,  1.00180979,  1.8532911 , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.6080586 , -0.66988024,  1.13898234, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.18346615,  1.25935307, -0.28963517, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.43298214,  1.00180979,  1.8532911 , ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = full_pipeline.fit_transform(train_data)\n",
    "\n",
    "X_train # contiene las variables numéricas y categóricas, sin missing values y todo escalado y codificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13f10f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59807796, -0.74011932,  1.53582054, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.67293276, -0.85718444,  1.21834998, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.31362974, -0.59027595,  0.34530595, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.78271979, -0.78226276,  0.10720303, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.12358232,  0.78172735, -1.08331156, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.20841775,  0.78172735,  0.18657067, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = full_pipeline.transform(test_data) # ojo ! aquí no hacemos fit :) sólo transform\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7ad77",
   "metadata": {},
   "source": [
    "#### Paso 5: Entrenar el modelo (aquí viene el cambio)\n",
    "\n",
    "Usamos **GridSearchCV** para que nos busque automáticamente el **mejor modelo y el mejor hiperperámetro**,  **combinando todos los hiperparámetros**, uno a uno, sin tener que ajustarlos manualmente.\n",
    "\n",
    "+ **Ventajas**: Mucho tiempo para probar todas las combinaciones.\n",
    "- **Desventajas**: Se obtienen los mejores hiperparámetros.\n",
    "\n",
    "Usamos **RandomSearchCV** para obtener una búsqueda aleatoria de un determinado número de combinaciones (iteraciones) dentro de un rango de valores.\n",
    "\n",
    "+ **Ventajas**: Más rápido.\n",
    "- **Desventajas**: No garantiza la mejor combinación porque no todos los valores se prueban.\n",
    "\n",
    "Usamos **Cross-Validation** a la hora de entranar, lo que permite, para el set de entrenamiento, dejar siempre un subconjunto de datos (test) perteneciente el conjunto de entrenamiento en cada iteración e ir rotándolo cada vez.\n",
    "\n",
    "Se usa para sacarle más provecho al set de datos cuando este es pequeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddcbf896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('num_pipeline',\n",
       "                                              Pipeline(steps=[('imputer',\n",
       "                                                               SimpleImputer(strategy='median')),\n",
       "                                                              ('std_scaler',\n",
       "                                                               StandardScaler())])),\n",
       "                                             ('svr', SVR())]),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'svr__C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa7f56f0460>,\n",
       "                                        'svr__gamma': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7fa7f567f7c0>,\n",
       "                                        'svr__kernel': ['linear', 'rbf']},\n",
       "                   random_state=42, scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, loguniform\n",
    "\n",
    "# Nota: gamma es ignorado cuando el kernel es \"linear\"\n",
    "\n",
    "param_distribs = {\n",
    "        'svr__kernel': ['linear', 'rbf'],\n",
    "        'svr__C': loguniform(20, 200_000),\n",
    "        'svr__gamma': expon(scale=1.0),\n",
    "    }\n",
    "\n",
    "rnd_search = RandomizedSearchCV(svr_pipeline,\n",
    "                                param_distributions=param_distribs,\n",
    "                                n_iter=50, cv=3,\n",
    "                                scoring='neg_root_mean_squared_error',\n",
    "                                random_state=42,\n",
    "                                n_jobs=4)\n",
    "\n",
    "rnd_search.fit(X_train[:5000], y_train[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89bf44e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('num_pipeline',\n",
      "                 Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
      "                                 ('std_scaler', StandardScaler())])),\n",
      "                ('svr', SVR(C=10000.0, kernel='linear'))])\n"
     ]
    }
   ],
   "source": [
    "# Impresión del mejor estimador\n",
    "\n",
    "#print(mejor_modelo.best_estimator_.get_params()[\"svr__kernel\"])\n",
    "print(mejor_modelo.best_estimator_)\n",
    "\n",
    "# El que mejor se adapta es SVR con kernel linear, C=3000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84f92f",
   "metadata": {},
   "source": [
    "#### Paso 6: Obtener predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21fa1201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([174394.25867546, 124343.08071145, 215126.35697703, ...,\n",
       "       488602.01055101, 268757.54500317, 263097.29949441])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecir valores para todos los datos del test\n",
    "\n",
    "y_test_pred = rnd_search.predict(X_test)\n",
    "#y_test_prob = grid_search.predict_proba(X_test)\n",
    "\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e8195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBTENER LAS MÉTRICAS\n",
    "\n",
    "#auc = roc_auc_score(y_test, y_test_prob[:,1])\n",
    "#print(\"- Precision: \", round(precision_score(y_test, y_test_pred), 2))\n",
    "#print(\"- Recall: \", round(recall_score(y_test, y_test_pred), 2))\n",
    "#print(\"- F-Score: \", round(f1_score(y_test, y_test_pred), 2))\n",
    "#print(\"- AUC: \", round(auc, 2)) #área bajo la curva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4135bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la puntuación del mejor modelo.\n",
    "\n",
    "puntuacion_mejor_modelo = -rnd_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7dad6a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60059.718721644276"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puntuacion_mejor_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd889cfe",
   "metadata": {},
   "source": [
    "Ahora es mucho mejor pero aún está lejos del rendimiento de **RandomForestRegressor**.\n",
    "\n",
    "Los mejores hiperparámetros son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebfcc67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svr__C': 157055.10989448498,\n",
       " 'svr__gamma': 0.26497040005002437,\n",
       " 'svr__kernel': 'rbf'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtener los < MEJORES HIPERPARÁMETROS >\n",
    "\n",
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9064d48",
   "metadata": {},
   "source": [
    "El mejor conjuntos de hiperparámetros para el kernel es **RBF**.\n",
    "\n",
    "La búsqueda aleatoria (**RandomSearchCV**) tiende a encontrar mejores hiperparámetros que la búsqueda rejilla (**GridSearchCV**) en la misma cantidad de tiempo.\n",
    "\n",
    "\n",
    "--------------------------------------------------------\n",
    "Usamos la distribución `expon()` para **gamma**, con una escala de 1, por lo que RandomSearch buscó principalmente valores de esa escala:\n",
    "\n",
    "Alrededor del 80% de las muestras estaban entre 0,1 y 2,3 (aproximadamente el 10% eran más pequeñas y el 10% eran más grandes).\n",
    "\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6eed0608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80066"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "s = expon(scale=1).rvs(100_000)  # get 100,000 samples\n",
    "((s > 0.105) & (s < 2.29)).sum() / 100_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c37ac8e",
   "metadata": {},
   "source": [
    "Usamos las distribución `longuniform()` para C, lo que significa que no teníamos ni idea de cuál era la escala óptima de C antes de ejecutar la búsqueda aletoria.\n",
    "\n",
    "Exploró el rango de 20 a 200 tanto como el rango de 2000 a 20.000 o de 20.000 a 200.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1198d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
