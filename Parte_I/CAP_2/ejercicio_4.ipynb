{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3311fe48",
   "metadata": {},
   "source": [
    "*Los ejercicios se basan en el conjunto de viviendas \"housing.csv\"*\n",
    "\n",
    "### Ejercicio 4\n",
    "\n",
    "Intente crear un transformador personalizado que entrene a un regresor de vecinos más cercanos (`sklearn.neighbors.KNeighborsRegresso`) en su método `fit()`, y genere las predicciones del modelo en su método `transform()`. \n",
    "\n",
    "A continuación, **agregue esta función al pipe de preprocesamiento**, utilizando la latitud y la longitud como entradas a este transformador. \n",
    "\n",
    "Esto añadirá una característica en el modelo que corresponde al precio medio de la vivienda de los distritos más cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a58bfa",
   "metadata": {},
   "source": [
    "#### Paso 1: Preparando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50fed6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "\n",
    "URL = \"https://mymldatasets.s3.eu-de.cloud-object-storage.appdomain.cloud/housing.tgz\"\n",
    "PATH = \"housing.tgz\"\n",
    "\n",
    "def getData(url=URL, path=PATH):\n",
    "  r = requests.get(url)\n",
    "  with open(path, 'wb') as f:\n",
    "    f.write(r.content)\n",
    "  housing_tgz = tarfile.open(path)\n",
    "  housing_tgz.extractall()\n",
    "  housing_tgz.close()\n",
    "\n",
    "getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82342e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('housing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43cc0d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c791521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 16512, 4128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2) # 20% para test y 80% para entrenamiento\n",
    "\n",
    "len(data), len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5fa18b",
   "metadata": {},
   "source": [
    "#### Paso 2: Tratar los valores inexistentes (\"missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d3c52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6de8b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, y_train = train.drop(['median_house_value'], axis=1), train['median_house_value'].copy() # quitar columna de targets del dataset de entrenamiento\n",
    "test_data, y_test = test.drop(['median_house_value'], axis=1), test['median_house_value'].copy() # agregar la columna de targets al set\n",
    "\n",
    "# separar variables en numéricas y categóricas\n",
    "train_num = train_data.drop(['ocean_proximity'], axis=1)\n",
    "train_cat = train_data[['ocean_proximity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d5d3d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-118.48  ,   34.24  ,   29.    , 2125.    ,  434.    , 1165.    ,\n",
       "        409.    ,    3.5275])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") # definir imputer\n",
    "imputer.fit(train_num) # calcular mediana\n",
    "\n",
    "# mediana de cada característica o columna (7)\n",
    "imputer.statistics_ # valores calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06245a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2109e+02,  3.9480e+01,  2.5000e+01, ...,  8.4500e+02,\n",
       "         3.3000e+02,  1.5603e+00],\n",
       "       [-1.2252e+02,  3.7880e+01,  5.2000e+01, ...,  8.8000e+01,\n",
       "         4.6000e+01,  3.8068e+00],\n",
       "       [-1.2196e+02,  3.8360e+01,  1.1000e+01, ...,  1.7720e+03,\n",
       "         6.9400e+02,  2.7434e+00],\n",
       "       ...,\n",
       "       [-1.1859e+02,  3.4210e+01,  2.6000e+01, ...,  1.9860e+03,\n",
       "         6.4500e+02,  2.9974e+00],\n",
       "       [-1.2272e+02,  3.8420e+01,  2.6000e+01, ...,  9.3700e+02,\n",
       "         2.4800e+02,  1.9458e+00],\n",
       "       [-1.1836e+02,  3.3920e+01,  2.6000e+01, ...,  2.3080e+03,\n",
       "         1.0090e+03,  2.6667e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llamamos a transform y le pasamos los valores que debe sustituir en cada característica\n",
    "\n",
    "X_train_num = imputer.transform(train_num) # cambiar valores inexistentes por la media\n",
    "\n",
    "X_train_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330f1385",
   "metadata": {},
   "source": [
    "#### Paso 3: Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9513edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76558832,  1.81138192, -0.28940083, ..., -0.52972113,\n",
       "        -0.44530818, -1.21220839],\n",
       "       [-1.47930356,  1.06129734,  1.85122327, ..., -1.22414766,\n",
       "        -1.19282265, -0.02730433],\n",
       "       [-1.19980668,  1.28632271, -1.39935407, ...,  0.32065323,\n",
       "         0.51277374, -0.5881888 ],\n",
       "       ...,\n",
       "       [ 0.48216561, -0.65920917, -0.21011846, ...,  0.51696403,\n",
       "         0.38380118, -0.4542179 ],\n",
       "       [-1.57912388,  1.31445089, -0.21011846, ..., -0.44532583,\n",
       "        -0.66113982, -1.00887853],\n",
       "       [ 0.59695897, -0.795162  , -0.21011846, ...,  0.81234758,\n",
       "         1.3418831 , -0.6286438 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PREPROCESADO DE LAS VARIABLES NUMÉRICAS (escalado)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # también hay min-max\n",
    "\n",
    "scaler = StandardScaler() # mean y std\n",
    "scaler.fit(X_train_num)\n",
    "X_train_num_scaled = scaler.transform(X_train_num)\n",
    "X_train_num_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4749005c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16512x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## PREPROCESADO DE LAS VARIABLES CATEGÓRICAS (OneHotEncoding)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "X_train_cat = cat_encoder.fit_transform(train_cat)\n",
    "X_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df503742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1252d24",
   "metadata": {},
   "source": [
    "#### Paso 4: Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "333ff903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "## >> CREACIÓN\n",
    "# inicializamos el pipeline y le pasamos una lista con los pasos a ejecutar\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")), # 1- imputer (rellenar huecos)\n",
    "        ('std_scaler', StandardScaler()), # 2- función para normalizar (escalado)\n",
    "    ])\n",
    "\n",
    "##  >> SEPARACIÓN \n",
    "# separo los atributos en numéricos y categóricos\n",
    "\n",
    "num_attribs = list(train_num) # atributos numéricos\n",
    "cat_attribs = [\"ocean_proximity\"] # atributos categóricos\n",
    "\n",
    "##  >> APLICACIÓN\n",
    "# tenemos la posibilidad de aplicar diferentes pipelines a diferentes columnas\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs), # aplico \"num_pipeline\" a las columnas numéricas\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs), # aplico OneHotEncoder a las columnas categóricas\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22ba07",
   "metadata": {},
   "source": [
    "### NOVEDAD DEL EJERCICIO\n",
    "\n",
    "En lugar de limitarnos a regresores KNN, vamos a crear un **transformador** que acepte cualquier regresor.\n",
    "\n",
    "Para esto podemos extender MetaEstimatorMixin y tener un argumento estimador requerido en el constructor.\n",
    "\n",
    "El método `fit()` debe funcionar en un clon de este estimador, y también debe guardar feature_names_in_. \n",
    "\n",
    "MetaEstimatorMixin se asegurará de que el estimador se incluya como parámetro obligatorio y actualizará `get_params()` y `set_params()` para que los hiperparámetros del estimador estén disponibles para el ajuste. \n",
    "\n",
    "Por último, creamos un método `get_feature_names_out()`: el nombre de la columna de salida es ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2341f644",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3k/rj832x716_563czpglqh2mmw0000gn/T/ipykernel_1973/4109010291.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetaEstimatorMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mFeatureFromRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetaEstimatorMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.base import MetaEstimatorMixin, clone\n",
    "\n",
    "class FeatureFromRegressor(MetaEstimatorMixin, BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        estimator_ = clone(self.estimator)\n",
    "        estimator_.fit(X, y)\n",
    "        self.estimator_ = estimator_\n",
    "        self.n_features_in_ = self.estimator_.n_features_in_\n",
    "        if hasattr(self.estimator, \"feature_names_in_\"):\n",
    "            self.feature_names_in_ = self.estimator.feature_names_in_\n",
    "        return self  # always return self!\n",
    "    \n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self)\n",
    "        predictions = self.estimator_.predict(X)\n",
    "        if predictions.ndim == 1:\n",
    "            predictions = predictions.reshape(-1, 1)\n",
    "        return predictions\n",
    "\n",
    "    def get_feature_names_out(self, names=None):\n",
    "        check_is_fitted(self)\n",
    "        n_outputs = getattr(self.estimator_, \"n_outputs_\", 1)\n",
    "        estimator_class_name = self.estimator_.__class__.__name__\n",
    "        estimator_short_name = estimator_class_name.lower().replace(\"_\", \"\")\n",
    "        return [f\"{estimator_short_name}_prediction_{i}\"\n",
    "                for i in range(n_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39b177c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FeatureFromRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3k/rj832x716_563czpglqh2mmw0000gn/T/ipykernel_1973/4203092382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_checks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcheck_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFeatureFromRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKNeighborsRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'FeatureFromRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "check_estimator(FeatureFromRegressor(KNeighborsRegressor()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cb92b1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FeatureFromRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3k/rj832x716_563czpglqh2mmw0000gn/T/ipykernel_1973/1575780958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mknn_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"distance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mknn_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureFromRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgeo_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhousing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"latitude\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"longitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mknn_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhousing_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FeatureFromRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "knn_reg = KNeighborsRegressor(n_neighbors=3, weights=\"distance\")\n",
    "knn_transformer = FeatureFromRegressor(knn_reg)\n",
    "geo_features = housing[[\"latitude\", \"longitude\"]]\n",
    "knn_transformer.fit_transform(geo_features, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4956fb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knn_transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3k/rj832x716_563czpglqh2mmw0000gn/T/ipykernel_1973/3347372130.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mknn_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'knn_transformer' is not defined"
     ]
    }
   ],
   "source": [
    "knn_transformer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65698f4e",
   "metadata": {},
   "source": [
    "Ahora lo incluimos en el pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0033f402",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3k/rj832x716_563czpglqh2mmw0000gn/T/ipykernel_1973/1141417507.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m transformers = [(name, clone(transformer), columns)\n\u001b[0;32m----> 4\u001b[0;31m                 for name, transformer, columns in preprocessing.transformers]\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgeo_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"geo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeo_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"geo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"latitude\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"longitude\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "transformers = [(name, clone(transformer), columns)\n",
    "                for name, transformer, columns in preprocessing.transformers]\n",
    "geo_index = [name for name, _, _ in transformers].index(\"geo\")\n",
    "transformers[geo_index] = (\"geo\", knn_transformer, [\"latitude\", \"longitude\"])\n",
    "\n",
    "new_geo_preprocessing = ColumnTransformer(transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82ed8908",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_geo_preprocessing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3k/rj832x716_563czpglqh2mmw0000gn/T/ipykernel_1973/3833103321.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m new_geo_pipeline = Pipeline([\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'preprocessing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_geo_preprocessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     ('svr', SVR(C=rnd_search.best_params_[\"svr__C\"],\n\u001b[1;32m      4\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnd_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"svr__gamma\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 kernel=rnd_search.best_params_[\"svr__kernel\"])),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_geo_preprocessing' is not defined"
     ]
    }
   ],
   "source": [
    "new_geo_pipeline = Pipeline([\n",
    "    ('preprocessing', new_geo_preprocessing),\n",
    "    ('svr', SVR(C=rnd_search.best_params_[\"svr__C\"],\n",
    "                gamma=rnd_search.best_params_[\"svr__gamma\"],\n",
    "                kernel=rnd_search.best_params_[\"svr__kernel\"])),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb9d99b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3k/rj832x716_563czpglqh2mmw0000gn/T/ipykernel_1973/3260191287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m new_pipe_rmses = -cross_val_score(new_geo_pipeline,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                   \u001b[0mhousing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                   \u001b[0mhousing_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_root_mean_squared_error\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   cv=3)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "new_pipe_rmses = -cross_val_score(new_geo_pipeline,\n",
    "                                  housing.iloc[:5000],\n",
    "                                  housing_labels.iloc[:5000],\n",
    "                                  scoring=\"neg_root_mean_squared_error\",\n",
    "                                  cv=3)\n",
    "pd.Series(new_pipe_rmses).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389bca2e",
   "metadata": {},
   "source": [
    "¡Sí, eso es terrible! Aparentemente, las características de similitud de los grupos eran mucho mejores. Pero, ¿quizás deberíamos ajustar los hiperparámetros de KNeighborsRegressor? De eso se trata el siguiente ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c90c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
