{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e03b9d",
   "metadata": {},
   "source": [
    "Supongamos que haces una pregunta compleja a miles de personas al azar y luego agregas sus respuestas. En muchos casos, encontrará que esta respuesta agregada es mejor que la respuesta de un experto. Esto se llama la sabiduría de la multitud. Del mismo modo, si agrega las predicciones de un grupo de predictores (como clasificadores o regresiónres), a menudo obtendrá mejores predicciones que con el mejor predictor individual. Un grupo de predictores se llama conjunto; por lo tanto, esta técnica se llama aprendizaje conjunto, y un algoritmo de aprendizaje conjunto se llama método conjunto.\n",
    "\n",
    "Como ejemplo de un método de conjunto, puedes entrenar a un grupo de clasificadores de árbol de decisiones, cada uno en un subconjunto aleatorio diferente del conjunto de entrenamiento. A continuación, puede obtener las predicciones de todos los árboles individuales, y la clase que obtiene la mayor cantidad de votos es la predicción del conjunto (ver el último ejercicio en el capítulo 6). Tal conjunto de árboles de decisión se llama bosque aleatorio, y a pesar de su simplicidad, este es uno de los algoritmos de aprendizaje automático más potentes disponibles en la actualidad.\n",
    "\n",
    "Como se discutió en el capítulo 2, a menudo usará métodos de conjunto cerca del final de un proyecto, una vez que ya haya construido algunos buenos predictores, para combinarlos en un predictor aún mejor. De hecho, las soluciones ganadoras en los concursos de aprendizaje automático a menudo implican varios métodos de conjunto, los más famosos en el concurso de premios Netflix.\n",
    "\n",
    "En este capítulo examinaremos los métodos de conjunto más populares, incluidos los clasificadores de votación, los conjuntos de embolsado y pegado, los bosques aleatorios y los conjuntos de refuerzo y apilamiento.\n",
    "\n",
    "# Clasificadores de votación\n",
    "\n",
    "Supongamos que has entrenado a algunos clasificadores, cada uno de los cuales alcanza una precisión de alrededor del 80 %. Puede tener un clasificador de regresión logística, un clasificador SVM, un clasificador de bosques aleatorio, un clasificador de vecinos más cercanos y tal vez algunos más (ver Figura 7-1).\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_0701.png)\n",
    "\n",
    "(_Figura 7-1. Formación de diversos clasificadores_)\n",
    "\n",
    "Una forma muy sencilla de crear un clasificador aún mejor es agregar las predicciones de cada clasificador: la clase que obtiene la mayor cantidad de votos es la predicción del conjunto. Este clasificador de voto mayoritario se llama clasificador de voto duro (ver Figura 7-2).\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_0702.png)\n",
    "\n",
    "(_Figura 7-2. Predicciones de clasificación de votación difícil_)\n",
    "\n",
    "Sorprendentemente, este clasificador de votación a menudo logra una mayor precisión que el mejor clasificador del conjunto. De hecho, incluso si cada clasificador es un alumno débil (lo que significa que solo lo hace un poco mejor que la adivinación aleatoria), el conjunto puede seguir siendo un aprendiz fuerte (lo que alcanza una alta precisión), siempre que haya un número suficiente de alumnos débiles en el conjunto y sean lo suficientemente diversos.\n",
    "\n",
    "¿Cómo es esto posible? La siguiente analogía puede ayudar a arrojar algo de luz sobre este misterio. Supongamos que tiene una moneda ligeramente sesgada que tiene un 51 % de probabilidades de subir cabezas y un 49 % de probabilidades de subir colas. Si lo lanzas 1.000 veces, generalmente obtendrás más o menos 510 cabezas y 490 colas, y por lo tanto una mayoría de cabezas. Si haces los cálculos, encontrarás que la probabilidad de obtener la mayoría de las cabezas después de 1000 lanzamientos es cercana al 75 %. Cuanto más lances la moneda, mayor será la probabilidad (por ejemplo, con 10.000 lanzamientos, la probabilidad aumenta por encima del 97 %). Esto se debe a la ley de los grandes números: a medida que sigues lanzando la moneda, la proporción de cabezas se acerca cada vez más a la probabilidad de cabezas (51%). La figura 7-3 muestra 10 series de lanzamientos de monedas sesgadas. Puedes ver que a medida que aumenta el número de lanzamientos, la proporción de cabezas se acerca al 51 %. Eventualmente, las 10 series terminan tan cerca del 51 % que están constantemente por encima del 50 %.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_0703.png)\n",
    "\n",
    "Del mismo modo, supongamos que construyes un conjunto que contiene 1000 clasificadores que son individualmente correctos solo el 51 % del tiempo (apenas mejor que la adivinanza aleatoria). Si predices la clase votada por la mayoría, ¡puedes esperar una precisión de hasta un 75 %! Sin embargo, esto solo es cierto si todos los clasificadores son perfectamente independientes, lo que produce errores no correlacionados, lo que claramente no es el caso porque están entrenados con los mismos datos. Es probable que cometan el mismo tipo de errores, por lo que habrá muchos votos mayoritarios para la clase equivocada, lo que reducirá la precisión del conjunto.\n",
    "\n",
    "\n",
    "TIP:\n",
    "\n",
    "- Los métodos de conjunto funcionan mejor cuando los predictores son lo más independientes posible entre sí. Una forma de obtener clasificadores diversos es entrenarlos utilizando algoritmos muy diferentes. Esto aumenta la posibilidad de que cometan tipos de errores muy diferentes, mejorando la precisión del conjunto.\n",
    "\n",
    "Scikit-Learn proporciona una clase VotingClassifier que es bastante fácil de usar: simplemente dale una lista de pares de nombre/predictor y úsala como un clasificador normal. Probémoslo en el conjunto de datos de las lunas (presentado en el Capítulo 5). Cargaremos y dividiremos el conjunto de datos de las lunas en un conjunto de entrenamiento y un conjunto de prueba, luego crearemos y entrenaremos un clasificador de votación compuesto por tres clasificadores diversos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25654e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42))])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42)),\n",
    "        ('svc', SVC(random_state=42))\n",
    "    ]\n",
    ")\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d415e2dc",
   "metadata": {},
   "source": [
    "Cuando ajustas un `VotingClassifier`, clona cada estimador y ajusta los clones. Los estimadores originales están disponibles a través del atributo `estimator`, mientras que los clones ajustados están disponibles a través del atributo `estimators_`. \n",
    "Si prefieres un dictado en lugar de una lista, puedes usar `named_estimators` o `named_estimators_` en su lugar. Para comenzar, veamos la precisión de cada clasificador ajustado en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4abf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 0.864\n",
      "rf = 0.896\n",
      "svc = 0.896\n"
     ]
    }
   ],
   "source": [
    "for name, clf in voting_clf.named_estimators_.items():\n",
    "    print(name, \"=\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c284164a",
   "metadata": {},
   "source": [
    "Cuando llama al método `predict()` del clasificador de votación, realiza una votación estricta. Por ejemplo, el clasificador de votación predice la clase 1 para la primera instancia del conjunto de prueba, porque dos de cada tres clasificadores predicen esa clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e6f710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6bd6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1]), array([1]), array([0])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[clf.predict(X_test[:1]) for clf in voting_clf.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f561a83c",
   "metadata": {},
   "source": [
    "Ahora veamos el rendimiento del clasificador de votación en el conjunto de pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885ef46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0444b9bb",
   "metadata": {},
   "source": [
    "¡Ahí lo tienes! El clasificador de votación supera a todos los clasificadores individuales.\n",
    "\n",
    "Si todos los clasificadores pueden estimar las probabilidades de clase (es decir, si todos tienen un método `predict_proba()`), entonces puede decirle a Scikit-Learn que prediga la clase con la probabilidad de clase más alta, promediada entre todos los clasificadores individuales. \n",
    "\n",
    "A esto se le llama soft voting. \n",
    "\n",
    "A menudo logra un mayor rendimiento que la votación dura porque da más peso a los votos con mucha confianza. Todo lo que necesita hacer es configurar el hiperparámetro de votación del clasificador de `voting` en \"soft\" y asegurarse de que todos los clasificadores puedan estimar las probabilidades de clase. Este no es el caso de la clase SVC de forma predeterminada, por lo que debe establecer su hiperparámetro de `probability` en `True` (esto hará que la clase SVC use validación cruzada para estimar las probabilidades de la clase, lo que ralentizará el entrenamiento y agregará un `predict_proba()` método). Probemos eso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d853861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.voting = \"soft\"\n",
    "voting_clf.named_estimators[\"svc\"].probability = True\n",
    "voting_clf.fit(X_train, y_train)\n",
    "voting_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2fe8b9",
   "metadata": {},
   "source": [
    "Llegamos al 92 % de precisión simplemente usando el voto suave, ¡no está mal!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c3843",
   "metadata": {},
   "source": [
    "## Bagging (embolsado) y Taping (pegado)\n",
    "\n",
    "\n",
    "Una forma de obtener un conjunto diverso de clasificadores es utilizar algoritmos de entrenamiento muy diferentes, como se acaba de discutir. Otro enfoque es utilizar el mismo algoritmo de entrenamiento para cada predictor, pero entrenarlos en diferentes subconjuntos aleatorios del conjunto de entrenamiento. Cuando el muestreo se realiza con reemplazo, ⁠1 este método se llama embolsado⁠2 (abreviatura de agregación de arranque ⁠3). Cuando el muestreo se realiza sin reemplazo, se llama pegado.⁠4\n",
    "\n",
    "En otras palabras, tanto el embolsado como el pegado permiten que las instancias de entrenamiento se muestreen varias veces a través de múltiples predictores, pero solo el embolsado permite que las instancias de entrenamiento se muestreen varias veces para el mismo predictor. Este proceso de muestreo y entrenamiento se muestra en la Figura 7-4.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_0704.png)\n",
    "\n",
    "(_Figura 7-4. El embolsado y pegado implica entrenar a varios predictores en diferentes muestras aleatorias del conjunto de entrenamiento_)\n",
    "\n",
    "Una vez que se entrenan todos los predictores, el conjunto puede hacer una predicción para una nueva instancia simplemente agregando las predicciones de todos los predictores. La función de agregación suele ser el modo estadístico para la clasificación (es decir, la predicción más frecuente, al igual que con un clasificador de votación dura), o el promedio para la regresión. Cada predictor individual tiene un sesgo más alto que si estuviera entrenado en el conjunto de entrenamiento original, pero la agregación reduce tanto el sesgo como la varianza.⁠5 En general, el resultado neto es que el conjunto tiene un sesgo similar pero una varianza más baja que un solo predictor entrenado en el conjunto de entrenamiento original.\n",
    "\n",
    "Como se puede ver en la Figura 7-4, todos los predictores se pueden entrenar en paralelo, a través de diferentes núcleos de CPU o incluso diferentes servidores. Del mismo modo, las predicciones se pueden hacer en paralelo. Esta es una de las razones por las que el ensacar y pegar son métodos tan populares: escalan muy bien.\n",
    "\n",
    "\n",
    "## Bagging y Taping en Scikit-Learn\n",
    "\n",
    "\n",
    "Scikit-Learn ofrece una API simple para empaquetar y pegar: clase `BaggingClassifier` (o `BaggingRegressor` para regresión). \n",
    "El siguiente código entrena un conjunto de 500 clasificadores de árboles de decisión:⁠6 cada uno se entrena en 100 instancias de entrenamiento tomadas aleatoriamente del conjunto de entrenamiento con reemplazo (este es un ejemplo de embolsado, pero si desea utilizar el pegado en su lugar, simplemente configure `bootstrap= False`). El parámetro `n_jobs` le dice a Scikit-Learn la cantidad de núcleos de CPU que se usarán para el entrenamiento y las predicciones, y `–1` le dice a Scikit-Learn que use todos los núcleos disponibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c81fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_samples=100,\n",
       "                  n_estimators=500, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,\n",
    "                            max_samples=100, n_jobs=-1, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb88624",
   "metadata": {},
   "source": [
    "La figura 7-5 compara el límite de decisión de un solo árbol de decisión con el límite de decisión de un conjunto de bolsas de 500 árboles (del código anterior), ambos entrenados en el conjunto de datos de lunas. Como puede ver, las predicciones del conjunto probablemente se generalizarán mucho mejor que las predicciones del árbol de decisión único: el conjunto tiene un sesgo comparable pero una varianza más pequeña (hace aproximadamente el mismo número de errores en el conjunto de entrenamiento, pero el límite de decisión es menos irregular).\n",
    "\n",
    "El embolsado introduce un poco más de diversidad en los subconjuntos en los que se entrena cada predictor, por lo que el embolsado termina con un sesgo ligeramente más alto que el pegado; pero la diversidad adicional también significa que los predictores terminan estando menos correlacionados, por lo que la varianza del conjunto se reduce. En general, el embolsado a menudo da como resultado mejores modelos, lo que explica por qué generalmente se prefiere. Pero si tienes tiempo libre y potencia de la CPU, puedes usar la validación cruzada para evaluar tanto el embolsado como el pegado y seleccionar el que mejor funcione.\n",
    "\n",
    "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098125967/files/assets/mls3_0705.png)\n",
    "\n",
    "(_Figura 7-5. Un solo árbol de decisión (izquierda) frente a un conjunto de embolsado de 500 árboles (derecha)_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac9609",
   "metadata": {},
   "source": [
    "## Evaluación fuera del Bagging\n",
    "\n",
    "Con el embolsado, es posible que algunas instancias de entrenamiento se muestreen varias veces para cualquier predictor determinado, mientras que es posible que otras no se muestreen en absoluto. \n",
    "De forma predeterminada, un `BaggingClassifier` muestra m instancias de entrenamiento con reemplazo (`bootstrap=True`), donde m es el tamaño del conjunto de entrenamiento. Con este proceso, se puede demostrar matemáticamente que solo alrededor del 63 % de las instancias de entrenamiento se muestrean en promedio para cada predictor.⁠7 El 37 % restante de las instancias de entrenamiento que no se muestrean se denominan listas para usar (Out-Of-Bag). instancias. \n",
    "\n",
    "Tenga en cuenta que no son los mismos 37% para todos los predictores.\n",
    "\n",
    "Un conjunto de embolsado se puede evaluar utilizando instancias de OOB, sin la necesidad de un conjunto de validación separado: de hecho, si hay suficientes estimadores, entonces cada instancia en el conjunto de entrenamiento probablemente será una instancia de OOB de varios estimadores, por lo que estos estimadores se pueden utilizar para hacer una predicción de conjunto justa para esa instancia. Una vez que tenga una predicción para cada instancia, puede calcular la precisión de la predicción del conjunto (o cualquier otra métrica).\n",
    "\n",
    "En Scikit-Learn, puede configurar `oob_score=True` al crear un `BaggingClassifier` para solicitar una evaluación OOB automática después del entrenamiento. El siguiente código demuestra esto. La puntuación de evaluación resultante está disponible en el atributo `oob_score_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f38ef80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500, oob_score=True, n_jobs=-1, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6e0c29",
   "metadata": {},
   "source": [
    "Según esta evaluación OOB, es probable que este BaggingClassifier logre aproximadamente un 89,6% de precisión en el conjunto de prueba. \n",
    "\n",
    "Verifiquemos esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c5e603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f82c73",
   "metadata": {},
   "source": [
    "Tenemos una precisión del 92 % en la prueba. La evaluación de la OOB fue un poco demasiado pesimista, un poco más del 2 % demasiado baja.\n",
    "\n",
    "La función de decisión OOB para cada instancia de entrenamiento también está disponible a través del atributo de  `oob_decision_function_`. Dado que el estimador base tiene el método `predict_proba()`, la función de decisión devuelve las probabilidades de la clase para cada instancia de entrenamiento. Por ejemplo, la evaluación de la OOB estima que la primera instancia de entrenamiento tiene una probabilidad del 63,6 % de pertenecer a la clase positiva y una probabilidad del 32,4 % de pertenecer a la clase negativa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd61f68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32352941, 0.67647059],\n",
       "       [0.3375    , 0.6625    ],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_[:3]  # probas para las primeras 3 instancias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe0872",
   "metadata": {},
   "source": [
    "## Parches aleatorios y subespacios aleatorios\n",
    "\n",
    "La clase `BaggingClassifier` también admite el muestreo de características. El muestreo está controlado por dos hiperparámetros: `max_features` y `bootstrap_features`. \n",
    "\n",
    "Funcionan de la misma manera que `max_samples` y `bootstrap`, pero para muestreo de características en lugar de muestreo de instancias. Por lo tanto, cada predictor se entrenará en un subconjunto aleatorio de características de entrada.\n",
    "\n",
    "Esta técnica es particularmente útil cuando se trata de entradas de alta dimensión (como imágenes), ya que puede acelerar considerablemente el entrenamiento. \n",
    "\n",
    "El muestreo de instancias y características de entrenamiento se denomina método de parches aleatorios.⁠ \n",
    "\n",
    "Mantener todas las instancias de entrenamiento (estableciendo `bootstrap=False y max_samples=1.0`) pero muestreando características (estableciendo `bootstrap_features en True` y/o `max_features` en un valor menor que `1.0`) se llama método de subespacios aleatorios.⁠\n",
    "\n",
    "Las características de muestreo dan como resultado una diversidad de predictores aún mayor, negociando un poco más de sesgo por una varianza más baja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2bdfc",
   "metadata": {},
   "source": [
    "# Bosques aleatorios\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be7717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
